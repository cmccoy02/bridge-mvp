{
  "statistics": {
    "detectionDate": "2025-06-06T21:14:45.872Z",
    "formats": {
      "python": {
        "sources": {
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/util.py": {
            "lines": 363,
            "tokens": 2728,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 10,
            "duplicatedTokens": 117,
            "percentage": 2.75,
            "percentageTokens": 4.29,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/tools.py": {
            "lines": 50,
            "tokens": 564,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/stubs.py": {
            "lines": 128,
            "tokens": 1232,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 46,
            "duplicatedTokens": 696,
            "percentage": 35.94,
            "percentageTokens": 56.49,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/specific_tests.py": {
            "lines": 361,
            "tokens": 3091,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 46,
            "duplicatedTokens": 562,
            "percentage": 12.74,
            "percentageTokens": 18.18,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/flow_control.py": {
            "lines": 172,
            "tokens": 1521,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/conditions.py": {
            "lines": 193,
            "tokens": 1593,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 38,
            "duplicatedTokens": 415,
            "percentage": 19.69,
            "percentageTokens": 26.05,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/__init__.py": {
            "lines": 21,
            "tokens": 170,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/encoders/noise_aug_modules.py": {
            "lines": 34,
            "tokens": 460,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 5,
            "duplicatedTokens": 88,
            "percentage": 14.71,
            "percentageTokens": 19.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/distributions/distributions.py": {
            "lines": 91,
            "tokens": 878,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/util.py": {
            "lines": 305,
            "tokens": 2676,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 30,
            "duplicatedTokens": 308,
            "percentage": 9.84,
            "percentageTokens": 11.51,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/upscaling.py": {
            "lines": 80,
            "tokens": 941,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 5,
            "duplicatedTokens": 88,
            "percentage": 6.25,
            "percentageTokens": 9.35,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py": {
            "lines": 912,
            "tokens": 7494,
            "sources": 1,
            "clones": 15,
            "duplicatedLines": 215,
            "duplicatedTokens": 1835,
            "percentage": 23.57,
            "percentageTokens": 24.49,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/model.py": {
            "lines": 733,
            "tokens": 7454,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 236,
            "percentage": 2.73,
            "percentageTokens": 3.17,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/lightricks/vae/pixel_norm.py": {
            "lines": 11,
            "tokens": 126,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/lightricks/vae/dual_conv3d.py": {
            "lines": 216,
            "tokens": 1794,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/lightricks/vae/conv_nd_factory.py": {
            "lines": 89,
            "tokens": 611,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/lightricks/vae/causal_conv3d.py": {
            "lines": 64,
            "tokens": 606,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/genmo/vae/model.py": {
            "lines": 710,
            "tokens": 5736,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/genmo/joint_model/utils.py": {
            "lines": 101,
            "tokens": 814,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/genmo/joint_model/temporal_rope.py": {
            "lines": 33,
            "tokens": 187,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/genmo/joint_model/rope_mixed.py": {
            "lines": 87,
            "tokens": 498,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/genmo/joint_model/layers.py": {
            "lines": 152,
            "tokens": 1531,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 12,
            "duplicatedTokens": 207,
            "percentage": 7.89,
            "percentageTokens": 13.52,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/genmo/joint_model/asymm_models_joint.py": {
            "lines": 555,
            "tokens": 4654,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/cosmos_tokenizer/utils.py": {
            "lines": 111,
            "tokens": 874,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/cosmos_tokenizer/patching.py": {
            "lines": 376,
            "tokens": 4495,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 68,
            "duplicatedTokens": 924,
            "percentage": 18.09,
            "percentageTokens": 20.56,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/vae/music_vocoder.py": {
            "lines": 537,
            "tokens": 4693,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 40,
            "duplicatedTokens": 236,
            "percentage": 7.45,
            "percentageTokens": 5.03,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/vae/music_log_mel.py": {
            "lines": 112,
            "tokens": 913,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/vae/music_dcae_pipeline.py": {
            "lines": 108,
            "tokens": 1141,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/vae/autoencoder_dc.py": {
            "lines": 642,
            "tokens": 6401,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 308,
            "percentage": 3.12,
            "percentageTokens": 4.81,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/server/utils/file_operations_test.py": {
            "lines": 41,
            "tokens": 441,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py": {
            "lines": 566,
            "tokens": 6256,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 174,
            "duplicatedTokens": 1910,
            "percentage": 30.74,
            "percentageTokens": 30.53,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py": {
            "lines": 792,
            "tokens": 8499,
            "sources": 1,
            "clones": 11,
            "duplicatedLines": 211,
            "duplicatedTokens": 2565,
            "percentage": 26.64,
            "percentageTokens": 30.18,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/pixartms.py": {
            "lines": 255,
            "tokens": 3064,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 5,
            "duplicatedTokens": 110,
            "percentage": 1.96,
            "percentageTokens": 3.59,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py": {
            "lines": 379,
            "tokens": 4537,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 63,
            "duplicatedTokens": 1017,
            "percentage": 16.62,
            "percentageTokens": 22.42,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/temporal_ae.py": {
            "lines": 245,
            "tokens": 2186,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 206,
            "percentage": 10.61,
            "percentageTokens": 9.42,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/sub_quadratic_attention.py": {
            "lines": 274,
            "tokens": 2171,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/ema.py": {
            "lines": 79,
            "tokens": 708,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/models/autoencoder.py": {
            "lines": 234,
            "tokens": 2069,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/lumina/model.py": {
            "lines": 620,
            "tokens": 5586,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/lightricks/symmetric_patchifier.py": {
            "lines": 116,
            "tokens": 872,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/lightricks/model.py": {
            "lines": 505,
            "tokens": 5105,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/posemb_layers.py": {
            "lines": 223,
            "tokens": 1885,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/poolers.py": {
            "lines": 35,
            "tokens": 681,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/models.py": {
            "lines": 415,
            "tokens": 3943,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 95,
            "duplicatedTokens": 1032,
            "percentage": 22.89,
            "percentageTokens": 26.17,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/controlnet.py": {
            "lines": 309,
            "tokens": 1880,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 71,
            "duplicatedTokens": 634,
            "percentage": 22.98,
            "percentageTokens": 33.72,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/attn_layers.py": {
            "lines": 217,
            "tokens": 2449,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 10,
            "duplicatedTokens": 260,
            "percentage": 4.61,
            "percentageTokens": 10.62,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py": {
            "lines": 354,
            "tokens": 4480,
            "sources": 1,
            "clones": 11,
            "duplicatedLines": 125,
            "duplicatedTokens": 1565,
            "percentage": 35.31,
            "percentageTokens": 34.93,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/vae.py": {
            "lines": 586,
            "tokens": 5336,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 40,
            "duplicatedTokens": 476,
            "percentage": 6.83,
            "percentageTokens": 8.92,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/model.py": {
            "lines": 134,
            "tokens": 1277,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 49,
            "duplicatedTokens": 538,
            "percentage": 36.57,
            "percentageTokens": 42.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py": {
            "lines": 801,
            "tokens": 9120,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 101,
            "duplicatedTokens": 1171,
            "percentage": 12.61,
            "percentageTokens": 12.84,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/redux.py": {
            "lines": 24,
            "tokens": 226,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py": {
            "lines": 210,
            "tokens": 2382,
            "sources": 1,
            "clones": 11,
            "duplicatedLines": 158,
            "duplicatedTokens": 1881,
            "percentage": 75.24,
            "percentageTokens": 78.97,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/math.py": {
            "lines": 43,
            "tokens": 892,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py": {
            "lines": 277,
            "tokens": 3990,
            "sources": 1,
            "clones": 14,
            "duplicatedLines": 141,
            "duplicatedTokens": 2082,
            "percentage": 50.9,
            "percentageTokens": 52.18,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/controlnet.py": {
            "lines": 205,
            "tokens": 2865,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 67,
            "duplicatedTokens": 1281,
            "percentage": 32.68,
            "percentageTokens": 44.71,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/vae.py": {
            "lines": 129,
            "tokens": 1344,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 12,
            "duplicatedTokens": 364,
            "percentage": 9.3,
            "percentageTokens": 27.08,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/position_embedding.py": {
            "lines": 207,
            "tokens": 2156,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/model.py": {
            "lines": 511,
            "tokens": 3581,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 14,
            "duplicatedTokens": 224,
            "percentage": 2.74,
            "percentageTokens": 6.26,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/blocks.py": {
            "lines": 806,
            "tokens": 5692,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 24,
            "duplicatedTokens": 206,
            "percentage": 2.98,
            "percentageTokens": 3.62,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/model.py": {
            "lines": 270,
            "tokens": 2853,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 106,
            "duplicatedTokens": 1256,
            "percentage": 39.26,
            "percentageTokens": 44.02,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py": {
            "lines": 180,
            "tokens": 2575,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 112,
            "duplicatedTokens": 1574,
            "percentage": 62.22,
            "percentageTokens": 61.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c_coder.py": {
            "lines": 97,
            "tokens": 927,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 14,
            "duplicatedTokens": 152,
            "percentage": 14.43,
            "percentageTokens": 16.4,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py": {
            "lines": 272,
            "tokens": 3739,
            "sources": 1,
            "clones": 16,
            "duplicatedLines": 219,
            "duplicatedTokens": 3029,
            "percentage": 80.51,
            "percentageTokens": 81.01,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py": {
            "lines": 255,
            "tokens": 3558,
            "sources": 1,
            "clones": 14,
            "duplicatedLines": 197,
            "duplicatedTokens": 2829,
            "percentage": 77.25,
            "percentageTokens": 79.51,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_a.py": {
            "lines": 258,
            "tokens": 3074,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/controlnet.py": {
            "lines": 91,
            "tokens": 1063,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/common.py": {
            "lines": 153,
            "tokens": 2139,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 14,
            "duplicatedTokens": 192,
            "percentage": 9.15,
            "percentageTokens": 8.98,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/aura/mmdit.py": {
            "lines": 497,
            "tokens": 6375,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 76,
            "duplicatedTokens": 1004,
            "percentage": 15.29,
            "percentageTokens": 15.75,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/audio/embedders.py": {
            "lines": 107,
            "tokens": 1006,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/audio/dit.py": {
            "lines": 895,
            "tokens": 8665,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/audio/autoencoder.py": {
            "lines": 274,
            "tokens": 2718,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/model.py": {
            "lines": 384,
            "tokens": 3818,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 10,
            "duplicatedTokens": 158,
            "percentage": 2.6,
            "percentageTokens": 4.14,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/attention.py": {
            "lines": 760,
            "tokens": 7209,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 108,
            "duplicatedTokens": 1026,
            "percentage": 14.21,
            "percentageTokens": 14.23,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/comfy_types/examples/example_nodes.py": {
            "lines": 27,
            "tokens": 166,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/api_server/routes/internal/internal_routes.py": {
            "lines": 72,
            "tokens": 694,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/utils/json_util_test.py": {
            "lines": 70,
            "tokens": 929,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/utils/extra_config_test.py": {
            "lines": 302,
            "tokens": 2164,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 16,
            "duplicatedTokens": 156,
            "percentage": 5.3,
            "percentageTokens": 7.21,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/prompt_server_test/user_manager_test.py": {
            "lines": 288,
            "tokens": 2861,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 12,
            "duplicatedTokens": 158,
            "percentage": 4.17,
            "percentageTokens": 5.52,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/folder_paths_test/filter_by_content_types_test.py": {
            "lines": 65,
            "tokens": 677,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/execution_test/validate_node_input_test.py": {
            "lines": 118,
            "tokens": 950,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/comfy_test/folder_path_test.py": {
            "lines": 161,
            "tokens": 1579,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/comfy_extras_test/image_stitch_test.py": {
            "lines": 241,
            "tokens": 2652,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/comfy_api_test/video_types_test.py": {
            "lines": 238,
            "tokens": 1926,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/comfy_api_test/input_impl_test.py": {
            "lines": 90,
            "tokens": 629,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/comfy_api_nodes_test/mapper_utils_test.py": {
            "lines": 296,
            "tokens": 1785,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/app_test/model_manager_test.py": {
            "lines": 61,
            "tokens": 495,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/app_test/frontend_manager_test.py": {
            "lines": 173,
            "tokens": 1067,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/app_test/custom_node_manager_test.py": {
            "lines": 146,
            "tokens": 1152,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_inference.py": {
            "lines": 234,
            "tokens": 1949,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 56,
            "duplicatedTokens": 591,
            "percentage": 23.93,
            "percentageTokens": 30.32,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_execution.py": {
            "lines": 523,
            "tokens": 7143,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 104,
            "duplicatedTokens": 1274,
            "percentage": 19.89,
            "percentageTokens": 17.84,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/compare/test_quality.py": {
            "lines": 194,
            "tokens": 1780,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/compare/conftest.py": {
            "lines": 40,
            "tokens": 381,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/chainner_models/model_loading.py": {
            "lines": 5,
            "tokens": 43,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/util/validation_utils.py": {
            "lines": 99,
            "tokens": 880,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/tripo_api.py": {
            "lines": 274,
            "tokens": 3187,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 14,
            "duplicatedTokens": 266,
            "percentage": 5.11,
            "percentageTokens": 8.35,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/stability_api.py": {
            "lines": 126,
            "tokens": 1218,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 26,
            "duplicatedTokens": 426,
            "percentage": 20.63,
            "percentageTokens": 34.98,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/rodin_api.py": {
            "lines": 52,
            "tokens": 575,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/request_logger.py": {
            "lines": 124,
            "tokens": 959,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/recraft_api.py": {
            "lines": 261,
            "tokens": 1943,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/pixverse_api.py": {
            "lines": 145,
            "tokens": 1294,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 22,
            "duplicatedTokens": 284,
            "percentage": 15.17,
            "percentageTokens": 21.95,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/luma_api.py": {
            "lines": 252,
            "tokens": 2155,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/bfl_api.py": {
            "lines": 173,
            "tokens": 2166,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 72,
            "duplicatedTokens": 1042,
            "percentage": 41.62,
            "percentageTokens": 48.11,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/PixverseDto.py": {
            "lines": 56,
            "tokens": 421,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/PixverseController.py": {
            "lines": 16,
            "tokens": 91,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api/util/video_types.py": {
            "lines": 49,
            "tokens": 316,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api/util/__init__.py": {
            "lines": 7,
            "tokens": 37,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api/torch_helpers/torch_compile.py": {
            "lines": 68,
            "tokens": 534,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api/torch_helpers/__init__.py": {
            "lines": 4,
            "tokens": 20,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api/input_impl/video_types.py": {
            "lines": 301,
            "tokens": 2824,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api/input_impl/__init__.py": {
            "lines": 6,
            "tokens": 30,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api/input/video_types.py": {
            "lines": 54,
            "tokens": 267,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api/input/basic_types.py": {
            "lines": 18,
            "tokens": 52,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api/input/__init__.py": {
            "lines": 7,
            "tokens": 40,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py": {
            "lines": 95,
            "tokens": 871,
            "sources": 1,
            "clones": 9,
            "duplicatedLines": 118,
            "duplicatedTokens": 1081,
            "percentage": 124.21,
            "percentageTokens": 124.11,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/lora.py": {
            "lines": 141,
            "tokens": 1241,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 12,
            "duplicatedTokens": 107,
            "percentage": 8.51,
            "percentageTokens": 8.62,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/lokr.py": {
            "lines": 132,
            "tokens": 1291,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 27,
            "duplicatedTokens": 340,
            "percentage": 20.45,
            "percentageTokens": 26.34,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/loha.py": {
            "lines": 99,
            "tokens": 992,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 19,
            "duplicatedTokens": 223,
            "percentage": 19.19,
            "percentageTokens": 22.48,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/glora.py": {
            "lines": 92,
            "tokens": 1080,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 224,
            "percentage": 21.74,
            "percentageTokens": 20.74,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/boft.py": {
            "lines": 114,
            "tokens": 1095,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 70,
            "duplicatedTokens": 653,
            "percentage": 61.4,
            "percentageTokens": 59.63,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/base.py": {
            "lines": 103,
            "tokens": 801,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 31,
            "duplicatedTokens": 211,
            "percentage": 30.1,
            "percentageTokens": 26.34,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/__init__.py": {
            "lines": 16,
            "tokens": 104,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/wan.py": {
            "lines": 36,
            "tokens": 584,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5.py": {
            "lines": 248,
            "tokens": 3108,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 12,
            "duplicatedTokens": 176,
            "percentage": 4.84,
            "percentageTokens": 5.66,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/spiece_tokenizer.py": {
            "lines": 33,
            "tokens": 338,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd3_clip.py": {
            "lines": 165,
            "tokens": 2090,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 59,
            "duplicatedTokens": 682,
            "percentage": 35.76,
            "percentageTokens": 32.63,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd2_clip.py": {
            "lines": 22,
            "tokens": 398,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 5,
            "duplicatedTokens": 89,
            "percentage": 22.73,
            "percentageTokens": 22.36,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sa_t5.py": {
            "lines": 21,
            "tokens": 428,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/pixart_t5.py": {
            "lines": 41,
            "tokens": 572,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 38,
            "duplicatedTokens": 679,
            "percentage": 92.68,
            "percentageTokens": 118.71,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/lumina2.py": {
            "lines": 38,
            "tokens": 568,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/lt.py": {
            "lines": 17,
            "tokens": 243,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/long_clipl.py": {
            "lines": 24,
            "tokens": 255,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/llama.py": {
            "lines": 330,
            "tokens": 3885,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 54,
            "duplicatedTokens": 662,
            "percentage": 16.36,
            "percentageTokens": 17.04,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hydit.py": {
            "lines": 80,
            "tokens": 1174,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hunyuan_video.py": {
            "lines": 158,
            "tokens": 1962,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hidream.py": {
            "lines": 154,
            "tokens": 1857,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 48,
            "duplicatedTokens": 512,
            "percentage": 31.17,
            "percentageTokens": 27.57,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/genmo.py": {
            "lines": 37,
            "tokens": 465,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 16,
            "duplicatedTokens": 292,
            "percentage": 43.24,
            "percentageTokens": 62.8,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/flux.py": {
            "lines": 69,
            "tokens": 823,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 11,
            "duplicatedTokens": 203,
            "percentage": 15.94,
            "percentageTokens": 24.67,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/cosmos.py": {
            "lines": 41,
            "tokens": 625,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 16,
            "duplicatedTokens": 262,
            "percentage": 39.02,
            "percentageTokens": 41.92,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/bert.py": {
            "lines": 142,
            "tokens": 2028,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 25,
            "duplicatedTokens": 451,
            "percentage": 17.61,
            "percentageTokens": 22.24,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/aura_t5.py": {
            "lines": 21,
            "tokens": 444,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/ace_text_cleaners.py": {
            "lines": 394,
            "tokens": 4153,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/ace.py": {
            "lines": 152,
            "tokens": 1743,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/taesd/taesd.py": {
            "lines": 78,
            "tokens": 1102,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/t2i_adapter/adapter.py": {
            "lines": 298,
            "tokens": 3372,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 24,
            "duplicatedTokens": 203,
            "percentage": 8.05,
            "percentageTokens": 6.02,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/util.py": {
            "lines": 196,
            "tokens": 1796,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/common_dit.py": {
            "lines": 15,
            "tokens": 183,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/k_diffusion/utils.py": {
            "lines": 312,
            "tokens": 2852,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 30,
            "duplicatedTokens": 280,
            "percentage": 9.62,
            "percentageTokens": 9.82,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/k_diffusion/deis.py": {
            "lines": 118,
            "tokens": 1711,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/image_encoders/dino2.py": {
            "lines": 140,
            "tokens": 1917,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 5,
            "duplicatedTokens": 74,
            "percentage": 3.57,
            "percentageTokens": 3.86,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/extra_samplers/uni_pc.py": {
            "lines": 872,
            "tokens": 8069,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 58,
            "duplicatedTokens": 644,
            "percentage": 6.65,
            "percentageTokens": 7.98,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/comfy_types/node_typing.py": {
            "lines": 347,
            "tokens": 2684,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/comfy_types/__init__.py": {
            "lines": 45,
            "tokens": 288,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/mmdit.py": {
            "lines": 80,
            "tokens": 743,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/dit_embedder.py": {
            "lines": 119,
            "tokens": 1099,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/control_types.py": {
            "lines": 9,
            "tokens": 62,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/cldm.py": {
            "lines": 431,
            "tokens": 4579,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 135,
            "duplicatedTokens": 1115,
            "percentage": 31.32,
            "percentageTokens": 24.35,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/api_server/utils/file_operations.py": {
            "lines": 41,
            "tokens": 371,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/api_server/services/terminal_service.py": {
            "lines": 59,
            "tokens": 468,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.ci/update_windows/update.py": {
            "lines": 150,
            "tokens": 1445,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/utils/json_util.py": {
            "lines": 25,
            "tokens": 152,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/utils/extra_config.py": {
            "lines": 33,
            "tokens": 385,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/conftest.py": {
            "lines": 35,
            "tokens": 314,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/script_examples/websockets_api_example_ws_images.py": {
            "lines": 157,
            "tokens": 595,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 46,
            "duplicatedTokens": 409,
            "percentage": 29.3,
            "percentageTokens": 68.74,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/script_examples/websockets_api_example.py": {
            "lines": 164,
            "tokens": 652,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 54,
            "duplicatedTokens": 496,
            "percentage": 32.93,
            "percentageTokens": 76.07,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/script_examples/basic_api_example.py": {
            "lines": 124,
            "tokens": 170,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/custom_nodes/websocket_image_save.py": {
            "lines": 43,
            "tokens": 292,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_webcam.py": {
            "lines": 32,
            "tokens": 249,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py": {
            "lines": 394,
            "tokens": 6173,
            "sources": 1,
            "clones": 32,
            "duplicatedLines": 306,
            "duplicatedTokens": 4540,
            "percentage": 77.66,
            "percentageTokens": 73.55,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_video_model.py": {
            "lines": 160,
            "tokens": 2061,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 51,
            "duplicatedTokens": 613,
            "percentage": 31.88,
            "percentageTokens": 29.74,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_video.py": {
            "lines": 240,
            "tokens": 2247,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 93,
            "percentage": 4.58,
            "percentageTokens": 4.14,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_upscale_model.py": {
            "lines": 82,
            "tokens": 764,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_torch_compile.py": {
            "lines": 22,
            "tokens": 162,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_tomesd.py": {
            "lines": 175,
            "tokens": 2026,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_string.py": {
            "lines": 359,
            "tokens": 3099,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable_cascade.py": {
            "lines": 140,
            "tokens": 1259,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py": {
            "lines": 142,
            "tokens": 2091,
            "sources": 1,
            "clones": 11,
            "duplicatedLines": 87,
            "duplicatedTokens": 1407,
            "percentage": 61.27,
            "percentageTokens": 67.29,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_slg.py": {
            "lines": 83,
            "tokens": 857,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_sdupscale.py": {
            "lines": 45,
            "tokens": 536,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_sd3.py": {
            "lines": 137,
            "tokens": 1482,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 29,
            "duplicatedTokens": 418,
            "percentage": 21.17,
            "percentageTokens": 28.21,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_sag.py": {
            "lines": 180,
            "tokens": 1866,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_rebatch.py": {
            "lines": 137,
            "tokens": 1577,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_primitive.py": {
            "lines": 97,
            "tokens": 738,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_preview_any.py": {
            "lines": 42,
            "tokens": 283,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_post_processing.py": {
            "lines": 280,
            "tokens": 3144,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_pixart.py": {
            "lines": 23,
            "tokens": 266,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_photomaker.py": {
            "lines": 186,
            "tokens": 1926,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_perpneg.py": {
            "lines": 128,
            "tokens": 1213,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_pag.py": {
            "lines": 55,
            "tokens": 416,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_optimalsteps.py": {
            "lines": 56,
            "tokens": 700,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 67,
            "duplicatedTokens": 607,
            "percentage": 119.64,
            "percentageTokens": 86.71,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_morphology.py": {
            "lines": 86,
            "tokens": 913,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py": {
            "lines": 283,
            "tokens": 2391,
            "sources": 1,
            "clones": 20,
            "duplicatedLines": 226,
            "duplicatedTokens": 2168,
            "percentage": 79.86,
            "percentageTokens": 90.67,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging.py": {
            "lines": 373,
            "tokens": 3702,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 42,
            "duplicatedTokens": 476,
            "percentage": 11.26,
            "percentageTokens": 12.86,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_downscale.py": {
            "lines": 52,
            "tokens": 647,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_advanced.py": {
            "lines": 324,
            "tokens": 3411,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 44,
            "duplicatedTokens": 401,
            "percentage": 13.58,
            "percentageTokens": 11.76,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_mochi.py": {
            "lines": 22,
            "tokens": 319,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 21,
            "duplicatedTokens": 321,
            "percentage": 95.45,
            "percentageTokens": 100.63,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_mask.py": {
            "lines": 411,
            "tokens": 4637,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 20,
            "duplicatedTokens": 210,
            "percentage": 4.87,
            "percentageTokens": 4.53,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_mahiro.py": {
            "lines": 40,
            "tokens": 385,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_lumina2.py": {
            "lines": 103,
            "tokens": 963,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_lt.py": {
            "lines": 473,
            "tokens": 5035,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 99,
            "percentage": 3.17,
            "percentageTokens": 1.97,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_lotus.py": {
            "lines": 28,
            "tokens": 7789,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_lora_extract.py": {
            "lines": 118,
            "tokens": 1346,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_load_3d.py": {
            "lines": 165,
            "tokens": 1531,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 102,
            "duplicatedTokens": 948,
            "percentage": 61.82,
            "percentageTokens": 61.92,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_latent.py": {
            "lines": 287,
            "tokens": 2669,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 34,
            "duplicatedTokens": 286,
            "percentage": 11.85,
            "percentageTokens": 10.72,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_ip2p.py": {
            "lines": 44,
            "tokens": 457,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_images.py": {
            "lines": 535,
            "tokens": 5448,
            "sources": 1,
            "clones": 5,
            "duplicatedLines": 35,
            "duplicatedTokens": 423,
            "percentage": 6.54,
            "percentageTokens": 7.76,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hypertile.py": {
            "lines": 80,
            "tokens": 971,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hypernetwork.py": {
            "lines": 119,
            "tokens": 1263,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hunyuan3d.py": {
            "lines": 633,
            "tokens": 6421,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 8,
            "duplicatedTokens": 86,
            "percentage": 1.26,
            "percentageTokens": 1.34,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hunyuan.py": {
            "lines": 122,
            "tokens": 1455,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 13,
            "duplicatedTokens": 211,
            "percentage": 10.66,
            "percentageTokens": 14.5,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py": {
            "lines": 744,
            "tokens": 6693,
            "sources": 1,
            "clones": 20,
            "duplicatedLines": 234,
            "duplicatedTokens": 2242,
            "percentage": 31.45,
            "percentageTokens": 33.5,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hidream.py": {
            "lines": 54,
            "tokens": 557,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 8,
            "duplicatedTokens": 105,
            "percentage": 14.81,
            "percentageTokens": 18.85,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_gits.py": {
            "lines": 368,
            "tokens": 11775,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 26,
            "duplicatedTokens": 224,
            "percentage": 7.07,
            "percentageTokens": 1.9,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_fresca.py": {
            "lines": 99,
            "tokens": 748,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_freelunch.py": {
            "lines": 112,
            "tokens": 1594,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 66,
            "duplicatedTokens": 880,
            "percentage": 58.93,
            "percentageTokens": 55.21,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_flux.py": {
            "lines": 62,
            "tokens": 527,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_differential_diffusion.py": {
            "lines": 41,
            "tokens": 348,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py": {
            "lines": 800,
            "tokens": 8472,
            "sources": 1,
            "clones": 23,
            "duplicatedLines": 205,
            "duplicatedTokens": 2671,
            "percentage": 25.63,
            "percentageTokens": 31.53,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_cosmos.py": {
            "lines": 81,
            "tokens": 1285,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 8,
            "duplicatedTokens": 110,
            "percentage": 9.88,
            "percentageTokens": 8.56,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_controlnet.py": {
            "lines": 59,
            "tokens": 666,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 14,
            "duplicatedTokens": 198,
            "percentage": 23.73,
            "percentageTokens": 29.73,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_cond.py": {
            "lines": 46,
            "tokens": 487,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_compositing.py": {
            "lines": 213,
            "tokens": 2541,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_clip_sdxl.py": {
            "lines": 53,
            "tokens": 798,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 7,
            "duplicatedTokens": 115,
            "percentage": 13.21,
            "percentageTokens": 14.41,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_cfg.py": {
            "lines": 44,
            "tokens": 423,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_canny.py": {
            "lines": 24,
            "tokens": 273,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_camera_trajectory.py": {
            "lines": 217,
            "tokens": 3023,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_audio.py": {
            "lines": 344,
            "tokens": 3189,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 57,
            "duplicatedTokens": 575,
            "percentage": 16.57,
            "percentageTokens": 18.03,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_attention_multiply.py": {
            "lines": 118,
            "tokens": 1712,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 42,
            "duplicatedTokens": 776,
            "percentage": 35.59,
            "percentageTokens": 45.33,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_apg.py": {
            "lines": 75,
            "tokens": 759,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_align_your_steps.py": {
            "lines": 52,
            "tokens": 577,
            "sources": 1,
            "clones": 3,
            "duplicatedLines": 50,
            "duplicatedTokens": 474,
            "percentage": 96.15,
            "percentageTokens": 82.15,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_advanced_samplers.py": {
            "lines": 110,
            "tokens": 1226,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_ace.py": {
            "lines": 48,
            "tokens": 504,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 9,
            "duplicatedTokens": 107,
            "percentage": 18.75,
            "percentageTokens": 21.23,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_execution/validation.py": {
            "lines": 38,
            "tokens": 206,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_execution/graph_utils.py": {
            "lines": 137,
            "tokens": 1319,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_execution/graph.py": {
            "lines": 286,
            "tokens": 2468,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_execution/caching.py": {
            "lines": 470,
            "tokens": 3873,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 14,
            "duplicatedTokens": 156,
            "percentage": 2.98,
            "percentageTokens": 4.03,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_config/types.py": {
            "lines": 79,
            "tokens": 671,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_config/config_parser.py": {
            "lines": 96,
            "tokens": 417,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_veo2.py": {
            "lines": 307,
            "tokens": 1834,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_tripo.py": {
            "lines": 573,
            "tokens": 4680,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 78,
            "duplicatedTokens": 734,
            "percentage": 13.61,
            "percentageTokens": 15.68,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py": {
            "lines": 613,
            "tokens": 3854,
            "sources": 1,
            "clones": 12,
            "duplicatedLines": 274,
            "duplicatedTokens": 1566,
            "percentage": 44.7,
            "percentageTokens": 40.63,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py": {
            "lines": 634,
            "tokens": 3832,
            "sources": 1,
            "clones": 14,
            "duplicatedLines": 242,
            "duplicatedTokens": 1518,
            "percentage": 38.17,
            "percentageTokens": 39.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_rodin.py": {
            "lines": 461,
            "tokens": 3168,
            "sources": 1,
            "clones": 8,
            "duplicatedLines": 168,
            "duplicatedTokens": 1192,
            "percentage": 36.44,
            "percentageTokens": 37.63,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py": {
            "lines": 524,
            "tokens": 3379,
            "sources": 1,
            "clones": 10,
            "duplicatedLines": 322,
            "duplicatedTokens": 2118,
            "percentage": 61.45,
            "percentageTokens": 62.68,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pika.py": {
            "lines": 781,
            "tokens": 4755,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 68,
            "duplicatedTokens": 436,
            "percentage": 8.71,
            "percentageTokens": 9.17,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_minimax.py": {
            "lines": 331,
            "tokens": 1865,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 114,
            "duplicatedTokens": 620,
            "percentage": 34.44,
            "percentageTokens": 33.24,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py": {
            "lines": 736,
            "tokens": 5031,
            "sources": 1,
            "clones": 12,
            "duplicatedLines": 238,
            "duplicatedTokens": 1666,
            "percentage": 32.34,
            "percentageTokens": 33.11,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py": {
            "lines": 800,
            "tokens": 4859,
            "sources": 1,
            "clones": 18,
            "duplicatedLines": 344,
            "duplicatedTokens": 2158,
            "percentage": 43,
            "percentageTokens": 44.41,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_gemini.py": {
            "lines": 445,
            "tokens": 2427,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/mapper_utils.py": {
            "lines": 115,
            "tokens": 846,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/canary.py": {
            "lines": 9,
            "tokens": 85,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apinode_utils.py": {
            "lines": 677,
            "tokens": 4331,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/supported_models_base.py": {
            "lines": 118,
            "tokens": 947,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/sdxl_clip.py": {
            "lines": 94,
            "tokens": 1343,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 11,
            "duplicatedTokens": 181,
            "percentage": 11.7,
            "percentageTokens": 13.48,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/sd1_clip.py": {
            "lines": 685,
            "tokens": 7301,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/sampler_helpers.py": {
            "lines": 183,
            "tokens": 1886,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/sample.py": {
            "lines": 51,
            "tokens": 821,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/rmsnorm.py": {
            "lines": 54,
            "tokens": 539,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/patcher_extension.py": {
            "lines": 156,
            "tokens": 1789,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/options.py": {
            "lines": 4,
            "tokens": 27,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py": {
            "lines": 437,
            "tokens": 4549,
            "sources": 1,
            "clones": 16,
            "duplicatedLines": 152,
            "duplicatedTokens": 1854,
            "percentage": 34.78,
            "percentageTokens": 40.76,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_sampling.py": {
            "lines": 351,
            "tokens": 3927,
            "sources": 1,
            "clones": 7,
            "duplicatedLines": 63,
            "duplicatedTokens": 700,
            "percentage": 17.95,
            "percentageTokens": 17.83,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py": {
            "lines": 835,
            "tokens": 11681,
            "sources": 1,
            "clones": 12,
            "duplicatedLines": 64,
            "duplicatedTokens": 1724,
            "percentage": 7.66,
            "percentageTokens": 14.76,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/lora_convert.py": {
            "lines": 23,
            "tokens": 212,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/lora.py": {
            "lines": 394,
            "tokens": 4239,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 31,
            "duplicatedTokens": 211,
            "percentage": 7.87,
            "percentageTokens": 4.98,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/latent_formats.py": {
            "lines": 471,
            "tokens": 5580,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 44,
            "duplicatedTokens": 628,
            "percentage": 9.34,
            "percentageTokens": 11.25,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/hooks.py": {
            "lines": 784,
            "tokens": 7554,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/gligen.py": {
            "lines": 343,
            "tokens": 3600,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 88,
            "duplicatedTokens": 742,
            "percentage": 25.66,
            "percentageTokens": 20.61,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/float.py": {
            "lines": 66,
            "tokens": 809,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/diffusers_load.py": {
            "lines": 35,
            "tokens": 360,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/diffusers_convert.py": {
            "lines": 188,
            "tokens": 1688,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/controlnet.py": {
            "lines": 857,
            "tokens": 9663,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 38,
            "duplicatedTokens": 490,
            "percentage": 4.43,
            "percentageTokens": 5.07,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/conds.py": {
            "lines": 129,
            "tokens": 1221,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision.py": {
            "lines": 147,
            "tokens": 1962,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_model.py": {
            "lines": 243,
            "tokens": 3431,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 14,
            "duplicatedTokens": 245,
            "percentage": 5.76,
            "percentageTokens": 7.14,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cli_args.py": {
            "lines": 228,
            "tokens": 2307,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/checkpoint_pickle.py": {
            "lines": 12,
            "tokens": 80,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/app/user_manager.py": {
            "lines": 435,
            "tokens": 3102,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/app/model_manager.py": {
            "lines": 183,
            "tokens": 1960,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 135,
            "percentage": 8.2,
            "percentageTokens": 6.89,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/app/logger.py": {
            "lines": 97,
            "tokens": 758,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/app/frontend_management.py": {
            "lines": 321,
            "tokens": 1850,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/app/custom_node_manager.py": {
            "lines": 144,
            "tokens": 912,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/app/app_settings.py": {
            "lines": 64,
            "tokens": 576,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/server.py": {
            "lines": 898,
            "tokens": 8796,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/node_helpers.py": {
            "lines": 59,
            "tokens": 539,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/new_updater.py": {
            "lines": 34,
            "tokens": 303,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/main.py": {
            "lines": 310,
            "tokens": 2635,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/latent_preview.py": {
            "lines": 106,
            "tokens": 1043,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/hook_breaker_ac10a0.py": {
            "lines": 16,
            "tokens": 124,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/folder_paths.py": {
            "lines": 395,
            "tokens": 4186,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 15,
            "duplicatedTokens": 135,
            "percentage": 3.8,
            "percentageTokens": 3.23,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/cuda_malloc.py": {
            "lines": 89,
            "tokens": 825,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          }
        },
        "total": {
          "lines": 63182,
          "tokens": 625908,
          "sources": 290,
          "clones": 329,
          "duplicatedLines": 4143,
          "duplicatedTokens": 45010,
          "percentage": 6.56,
          "percentageTokens": 7.19,
          "newDuplicatedLines": 0,
          "newClones": 0
        }
      },
      "json": {
        "sources": {
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/graphs/default_graph_sdxl1_0.json": {
            "lines": 143,
            "tokens": 721,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5_tokenizer/tokenizer_config.json": {
            "lines": 938,
            "tokens": 5736,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 102,
            "duplicatedTokens": 409,
            "percentage": 10.87,
            "percentageTokens": 7.13,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5_tokenizer/special_tokens_map.json": {
            "lines": 124,
            "tokens": 542,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 102,
            "duplicatedTokens": 409,
            "percentage": 82.26,
            "percentageTokens": 75.46,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hydit_clip_tokenizer/tokenizer_config.json": {
            "lines": 15,
            "tokens": 99,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hydit_clip_tokenizer/special_tokens_map.json": {
            "lines": 6,
            "tokens": 36,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/umt5_config_xxl.json": {
            "lines": 21,
            "tokens": 141,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/umt5_config_base.json": {
            "lines": 21,
            "tokens": 141,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5_pile_config_xl.json": {
            "lines": 21,
            "tokens": 141,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5_old_config_xxl.json": {
            "lines": 21,
            "tokens": 141,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5_config_xxl.json": {
            "lines": 21,
            "tokens": 141,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5_config_base.json": {
            "lines": 21,
            "tokens": 141,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd2_clip_config.json": {
            "lines": 22,
            "tokens": 140,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/mt5_config_xl.json": {
            "lines": 21,
            "tokens": 141,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hydit_clip.json": {
            "lines": 33,
            "tokens": 217,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/sd1_tokenizer/tokenizer_config.json": {
            "lines": 33,
            "tokens": 210,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/sd1_tokenizer/special_tokens_map.json": {
            "lines": 23,
            "tokens": 140,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/image_encoders/dino2_giant.json": {
            "lines": 20,
            "tokens": 150,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/sd1_clip_config.json": {
            "lines": 24,
            "tokens": 154,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision_siglip_512.json": {
            "lines": 12,
            "tokens": 94,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision_siglip_384.json": {
            "lines": 12,
            "tokens": 94,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision_config_vitl_336_llava.json": {
            "lines": 18,
            "tokens": 120,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 16,
            "duplicatedTokens": 108,
            "percentage": 88.89,
            "percentageTokens": 90,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision_config_vitl_336.json": {
            "lines": 17,
            "tokens": 113,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 16,
            "duplicatedTokens": 108,
            "percentage": 94.12,
            "percentageTokens": 95.58,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision_config_vitl.json": {
            "lines": 17,
            "tokens": 113,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision_config_h.json": {
            "lines": 17,
            "tokens": 113,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision_config_g.json": {
            "lines": 17,
            "tokens": 113,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_config_bigg.json": {
            "lines": 22,
            "tokens": 140,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          }
        },
        "total": {
          "lines": 1660,
          "tokens": 10032,
          "sources": 26,
          "clones": 2,
          "duplicatedLines": 118,
          "duplicatedTokens": 517,
          "percentage": 7.11,
          "percentageTokens": 5.15,
          "newDuplicatedLines": 0,
          "newClones": 0
        }
      },
      "yaml": {
        "sources": {
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/extra_model_paths.yaml": {
            "lines": 2,
            "tokens": 9,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inpainting-inference.yaml": {
            "lines": 157,
            "tokens": 871,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 40,
            "duplicatedTokens": 235,
            "percentage": 25.48,
            "percentageTokens": 26.98,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference_fp32.yaml": {
            "lines": 66,
            "tokens": 380,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 167,
            "duplicatedTokens": 972,
            "percentage": 253.03,
            "percentageTokens": 255.79,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference.yaml": {
            "lines": 66,
            "tokens": 380,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 65,
            "duplicatedTokens": 377,
            "percentage": 98.48,
            "percentageTokens": 99.21,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference-v_fp32.yaml": {
            "lines": 67,
            "tokens": 386,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 129,
            "duplicatedTokens": 746,
            "percentage": 192.54,
            "percentageTokens": 193.26,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference-v.yaml": {
            "lines": 67,
            "tokens": 386,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 67,
            "duplicatedTokens": 386,
            "percentage": 100,
            "percentageTokens": 100,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inpainting-inference.yaml": {
            "lines": 69,
            "tokens": 417,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 36,
            "duplicatedTokens": 215,
            "percentage": 52.17,
            "percentageTokens": 51.56,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_fp16.yaml": {
            "lines": 70,
            "tokens": 418,
            "sources": 1,
            "clones": 6,
            "duplicatedLines": 319,
            "duplicatedTokens": 1901,
            "percentage": 455.71,
            "percentageTokens": 454.78,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_clip_skip_2_fp16.yaml": {
            "lines": 73,
            "tokens": 434,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 70,
            "duplicatedTokens": 418,
            "percentage": 95.89,
            "percentageTokens": 96.31,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_clip_skip_2.yaml": {
            "lines": 72,
            "tokens": 428,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 72,
            "duplicatedTokens": 428,
            "percentage": 100,
            "percentageTokens": 100,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference.yaml": {
            "lines": 69,
            "tokens": 412,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 69,
            "duplicatedTokens": 412,
            "percentage": 100,
            "percentageTokens": 100,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/anything_v3.yaml": {
            "lines": 72,
            "tokens": 428,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 72,
            "duplicatedTokens": 428,
            "percentage": 100,
            "percentageTokens": 100,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/windows_release_package.yml": {
            "lines": 100,
            "tokens": 513,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 215,
            "percentage": 28,
            "percentageTokens": 41.91,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/windows_release_nightly_pytorch.yml": {
            "lines": 90,
            "tokens": 519,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/windows_release_dependencies.yml": {
            "lines": 70,
            "tokens": 444,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/update-version.yml": {
            "lines": 57,
            "tokens": 260,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/update-api-stubs.yml": {
            "lines": 55,
            "tokens": 329,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/test-unit.yml": {
            "lines": 29,
            "tokens": 177,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/test-launch.yml": {
            "lines": 44,
            "tokens": 242,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/test-ci.yml": {
            "lines": 95,
            "tokens": 601,
            "sources": 1,
            "clones": 4,
            "duplicatedLines": 41,
            "duplicatedTokens": 415,
            "percentage": 43.16,
            "percentageTokens": 69.05,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/test-build.yml": {
            "lines": 30,
            "tokens": 173,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/stale-issues.yml": {
            "lines": 20,
            "tokens": 104,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/stable-release.yml": {
            "lines": 104,
            "tokens": 544,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 28,
            "duplicatedTokens": 215,
            "percentage": 26.92,
            "percentageTokens": 39.52,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/ruff.yml": {
            "lines": 22,
            "tokens": 134,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/pullrequest-ci-run.yml": {
            "lines": 52,
            "tokens": 385,
            "sources": 1,
            "clones": 2,
            "duplicatedLines": 23,
            "duplicatedTokens": 209,
            "percentage": 44.23,
            "percentageTokens": 54.29,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/ISSUE_TEMPLATE/user-support.yml": {
            "lines": 39,
            "tokens": 385,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 161,
            "percentage": 28.21,
            "percentageTokens": 41.82,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/ISSUE_TEMPLATE/feature-request.yml": {
            "lines": 31,
            "tokens": 309,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/ISSUE_TEMPLATE/config.yml": {
            "lines": 10,
            "tokens": 195,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/ISSUE_TEMPLATE/bug-report.yml": {
            "lines": 55,
            "tokens": 593,
            "sources": 1,
            "clones": 1,
            "duplicatedLines": 11,
            "duplicatedTokens": 161,
            "percentage": 20,
            "percentageTokens": 27.15,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/redocly.yaml": {
            "lines": 9,
            "tokens": 45,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/redocly-dev.yaml": {
            "lines": 9,
            "tokens": 43,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          }
        },
        "total": {
          "lines": 1771,
          "tokens": 10944,
          "sources": 31,
          "clones": 17,
          "duplicatedLines": 624,
          "duplicatedTokens": 3947,
          "percentage": 35.23,
          "percentageTokens": 36.07,
          "newDuplicatedLines": 0,
          "newClones": 0
        }
      },
      "markdown": {
        "sources": {
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/comfy_types/README.md": {
            "lines": 39,
            "tokens": 258,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.ci/windows_base_files/README_VERY_IMPORTANT.txt": {
            "lines": 30,
            "tokens": 281,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/README.md": {
            "lines": 3,
            "tokens": 4,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/README.md": {
            "lines": 24,
            "tokens": 128,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/README.md": {
            "lines": 60,
            "tokens": 643,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/requirements.txt": {
            "lines": 26,
            "tokens": 50,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/README.md": {
            "lines": 399,
            "tokens": 4669,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          },
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/CONTRIBUTING.md": {
            "lines": 38,
            "tokens": 504,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          }
        },
        "total": {
          "lines": 619,
          "tokens": 6537,
          "sources": 8,
          "clones": 0,
          "duplicatedLines": 0,
          "duplicatedTokens": 0,
          "percentage": 0,
          "percentageTokens": 0,
          "newDuplicatedLines": 0,
          "newClones": 0
        }
      },
      "ini": {
        "sources": {
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/pytest.ini": {
            "lines": 8,
            "tokens": 67,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          }
        },
        "total": {
          "lines": 8,
          "tokens": 67,
          "sources": 1,
          "clones": 0,
          "duplicatedLines": 0,
          "duplicatedTokens": 0,
          "percentage": 0,
          "percentageTokens": 0,
          "newDuplicatedLines": 0,
          "newClones": 0
        }
      },
      "url": {
        "sources": {
          "/var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/README.md": {
            "lines": 15,
            "tokens": 85,
            "sources": 1,
            "clones": 0,
            "duplicatedLines": 0,
            "duplicatedTokens": 0,
            "percentage": 0,
            "percentageTokens": 0,
            "newDuplicatedLines": 0,
            "newClones": 0
          }
        },
        "total": {
          "lines": 15,
          "tokens": 85,
          "sources": 1,
          "clones": 0,
          "duplicatedLines": 0,
          "duplicatedTokens": 0,
          "percentage": 0,
          "percentageTokens": 0,
          "newDuplicatedLines": 0,
          "newClones": 0
        }
      }
    },
    "total": {
      "lines": 67255,
      "tokens": 653573,
      "sources": 357,
      "clones": 348,
      "duplicatedLines": 4885,
      "duplicatedTokens": 49474,
      "percentage": 7.26,
      "percentageTokens": 7.57,
      "newDuplicatedLines": 0,
      "newClones": 0
    }
  },
  "duplicates": [
    {
      "format": "python",
      "lines": 9,
      "fragment": "),\n                \"height\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": 1024 ** 3, \"step\": 1}),\n                \"width\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": 4096 ** 3, \"step\": 1}),\n                \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 1024 ** 3, \"step\": 1}),\n            },\n        }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"stub_constant_image\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/stubs.py",
        "start": 38,
        "end": 46,
        "startLoc": {
          "line": 38,
          "column": 2,
          "position": 407
        },
        "endLoc": {
          "line": 46,
          "column": 22,
          "position": 550
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/stubs.py",
        "start": 11,
        "end": 19,
        "startLoc": {
          "line": 11,
          "column": 2,
          "position": 62
        },
        "endLoc": {
          "line": 19,
          "column": 13,
          "position": 205
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": ":\n    def __init__(self):\n        pass\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"value\": (\"FLOAT\", {\"default\": 0.5, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                \"height\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": 1024 ** 3, \"step\": 1}),\n                \"width\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": 4096 ** 3, \"step\": 1}),\n                \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 1024 ** 3, \"step\": 1}),\n            },\n        }\n\n    RETURN_TYPES = (\"MASK\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/stubs.py",
        "start": 53,
        "end": 68,
        "startLoc": {
          "line": 53,
          "column": 9,
          "position": 612
        },
        "endLoc": {
          "line": 68,
          "column": 7,
          "position": 817
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/stubs.py",
        "start": 31,
        "end": 18,
        "startLoc": {
          "line": 31,
          "column": 18,
          "position": 337
        },
        "endLoc": {
          "line": 18,
          "column": 8,
          "position": 196
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "(self, input1, input2):\n        if isinstance(input1, float) and isinstance(input2, float):\n            result = torch.ones([1, 512, 512, 3]) * input1 * input2\n        else:\n            result = input1 * input2\n        return (result,)\n\n    @classmethod\n    def VALIDATE_INPUTS(cls, input_types",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/specific_tests.py",
        "start": 171,
        "end": 179,
        "startLoc": {
          "line": 171,
          "column": 19,
          "position": 1392
        },
        "endLoc": {
          "line": 179,
          "column": 12,
          "position": 1492
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/specific_tests.py",
        "start": 138,
        "end": 146,
        "startLoc": {
          "line": 138,
          "column": 19,
          "position": 1109
        },
        "endLoc": {
          "line": 146,
          "column": 7,
          "position": 1209
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": ", input1=None, input2=None):\n        if input1 is not None:\n            if not isinstance(input1, (torch.Tensor, float)):\n                return f\"Invalid type of input1: {type(input1)}\"\n        if input2 is not None:\n            if not isinstance(input2, (torch.Tensor, float)):\n                return f\"Invalid type of input2: {type(input2)}\"\n\n        if",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/specific_tests.py",
        "start": 179,
        "end": 187,
        "startLoc": {
          "line": 179,
          "column": 12,
          "position": 1493
        },
        "endLoc": {
          "line": 187,
          "column": 3,
          "position": 1586
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/specific_tests.py",
        "start": 146,
        "end": 154,
        "startLoc": {
          "line": 146,
          "column": 4,
          "position": 1207
        },
        "endLoc": {
          "line": 154,
          "column": 7,
          "position": 1300
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "(self, input1, input2):\n        if isinstance(input1, float) and isinstance(input2, float):\n            result = torch.ones([1, 512, 512, 3]) * input1 * input2\n        else:\n            result = input1 * input2\n        return (result,)\n\nclass",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/specific_tests.py",
        "start": 212,
        "end": 219,
        "startLoc": {
          "line": 212,
          "column": 19,
          "position": 1755
        },
        "endLoc": {
          "line": 219,
          "column": 6,
          "position": 1843
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/specific_tests.py",
        "start": 138,
        "end": 145,
        "startLoc": {
          "line": 138,
          "column": 19,
          "position": 1109
        },
        "endLoc": {
          "line": 145,
          "column": 2,
          "position": 1198
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ":\n    def __init__(self):\n        pass\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"a\": (\"INT\", {\"default\": 0, \"min\": -0xffffffffffffffff, \"max\": 0xffffffffffffffff, \"step\": 1}),\n                \"b\": (\"INT\", {\"default\": 0, \"min\": -0xffffffffffffffff, \"max\": 0xffffffffffffffff, \"step\": 1}),\n                \"operation\": ([\"==\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/conditions.py",
        "start": 4,
        "end": 14,
        "startLoc": {
          "line": 4,
          "column": 18,
          "position": 12
        },
        "endLoc": {
          "line": 14,
          "column": 5,
          "position": 129
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/util.py",
        "start": 198,
        "end": 208,
        "startLoc": {
          "line": 198,
          "column": 21,
          "position": 1221
        },
        "endLoc": {
          "line": 208,
          "column": 6,
          "position": 1338
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": "(self, a, b, operation):\n        if operation == \"==\":\n            return (a == b,)\n        elif operation == \"!=\":\n            return (a != b,)\n        elif operation == \"<\":\n            return (a < b,)\n        elif operation == \">\":\n            return (a > b,)\n        elif operation == \"<=\":\n            return (a <= b,)\n        elif operation == \">=\":\n            return (a >= b,)\n\nclass TestStringConditions",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/conditions.py",
        "start": 57,
        "end": 71,
        "startLoc": {
          "line": 57,
          "column": 16,
          "position": 515
        },
        "endLoc": {
          "line": 71,
          "column": 21,
          "position": 664
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/testing_nodes/testing-pack/conditions.py",
        "start": 23,
        "end": 38,
        "startLoc": {
          "line": 23,
          "column": 14,
          "position": 188
        },
        "endLoc": {
          "line": 38,
          "column": 20,
          "position": 338
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "def forward(self, x, noise_level=None, seed=None):\n        if noise_level is None:\n            noise_level = torch.randint(0, self.max_noise_level, (x.shape[0],), device=x.device).long()\n        else:\n            assert isinstance(noise_level, torch.Tensor)\n        z",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/upscaling.py",
        "start": 75,
        "end": 80,
        "startLoc": {
          "line": 75,
          "column": 5,
          "position": 828
        },
        "endLoc": {
          "line": 80,
          "column": 2,
          "position": 916
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/encoders/noise_aug_modules.py",
        "start": 26,
        "end": 31,
        "startLoc": {
          "line": 26,
          "column": 5,
          "position": 311
        },
        "endLoc": {
          "line": 31,
          "column": 2,
          "position": 399
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "def __init__(self, channels, use_conv, dims=2, out_channels=None, padding=1, dtype=None, device=None, operations=ops):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.dims = dims\n        stride",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 116,
        "end": 122,
        "startLoc": {
          "line": 116,
          "column": 5,
          "position": 1008
        },
        "endLoc": {
          "line": 122,
          "column": 7,
          "position": 1102
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 80,
        "end": 86,
        "startLoc": {
          "line": 80,
          "column": 5,
          "position": 609
        },
        "endLoc": {
          "line": 86,
          "column": 3,
          "position": 703
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": "get_resblock(\n                    merge_factor=merge_factor,\n                    merge_strategy=merge_strategy,\n                    video_kernel_size=video_kernel_size,\n                    ch=ch,\n                    time_embed_dim=time_embed_dim,\n                    dropout=dropout,\n                    out_channels=None,\n                    dims=dims,\n                    use_checkpoint=use_checkpoint,\n                    use_scale_shift_norm=use_scale_shift_norm,\n                    dtype=self.dtype,\n                    device=device,\n                    operations=operations\n                )]\n            self.middle_block = TimestepEmbedSequential",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 730,
        "end": 745,
        "startLoc": {
          "line": 730,
          "column": 17,
          "position": 5680
        },
        "endLoc": {
          "line": 745,
          "column": 24,
          "position": 5773
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 707,
        "end": 723,
        "startLoc": {
          "line": 707,
          "column": 13,
          "position": 5517
        },
        "endLoc": {
          "line": 723,
          "column": 5,
          "position": 5611
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": ")\n                if num_transformers > 0:\n                    if num_head_channels == -1:\n                        dim_head = ch // num_heads\n                    else:\n                        num_heads = ch // num_head_channels\n                        dim_head = num_head_channels\n                    if legacy:\n                        #num_heads = 1\n                        dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n                    if exists(disable_self_attentions):\n                        disabled_sa = disable_self_attentions[level]\n                    else:\n                        disabled_sa = False\n\n                    if not exists(num_attention_blocks) or i",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 770,
        "end": 785,
        "startLoc": {
          "line": 770,
          "column": 2,
          "position": 5986
        },
        "endLoc": {
          "line": 785,
          "column": 2,
          "position": 6113
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 644,
        "end": 659,
        "startLoc": {
          "line": 644,
          "column": 2,
          "position": 5014
        },
        "endLoc": {
          "line": 659,
          "column": 3,
          "position": 5141
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "self.down = nn.ModuleList()\n        for i_level in range(self.num_resolutions):\n            block = nn.ModuleList()\n            attn = nn.ModuleList()\n            block_in = ch*in_ch_mult[i_level]\n            block_out = ch*ch_mult[i_level]\n            for i_block in range(self.num_res_blocks):\n                block.append(ResnetBlock(in_channels=block_in,\n                                         out_channels=block_out,\n                                         temb_channels=self.temb_ch,\n                                         dropout=dropout,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/model.py",
        "start": 538,
        "end": 548,
        "startLoc": {
          "line": 538,
          "column": 9,
          "position": 5527
        },
        "endLoc": {
          "line": 548,
          "column": 2,
          "position": 5645
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/model.py",
        "start": 387,
        "end": 397,
        "startLoc": {
          "line": 387,
          "column": 9,
          "position": 3978
        },
        "endLoc": {
          "line": 397,
          "column": 2,
          "position": 4096
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "[:, None].float() * freqs[None]\n        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n        if dim % 2:\n            embedding = torch.cat(\n                [embedding, torch.zeros_like(embedding[:, :1])], dim=-1\n            )\n        return",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/genmo/joint_model/layers.py",
        "start": 55,
        "end": 61,
        "startLoc": {
          "line": 55,
          "column": 2,
          "position": 454
        },
        "endLoc": {
          "line": 61,
          "column": 7,
          "position": 555
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/util.py",
        "start": 243,
        "end": 247,
        "startLoc": {
          "line": 243,
          "column": 10,
          "position": 2085
        },
        "endLoc": {
          "line": 247,
          "column": 5,
          "position": 2182
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": ", mode=\"reflect\", rescale=False):\n        dtype = x.dtype\n        h = self.wavelets.to(device=x.device)\n\n        n = h.shape[0]\n        g = x.shape[1]\n        hl = h.flip(0).reshape(1, 1, -1).repeat(g, 1, 1)\n        hh = (h * ((-1) ** self._arange.to(device=x.device))).reshape(1, 1, -1).repeat(g, 1, 1)\n        hh = hh.to(dtype=dtype)\n        hl = hl.to(dtype=dtype)\n\n        # Handles temporal axis.",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/cosmos_tokenizer/patching.py",
        "start": 123,
        "end": 134,
        "startLoc": {
          "line": 123,
          "column": 8,
          "position": 1074
        },
        "endLoc": {
          "line": 134,
          "column": 25,
          "position": 1260
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/cosmos_tokenizer/patching.py",
        "start": 73,
        "end": 84,
        "startLoc": {
          "line": 73,
          "column": 2,
          "position": 366
        },
        "endLoc": {
          "line": 84,
          "column": 2,
          "position": 552
        }
      }
    },
    {
      "format": "python",
      "lines": 19,
      "fragment": "def __init__(self, patch_size=1, patch_method=\"haar\"):\n        super().__init__()\n        self.patch_size = patch_size\n        self.patch_method = patch_method\n        self.register_buffer(\n            \"wavelets\", _WAVELETS[patch_method], persistent=_PERSISTENT\n        )\n        self.range = range(int(torch.log2(torch.tensor(self.patch_size)).item()))\n        self.register_buffer(\n            \"_arange\",\n            torch.arange(_WAVELETS[patch_method].shape[0]),\n            persistent=_PERSISTENT,\n        )\n        for param in self.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        if self.patch_method == \"haar\":\n            return self._ihaar",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/cosmos_tokenizer/patching.py",
        "start": 191,
        "end": 209,
        "startLoc": {
          "line": 191,
          "column": 5,
          "position": 2302
        },
        "endLoc": {
          "line": 209,
          "column": 7,
          "position": 2490
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/cosmos_tokenizer/patching.py",
        "start": 49,
        "end": 67,
        "startLoc": {
          "line": 49,
          "column": 5,
          "position": 123
        },
        "endLoc": {
          "line": 67,
          "column": 6,
          "position": 311
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ")\n        hh = (h * ((-1) ** self._arange.to(device=x.device))).reshape(1, 1, -1).repeat(g, 1, 1)\n        hh = hh.to(dtype=dtype)\n        hl = hl.to(dtype=dtype)\n\n        xll",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/cosmos_tokenizer/patching.py",
        "start": 221,
        "end": 226,
        "startLoc": {
          "line": 221,
          "column": 2,
          "position": 2656
        },
        "endLoc": {
          "line": 226,
          "column": 4,
          "position": 2744
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/cosmos_tokenizer/patching.py",
        "start": 79,
        "end": 84,
        "startLoc": {
          "line": 79,
          "column": 2,
          "position": 464
        },
        "endLoc": {
          "line": 84,
          "column": 2,
          "position": 552
        }
      }
    },
    {
      "format": "python",
      "lines": 21,
      "fragment": "torch.nn.utils.parametrizations.weight_norm(\n                    ops.Conv1d(\n                        channels,\n                        channels,\n                        kernel_size,\n                        1,\n                        dilation=1,\n                        padding=get_padding(kernel_size, 1),\n                    )\n                ),\n                torch.nn.utils.parametrizations.weight_norm(\n                    ops.Conv1d(\n                        channels,\n                        channels,\n                        kernel_size,\n                        1,\n                        dilation=1,\n                        padding=get_padding(kernel_size, 1),\n                    )\n                ),\n            ]",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/vae/music_vocoder.py",
        "start": 303,
        "end": 323,
        "startLoc": {
          "line": 303,
          "column": 17,
          "position": 2567
        },
        "endLoc": {
          "line": 323,
          "column": 2,
          "position": 2685
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/vae/music_vocoder.py",
        "start": 293,
        "end": 313,
        "startLoc": {
          "line": 293,
          "column": 17,
          "position": 2508
        },
        "endLoc": {
          "line": 313,
          "column": 6,
          "position": 2626
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "(nn.Module):\n    def __init__(\n        self,\n        in_channels: int,\n        latent_channels: int,\n        attention_head_dim: int = 32,\n        block_type: str or tuple = \"ResBlock\",\n        block_out_channels: tuple = (128, 256, 512, 512, 1024, 1024),\n        layers_per_block: tuple = (2, 2, 2, 2, 2, 2),\n        qkv_multiscales: tuple = ((), (), (), (5,), (5,), (5,)),\n        norm_type",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/vae/autoencoder_dc.py",
        "start": 489,
        "end": 499,
        "startLoc": {
          "line": 489,
          "column": 8,
          "position": 4714
        },
        "endLoc": {
          "line": 499,
          "column": 10,
          "position": 4868
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/vae/autoencoder_dc.py",
        "start": 403,
        "end": 413,
        "startLoc": {
          "line": 403,
          "column": 8,
          "position": 3908
        },
        "endLoc": {
          "line": 413,
          "column": 22,
          "position": 4062
        }
      }
    },
    {
      "format": "json",
      "lines": 103,
      "fragment": "\"additional_special_tokens\": [\n    \"<extra_id_0>\",\n    \"<extra_id_1>\",\n    \"<extra_id_2>\",\n    \"<extra_id_3>\",\n    \"<extra_id_4>\",\n    \"<extra_id_5>\",\n    \"<extra_id_6>\",\n    \"<extra_id_7>\",\n    \"<extra_id_8>\",\n    \"<extra_id_9>\",\n    \"<extra_id_10>\",\n    \"<extra_id_11>\",\n    \"<extra_id_12>\",\n    \"<extra_id_13>\",\n    \"<extra_id_14>\",\n    \"<extra_id_15>\",\n    \"<extra_id_16>\",\n    \"<extra_id_17>\",\n    \"<extra_id_18>\",\n    \"<extra_id_19>\",\n    \"<extra_id_20>\",\n    \"<extra_id_21>\",\n    \"<extra_id_22>\",\n    \"<extra_id_23>\",\n    \"<extra_id_24>\",\n    \"<extra_id_25>\",\n    \"<extra_id_26>\",\n    \"<extra_id_27>\",\n    \"<extra_id_28>\",\n    \"<extra_id_29>\",\n    \"<extra_id_30>\",\n    \"<extra_id_31>\",\n    \"<extra_id_32>\",\n    \"<extra_id_33>\",\n    \"<extra_id_34>\",\n    \"<extra_id_35>\",\n    \"<extra_id_36>\",\n    \"<extra_id_37>\",\n    \"<extra_id_38>\",\n    \"<extra_id_39>\",\n    \"<extra_id_40>\",\n    \"<extra_id_41>\",\n    \"<extra_id_42>\",\n    \"<extra_id_43>\",\n    \"<extra_id_44>\",\n    \"<extra_id_45>\",\n    \"<extra_id_46>\",\n    \"<extra_id_47>\",\n    \"<extra_id_48>\",\n    \"<extra_id_49>\",\n    \"<extra_id_50>\",\n    \"<extra_id_51>\",\n    \"<extra_id_52>\",\n    \"<extra_id_53>\",\n    \"<extra_id_54>\",\n    \"<extra_id_55>\",\n    \"<extra_id_56>\",\n    \"<extra_id_57>\",\n    \"<extra_id_58>\",\n    \"<extra_id_59>\",\n    \"<extra_id_60>\",\n    \"<extra_id_61>\",\n    \"<extra_id_62>\",\n    \"<extra_id_63>\",\n    \"<extra_id_64>\",\n    \"<extra_id_65>\",\n    \"<extra_id_66>\",\n    \"<extra_id_67>\",\n    \"<extra_id_68>\",\n    \"<extra_id_69>\",\n    \"<extra_id_70>\",\n    \"<extra_id_71>\",\n    \"<extra_id_72>\",\n    \"<extra_id_73>\",\n    \"<extra_id_74>\",\n    \"<extra_id_75>\",\n    \"<extra_id_76>\",\n    \"<extra_id_77>\",\n    \"<extra_id_78>\",\n    \"<extra_id_79>\",\n    \"<extra_id_80>\",\n    \"<extra_id_81>\",\n    \"<extra_id_82>\",\n    \"<extra_id_83>\",\n    \"<extra_id_84>\",\n    \"<extra_id_85>\",\n    \"<extra_id_86>\",\n    \"<extra_id_87>\",\n    \"<extra_id_88>\",\n    \"<extra_id_89>\",\n    \"<extra_id_90>\",\n    \"<extra_id_91>\",\n    \"<extra_id_92>\",\n    \"<extra_id_93>\",\n    \"<extra_id_94>\",\n    \"<extra_id_95>\",\n    \"<extra_id_96>\",\n    \"<extra_id_97>\",\n    \"<extra_id_98>\",\n    \"<extra_id_99>\"\n  ],\n  \"eos_token\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5_tokenizer/special_tokens_map.json",
        "start": 2,
        "end": 104,
        "startLoc": {
          "line": 2,
          "column": 3,
          "position": 3
        },
        "endLoc": {
          "line": 104,
          "column": 12,
          "position": 412
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5_tokenizer/tokenizer_config.json",
        "start": 828,
        "end": 930,
        "startLoc": {
          "line": 828,
          "column": 3,
          "position": 5265
        },
        "endLoc": {
          "line": 930,
          "column": 31,
          "position": 5674
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "feat_cache is not None:\n            idx = feat_idx[0]\n            cache_x = x[:, :, -CACHE_T:, :, :].clone()\n            if cache_x.shape[2] < 2 and feat_cache[idx] is not None:\n                # cache last frame of last two chunk\n                cache_x = torch.cat([\n                    feat_cache[idx][:, :, -1, :, :].unsqueeze(2).to(\n                        cache_x.device), cache_x\n                ],\n                                    dim=2)\n            x = self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 306,
        "end": 316,
        "startLoc": {
          "line": 306,
          "column": 2,
          "position": 3433
        },
        "endLoc": {
          "line": 316,
          "column": 5,
          "position": 3576
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 203,
        "end": 213,
        "startLoc": {
          "line": 203,
          "column": 2,
          "position": 2426
        },
        "endLoc": {
          "line": 213,
          "column": 6,
          "position": 2569
        }
      }
    },
    {
      "format": "python",
      "lines": 20,
      "fragment": ":\n            if isinstance(layer, CausalConv3d) and feat_cache is not None:\n                idx = feat_idx[0]\n                cache_x = x[:, :, -CACHE_T:, :, :].clone()\n                if cache_x.shape[2] < 2 and feat_cache[idx] is not None:\n                    # cache last frame of last two chunk\n                    cache_x = torch.cat([\n                        feat_cache[idx][:, :, -1, :, :].unsqueeze(2).to(\n                            cache_x.device), cache_x\n                    ],\n                                        dim=2)\n                x = layer(x, feat_cache[idx])\n                feat_cache[idx] = cache_x\n                feat_idx[0] += 1\n            else:\n                x = layer(x)\n        return x\n\n\nclass",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 337,
        "end": 356,
        "startLoc": {
          "line": 337,
          "column": 5,
          "position": 3765
        },
        "endLoc": {
          "line": 356,
          "column": 6,
          "position": 3975
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 202,
        "end": 218,
        "startLoc": {
          "line": 202,
          "column": 9,
          "position": 2411
        },
        "endLoc": {
          "line": 218,
          "column": 2,
          "position": 2619
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": "if feat_cache is not None:\n            idx = feat_idx[0]\n            cache_x = x[:, :, -CACHE_T:, :, :].clone()\n            if cache_x.shape[2] < 2 and feat_cache[idx] is not None:\n                # cache last frame of last two chunk\n                cache_x = torch.cat([\n                    feat_cache[idx][:, :, -1, :, :].unsqueeze(2).to(\n                        cache_x.device), cache_x\n                ],\n                                    dim=2)\n            x = self.conv1(x, feat_cache[idx])\n            feat_cache[idx] = cache_x\n            feat_idx[0] += 1\n        else:\n            x = self.conv1(x)\n\n        ## middle",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 412,
        "end": 428,
        "startLoc": {
          "line": 412,
          "column": 9,
          "position": 4585
        },
        "endLoc": {
          "line": 428,
          "column": 10,
          "position": 4781
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 306,
        "end": 322,
        "startLoc": {
          "line": 306,
          "column": 9,
          "position": 3431
        },
        "endLoc": {
          "line": 322,
          "column": 15,
          "position": 3627
        }
      }
    },
    {
      "format": "python",
      "lines": 26,
      "fragment": "feat_cache is not None:\n                x = layer(x, feat_cache, feat_idx)\n            else:\n                x = layer(x)\n\n        ## head\n        for layer in self.head:\n            if isinstance(layer, CausalConv3d) and feat_cache is not None:\n                idx = feat_idx[0]\n                cache_x = x[:, :, -CACHE_T:, :, :].clone()\n                if cache_x.shape[2] < 2 and feat_cache[idx] is not None:\n                    # cache last frame of last two chunk\n                    cache_x = torch.cat([\n                        feat_cache[idx][:, :, -1, :, :].unsqueeze(2).to(\n                            cache_x.device), cache_x\n                    ],\n                                        dim=2)\n                x = layer(x, feat_cache[idx])\n                feat_cache[idx] = cache_x\n                feat_idx[0] += 1\n            else:\n                x = layer(x)\n        return x\n\n\ndef",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 437,
        "end": 462,
        "startLoc": {
          "line": 437,
          "column": 2,
          "position": 4866
        },
        "endLoc": {
          "line": 462,
          "column": 4,
          "position": 5129
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 331,
        "end": 218,
        "startLoc": {
          "line": 331,
          "column": 2,
          "position": 3712
        },
        "endLoc": {
          "line": 218,
          "column": 2,
          "position": 2619
        }
      }
    },
    {
      "format": "python",
      "lines": 18,
      "fragment": "(nn.Module):\n\n    def __init__(self,\n                 dim=128,\n                 z_dim=4,\n                 dim_mult=[1, 2, 4, 4],\n                 num_res_blocks=2,\n                 attn_scales=[],\n                 temperal_downsample=[True, True, False],\n                 dropout=0.0):\n        super().__init__()\n        self.dim = dim\n        self.z_dim = z_dim\n        self.dim_mult = dim_mult\n        self.num_res_blocks = num_res_blocks\n        self.attn_scales = attn_scales\n        self.temperal_downsample = temperal_downsample\n        self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 470,
        "end": 487,
        "startLoc": {
          "line": 470,
          "column": 7,
          "position": 5187
        },
        "endLoc": {
          "line": 487,
          "column": 5,
          "position": 5330
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/vae.py",
        "start": 252,
        "end": 270,
        "startLoc": {
          "line": 252,
          "column": 10,
          "position": 2906
        },
        "endLoc": {
          "line": 270,
          "column": 13,
          "position": 3050
        }
      }
    },
    {
      "format": "python",
      "lines": 18,
      "fragment": ",\n                 patch_size=(1, 2, 2),\n                 text_len=512,\n                 in_dim=16,\n                 dim=2048,\n                 ffn_dim=8192,\n                 freq_dim=256,\n                 text_dim=4096,\n                 out_dim=16,\n                 num_heads=16,\n                 num_layers=32,\n                 window_size=(-1, -1),\n                 qk_norm=True,\n                 cross_attn_norm=True,\n                 eps=1e-6,\n                 flf_pos_embed_token_number=None,\n                 image_model=None,\n                 vace_layers",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 596,
        "end": 613,
        "startLoc": {
          "line": 596,
          "column": 7,
          "position": 6268
        },
        "endLoc": {
          "line": 613,
          "column": 12,
          "position": 6384
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 362,
        "end": 379,
        "startLoc": {
          "line": 362,
          "column": 6,
          "position": 4055
        },
        "endLoc": {
          "line": 379,
          "column": 7,
          "position": 4171
        }
      }
    },
    {
      "format": "python",
      "lines": 21,
      "fragment": "# embeddings\n        x = self.patch_embedding(x.float()).to(x.dtype)\n        grid_sizes = x.shape[2:]\n        x = x.flatten(2).transpose(1, 2)\n\n        # time embeddings\n        e = self.time_embedding(\n            sinusoidal_embedding_1d(self.freq_dim, t).to(dtype=x[0].dtype))\n        e0 = self.time_projection(e).unflatten(1, (6, self.dim))\n\n        # context\n        context = self.text_embedding(context)\n\n        context_img_len = None\n        if clip_fea is not None:\n            if self.img_emb is not None:\n                context_clip = self.img_emb(clip_fea)  # bs x 257 x dim\n                context = torch.concat([context_clip, context], dim=1)\n            context_img_len = clip_fea.shape[-2]\n\n        orig_shape",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 651,
        "end": 671,
        "startLoc": {
          "line": 651,
          "column": 9,
          "position": 6830
        },
        "endLoc": {
          "line": 671,
          "column": 11,
          "position": 7054
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 502,
        "end": 522,
        "startLoc": {
          "line": 502,
          "column": 9,
          "position": 4960
        },
        "endLoc": {
          "line": 522,
          "column": 16,
          "position": 5184
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "patches_replace = transformer_options.get(\"patches_replace\", {})\n        blocks_replace = patches_replace.get(\"dit\", {})\n        for i, block in enumerate(self.blocks):\n            if (\"double_block\", i) in blocks_replace:\n                def block_wrap(args):\n                    out = {}\n                    out[\"img\"] = block(args[\"img\"], context=args[\"txt\"], e=args[\"vec\"], freqs=args[\"pe\"], context_img_len=context_img_len)\n                    return out\n                out = blocks_replace[(\"double_block\", i)]({\"img\": x, \"txt\": context, \"vec\": e0, \"pe\": freqs}, {\"original_block\": block_wrap})\n                x = out[\"img\"]\n            else:\n                x = block(x, e=e0, freqs=freqs, context=context, context_img_len=context_img_len)\n\n            ii",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 680,
        "end": 693,
        "startLoc": {
          "line": 680,
          "column": 9,
          "position": 7175
        },
        "endLoc": {
          "line": 693,
          "column": 3,
          "position": 7401
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 522,
        "end": 535,
        "startLoc": {
          "line": 522,
          "column": 9,
          "position": 5184
        },
        "endLoc": {
          "line": 535,
          "column": 7,
          "position": 5410
        }
      }
    },
    {
      "format": "python",
      "lines": 18,
      "fragment": ",\n                 patch_size=(1, 2, 2),\n                 text_len=512,\n                 in_dim=16,\n                 dim=2048,\n                 ffn_dim=8192,\n                 freq_dim=256,\n                 text_dim=4096,\n                 out_dim=16,\n                 num_heads=16,\n                 num_layers=32,\n                 window_size=(-1, -1),\n                 qk_norm=True,\n                 cross_attn_norm=True,\n                 eps=1e-6,\n                 flf_pos_embed_token_number=None,\n                 image_model=None,\n                 in_dim_control_adapter",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 712,
        "end": 729,
        "startLoc": {
          "line": 712,
          "column": 9,
          "position": 7581
        },
        "endLoc": {
          "line": 729,
          "column": 23,
          "position": 7697
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 362,
        "end": 379,
        "startLoc": {
          "line": 362,
          "column": 6,
          "position": 4055
        },
        "endLoc": {
          "line": 379,
          "column": 7,
          "position": 4171
        }
      }
    },
    {
      "format": "python",
      "lines": 37,
      "fragment": "grid_sizes = x.shape[2:]\n        x = x.flatten(2).transpose(1, 2)\n\n        # time embeddings\n        e = self.time_embedding(\n            sinusoidal_embedding_1d(self.freq_dim, t).to(dtype=x[0].dtype))\n        e0 = self.time_projection(e).unflatten(1, (6, self.dim))\n\n        # context\n        context = self.text_embedding(context)\n\n        context_img_len = None\n        if clip_fea is not None:\n            if self.img_emb is not None:\n                context_clip = self.img_emb(clip_fea)  # bs x 257 x dim\n                context = torch.concat([context_clip, context], dim=1)\n            context_img_len = clip_fea.shape[-2]\n\n        patches_replace = transformer_options.get(\"patches_replace\", {})\n        blocks_replace = patches_replace.get(\"dit\", {})\n        for i, block in enumerate(self.blocks):\n            if (\"double_block\", i) in blocks_replace:\n                def block_wrap(args):\n                    out = {}\n                    out[\"img\"] = block(args[\"img\"], context=args[\"txt\"], e=args[\"vec\"], freqs=args[\"pe\"], context_img_len=context_img_len)\n                    return out\n                out = blocks_replace[(\"double_block\", i)]({\"img\": x, \"txt\": context, \"vec\": e0, \"pe\": freqs}, {\"original_block\": block_wrap})\n                x = out[\"img\"]\n            else:\n                x = block(x, e=e0, freqs=freqs, context=context, context_img_len=context_img_len)\n\n        # head\n        x = self.head(x, e)\n\n        # unpatchify\n        x = self.unpatchify(x, grid_sizes)\n        return x",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 757,
        "end": 793,
        "startLoc": {
          "line": 757,
          "column": 9,
          "position": 8036
        },
        "endLoc": {
          "line": 793,
          "column": 2,
          "position": 8499
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 504,
        "end": 540,
        "startLoc": {
          "line": 504,
          "column": 9,
          "position": 4986
        },
        "endLoc": {
          "line": 540,
          "column": 2,
          "position": 5449
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "(nn.Module):\n    \"\"\"\n    The final layer of PixArt.\n    \"\"\"\n    def __init__(self, hidden_size, patch_size, out_channels, dtype=None, device=None, operations=None):\n        super().__init__()\n        self.norm_final = operations.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n        self.linear = operations.Linear(hidden_size, patch_size * patch_size * out_channels, bias=True, dtype=dtype, device=device)\n        self.scale_shift_table",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py",
        "start": 198,
        "end": 206,
        "startLoc": {
          "line": 198,
          "column": 14,
          "position": 2207
        },
        "endLoc": {
          "line": 206,
          "column": 18,
          "position": 2338
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py",
        "start": 179,
        "end": 187,
        "startLoc": {
          "line": 179,
          "column": 11,
          "position": 1943
        },
        "endLoc": {
          "line": 187,
          "column": 17,
          "position": 2074
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", bias=True, dtype=dtype, device=device)\n        self.adaLN_modulation = nn.Sequential(\n            nn.SiLU(),\n            operations.Linear(hidden_size, 2 * hidden_size, bias=True, dtype=dtype, device=device)\n        )\n    def forward(self, x, t",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py",
        "start": 242,
        "end": 247,
        "startLoc": {
          "line": 242,
          "column": 20,
          "position": 2853
        },
        "endLoc": {
          "line": 247,
          "column": 2,
          "position": 2934
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py",
        "start": 186,
        "end": 192,
        "startLoc": {
          "line": 186,
          "column": 13,
          "position": 2054
        },
        "endLoc": {
          "line": 192,
          "column": 2,
          "position": 2136
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "(nn.Module):\n    \"\"\"\n    Embeds class labels into vector representations. Also handles label dropout for classifier-free guidance.\n    \"\"\"\n    def __init__(self, in_channels, hidden_size, uncond_prob, act_layer=nn.GELU(approximate='tanh'), token_num=120, dtype=None, device=None, operations=None):\n        super().__init__()\n        self.proj",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py",
        "start": 347,
        "end": 353,
        "startLoc": {
          "line": 347,
          "column": 24,
          "position": 4072
        },
        "endLoc": {
          "line": 353,
          "column": 5,
          "position": 4144
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py",
        "start": 313,
        "end": 319,
        "startLoc": {
          "line": 313,
          "column": 16,
          "position": 3682
        },
        "endLoc": {
          "line": 319,
          "column": 7,
          "position": 3754
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": ",\n        )\n\n        self.merge_strategy = merge_strategy\n        if self.merge_strategy == \"fixed\":\n            self.register_buffer(\"mix_factor\", torch.Tensor([alpha]))\n        elif self.merge_strategy == \"learned\":\n            self.register_parameter(\n                \"mix_factor\", torch.nn.Parameter(torch.Tensor([alpha]))\n            )\n        else:\n            raise ValueError(f\"unknown merge strategy {self.merge_strategy}\")\n\n    def forward",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/temporal_ae.py",
        "start": 136,
        "end": 149,
        "startLoc": {
          "line": 136,
          "column": 2,
          "position": 1149
        },
        "endLoc": {
          "line": 149,
          "column": 8,
          "position": 1252
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/temporal_ae.py",
        "start": 50,
        "end": 63,
        "startLoc": {
          "line": 50,
          "column": 5,
          "position": 337
        },
        "endLoc": {
          "line": 63,
          "column": 10,
          "position": 440
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "def __init__(self, final_hidden_size, c_emb_size, patch_size, out_channels, dtype=None, device=None, operations=None):\n        super().__init__()\n        self.norm_final = operations.LayerNorm(final_hidden_size, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n        self.linear = operations.Linear(final_hidden_size, patch_size * patch_size * out_channels, bias=True, dtype=dtype, device=device)\n        self.adaLN_modulation = nn.Sequential(\n            nn.SiLU(),\n            operations.Linear(c_emb_size, 2 * final_hidden_size, bias=True, dtype=dtype, device=device)\n        )\n\n    def forward(self, x, c",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/models.py",
        "start": 127,
        "end": 136,
        "startLoc": {
          "line": 127,
          "column": 5,
          "position": 1324
        },
        "endLoc": {
          "line": 136,
          "column": 2,
          "position": 1509
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py",
        "start": 220,
        "end": 228,
        "startLoc": {
          "line": 220,
          "column": 5,
          "position": 2497
        },
        "endLoc": {
          "line": 228,
          "column": 2,
          "position": 2681
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ", bias=True, dtype=dtype, device=device)\n        )\n\n    def forward(self, x, c):\n        shift, scale = self.adaLN_modulation(c).chunk(2, dim=1)\n        x = modulate(self.norm_final(x), shift, scale)\n        x = self.linear(x)\n        return x\n\n\nclass HunYuanDiT",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/models.py",
        "start": 133,
        "end": 143,
        "startLoc": {
          "line": 133,
          "column": 18,
          "position": 1477
        },
        "endLoc": {
          "line": 143,
          "column": 11,
          "position": 1580
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py",
        "start": 189,
        "end": 198,
        "startLoc": {
          "line": 189,
          "column": 12,
          "position": 2104
        },
        "endLoc": {
          "line": 198,
          "column": 14,
          "position": 2206
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "assert h * w == x.shape[1]\n\n        x = x.reshape(shape=(x.shape[0], h, w, p, p, c))\n        x = torch.einsum('nhwpqc->nchpwq', x)\n        imgs = x.reshape(shape=(x.shape[0], c, h * p, w * p))\n        return imgs",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/models.py",
        "start": 412,
        "end": 417,
        "startLoc": {
          "line": 412,
          "column": 9,
          "position": 3834
        },
        "endLoc": {
          "line": 417,
          "column": 5,
          "position": 3944
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/pixartms.py",
        "start": 251,
        "end": 256,
        "startLoc": {
          "line": 251,
          "column": 9,
          "position": 2949
        },
        "endLoc": {
          "line": 256,
          "column": 5,
          "position": 3064
        }
      }
    },
    {
      "format": "python",
      "lines": 35,
      "fragment": ",\n        text_states_dim=1024,\n        text_states_dim_t5=2048,\n        text_len=77,\n        text_len_t5=256,\n        qk_norm=True,  # See http://arxiv.org/abs/2302.05442 for details.\n        size_cond=False,\n        use_style_cond=False,\n        learn_sigma=True,\n        norm=\"layer\",\n        log_fn: callable = print,\n        attn_precision=None,\n        dtype=None,\n        device=None,\n        operations=None,\n        **kwargs,\n    ):\n        super().__init__()\n        self.log_fn = log_fn\n        self.depth = depth\n        self.learn_sigma = learn_sigma\n        self.in_channels = in_channels\n        self.out_channels = in_channels * 2 if learn_sigma else in_channels\n        self.patch_size = patch_size\n        self.num_heads = num_heads\n        self.hidden_size = hidden_size\n        self.text_states_dim = text_states_dim\n        self.text_states_dim_t5 = text_states_dim_t5\n        self.text_len = text_len\n        self.text_len_t5 = text_len_t5\n        self.size_cond = size_cond\n        self.use_style_cond = use_style_cond\n        self.norm = norm\n        self.dtype = dtype\n        self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/controlnet.py",
        "start": 55,
        "end": 89,
        "startLoc": {
          "line": 55,
          "column": 7,
          "position": 173
        },
        "endLoc": {
          "line": 89,
          "column": 5,
          "position": 441
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/models.py",
        "start": 180,
        "end": 214,
        "startLoc": {
          "line": 180,
          "column": 4,
          "position": 1677
        },
        "endLoc": {
          "line": 214,
          "column": 12,
          "position": 1962
        }
      }
    },
    {
      "format": "python",
      "lines": 26,
      "fragment": ")\n        self.t_embedder = TimestepEmbedder(\n            hidden_size, dtype=dtype, device=device, operations=operations\n        )\n        self.extra_embedder = nn.Sequential(\n            operations.Linear(\n                self.extra_in_dim, hidden_size * 4, dtype=dtype, device=device\n            ),\n            nn.SiLU(),\n            operations.Linear(\n                hidden_size * 4, hidden_size, bias=True, dtype=dtype, device=device\n            ),\n        )\n\n        # HUnYuanDiT Blocks\n        self.blocks = nn.ModuleList(\n            [\n                HunYuanDiTBlock(\n                    hidden_size=hidden_size,\n                    c_emb_size=hidden_size,\n                    num_heads=num_heads,\n                    mlp_ratio=mlp_ratio,\n                    text_states_dim=self.text_states_dim,\n                    qk_norm=qk_norm,\n                    norm_type=self.norm,\n                    skip=False",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/controlnet.py",
        "start": 153,
        "end": 178,
        "startLoc": {
          "line": 153,
          "column": 9,
          "position": 827
        },
        "endLoc": {
          "line": 178,
          "column": 6,
          "position": 1022
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/models.py",
        "start": 243,
        "end": 260,
        "startLoc": {
          "line": 243,
          "column": 11,
          "position": 2287
        },
        "endLoc": {
          "line": 260,
          "column": 6,
          "position": 2466
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "# 2,77,1024\n        text_states_t5 = encoder_hidden_states_t5  # 2,256,2048\n        text_states_mask = text_embedding_mask.bool()  # 2,77\n        text_states_t5_mask = text_embedding_mask_t5.bool()  # 2,256\n        b_t5, l_t5, c_t5 = text_states_t5.shape\n        text_states_t5 = self.mlp_t5(text_states_t5.view(-1, c_t5)).view(b_t5, l_t5, -1)\n\n        padding = comfy.ops.cast_to_input(self.text_embedding_padding, text_states)\n\n        text_states[:, -self.text_len :] = torch.where(\n            text_states_mask[:, -self.text_len :].unsqueeze(2),\n            text_states[:, -self.text_len :],\n            padding[: self.text_len],",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/controlnet.py",
        "start": 247,
        "end": 259,
        "startLoc": {
          "line": 247,
          "column": 3,
          "position": 1309
        },
        "endLoc": {
          "line": 259,
          "column": 2,
          "position": 1480
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/models.py",
        "start": 315,
        "end": 324,
        "startLoc": {
          "line": 315,
          "column": 22,
          "position": 2680
        },
        "endLoc": {
          "line": 324,
          "column": 2,
          "position": 2840
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ")\n        # TODO: eps should be 1 / 65530 if using fp16\n        self.q_norm = operations.LayerNorm(self.head_dim, elementwise_affine=True, eps=1e-6, dtype=dtype, device=device) if qk_norm else nn.Identity()\n        self.k_norm = operations.LayerNorm(self.head_dim, elementwise_affine=True, eps=1e-6, dtype=dtype, device=device) if qk_norm else nn.Identity()\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.out_proj = operations.Linear(dim",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/attn_layers.py",
        "start": 190,
        "end": 195,
        "startLoc": {
          "line": 190,
          "column": 7,
          "position": 1998
        },
        "endLoc": {
          "line": 195,
          "column": 4,
          "position": 2128
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hydit/attn_layers.py",
        "start": 125,
        "end": 131,
        "startLoc": {
          "line": 125,
          "column": 15,
          "position": 1238
        },
        "endLoc": {
          "line": 131,
          "column": 5,
          "position": 1369
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "])\n        img_ids = torch.zeros((t_len, h_len, w_len, 3), device=x.device, dtype=x.dtype)\n        img_ids[:, :, :, 0] = img_ids[:, :, :, 0] + torch.linspace(0, t_len - 1, steps=t_len, device=x.device, dtype=x.dtype).reshape(-1, 1, 1)\n        img_ids[:, :, :, 1] = img_ids[:, :, :, 1] + torch.linspace(0, h_len - 1, steps=h_len, device=x.device, dtype=x.dtype).reshape(1, -1, 1)\n        img_ids[:, :, :, 2] = img_ids[:, :, :, 2] + torch.linspace(0, w_len - 1, steps=w_len, device=x.device, dtype=x.dtype).reshape(1, 1, -1)\n        return",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 343,
        "end": 348,
        "startLoc": {
          "line": 343,
          "column": 2,
          "position": 4009
        },
        "endLoc": {
          "line": 348,
          "column": 7,
          "position": 4284
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/wan/model.py",
        "start": 554,
        "end": 560,
        "startLoc": {
          "line": 554,
          "column": 2,
          "position": 5724
        },
        "endLoc": {
          "line": 560,
          "column": 8,
          "position": 6000
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": "(nn.Module):\n    def __init__(\n        self,\n        *,\n        heads: int,\n        width=None,\n        qk_norm=False,\n        norm_layer=ops.LayerNorm\n    ):\n        super().__init__()\n        self.heads = heads\n        self.q_norm = norm_layer(width // heads, elementwise_affine=True, eps=1e-6) if qk_norm else nn.Identity()\n        self.k_norm = norm_layer(width // heads, elementwise_affine=True, eps=1e-6) if qk_norm else nn.Identity()\n\n    def",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/vae.py",
        "start": 346,
        "end": 360,
        "startLoc": {
          "line": 346,
          "column": 22,
          "position": 3147
        },
        "endLoc": {
          "line": 360,
          "column": 4,
          "position": 3298
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/vae.py",
        "start": 236,
        "end": 250,
        "startLoc": {
          "line": 236,
          "column": 27,
          "position": 1982
        },
        "endLoc": {
          "line": 250,
          "column": 5,
          "position": 2133
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ", attn_ch, dim=-1)\n\n        q = self.q_norm(q)\n        k = self.k_norm(k)\n\n        q, k, v = map(lambda t: rearrange(t, 'b n h d -> b h n d', h=self.heads), (q, k, v))\n        out = F",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/vae.py",
        "start": 364,
        "end": 370,
        "startLoc": {
          "line": 364,
          "column": 4,
          "position": 3381
        },
        "endLoc": {
          "line": 370,
          "column": 2,
          "position": 3468
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/vae.py",
        "start": 258,
        "end": 263,
        "startLoc": {
          "line": 258,
          "column": 3,
          "position": 2267
        },
        "endLoc": {
          "line": 263,
          "column": 5,
          "position": 2353
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "blocks_replace = patches_replace.get(\"dit\", {})\n        for i, block in enumerate(self.double_blocks):\n            if (\"double_block\", i) in blocks_replace:\n                def block_wrap(args):\n                    out = {}\n                    out[\"img\"], out[\"txt\"] = block(img=args[\"img\"],\n                                                   txt=args[\"txt\"],\n                                                   vec=args[\"vec\"],\n                                                   pe=args[\"pe\"],\n                                                   attn_mask=args.",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/model.py",
        "start": 85,
        "end": 94,
        "startLoc": {
          "line": 85,
          "column": 9,
          "position": 746
        },
        "endLoc": {
          "line": 94,
          "column": 2,
          "position": 866
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 282,
        "end": 287,
        "startLoc": {
          "line": 282,
          "column": 9,
          "position": 2992
        },
        "endLoc": {
          "line": 287,
          "column": 2,
          "position": 3108
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "), 1)\n\n        for i, block in enumerate(self.single_blocks):\n            if (\"single_block\", i) in blocks_replace:\n                def block_wrap(args):\n                    out = {}\n                    out[\"img\"] = block(args[\"img\"],\n                                       vec=args[\"vec\"],\n                                       pe=args[\"pe\"],\n                                       attn_mask=args.",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/model.py",
        "start": 112,
        "end": 121,
        "startLoc": {
          "line": 112,
          "column": 4,
          "position": 1017
        },
        "endLoc": {
          "line": 121,
          "column": 2,
          "position": 1112
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 303,
        "end": 309,
        "startLoc": {
          "line": 303,
          "column": 4,
          "position": 3355
        },
        "endLoc": {
          "line": 309,
          "column": 2,
          "position": 3447
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": "(nn.Module):\n    def __init__(\n        self,\n        dim: int,\n        num_attention_heads: int,\n        attention_head_dim: int,\n        num_routed_experts: int = 4,\n        num_activated_experts: int = 2,\n        dtype=None, device=None, operations=None\n    ):\n        super().__init__()\n        self.num_attention_heads = num_attention_heads\n        self.adaLN_modulation = nn.Sequential(\n            nn.SiLU(),\n            operations.Linear(dim, 12",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py",
        "start": 432,
        "end": 446,
        "startLoc": {
          "line": 432,
          "column": 29,
          "position": 4977
        },
        "endLoc": {
          "line": 446,
          "column": 3,
          "position": 5102
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py",
        "start": 360,
        "end": 374,
        "startLoc": {
          "line": 360,
          "column": 35,
          "position": 4231
        },
        "endLoc": {
          "line": 374,
          "column": 2,
          "position": 4356
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "= operations.LayerNorm(dim, eps = 1e-06, elementwise_affine = False, dtype=dtype, device=device)\n        self.attn1 = HiDreamAttention(\n            query_dim=dim,\n            heads=num_attention_heads,\n            dim_head=attention_head_dim,\n            processor = HiDreamAttnProcessor_flashattn(),\n            single = False",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py",
        "start": 453,
        "end": 459,
        "startLoc": {
          "line": 453,
          "column": 2,
          "position": 5182
        },
        "endLoc": {
          "line": 459,
          "column": 6,
          "position": 5260
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py",
        "start": 378,
        "end": 384,
        "startLoc": {
          "line": 378,
          "column": 2,
          "position": 4390
        },
        "endLoc": {
          "line": 384,
          "column": 5,
          "position": 4468
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": ",\n            dtype=dtype, device=device, operations=operations\n        )\n\n        # 3. Feed-forward\n        self.norm3_i = operations.LayerNorm(dim, eps = 1e-06, elementwise_affine = False, dtype=dtype, device=device)\n        if num_routed_experts > 0:\n            self.ff_i = MOEFeedForwardSwiGLU(\n                dim = dim,\n                hidden_dim = 4 * dim,\n                num_routed_experts = num_routed_experts,\n                num_activated_experts = num_activated_experts,\n                dtype=dtype, device=device, operations=operations\n            )\n        else:\n            self.ff_i = FeedForwardSwiGLU(dim = dim, hidden_dim = 4 * dim, dtype=dtype, device=device, operations=operations)\n        self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py",
        "start": 459,
        "end": 475,
        "startLoc": {
          "line": 459,
          "column": 6,
          "position": 5261
        },
        "endLoc": {
          "line": 475,
          "column": 5,
          "position": 5446
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py",
        "start": 384,
        "end": 401,
        "startLoc": {
          "line": 384,
          "column": 5,
          "position": 4469
        },
        "endLoc": {
          "line": 401,
          "column": 4,
          "position": 4655
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": "= FeedForwardSwiGLU(dim = dim, hidden_dim = 4 * dim, dtype=dtype, device=device, operations=operations)\n\n    def forward(\n        self,\n        image_tokens: torch.FloatTensor,\n        image_tokens_masks: Optional[torch.FloatTensor] = None,\n        text_tokens: Optional[torch.FloatTensor] = None,\n        adaln_input: Optional[torch.FloatTensor] = None,\n        rope: torch.FloatTensor = None,\n    ) -> torch.FloatTensor:\n        wtype = image_tokens.dtype\n        shift_msa_i, scale_msa_i, gate_msa_i, shift_mlp_i, scale_mlp_i, gate_mlp_i,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py",
        "start": 476,
        "end": 487,
        "startLoc": {
          "line": 476,
          "column": 2,
          "position": 5480
        },
        "endLoc": {
          "line": 487,
          "column": 2,
          "position": 5635
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py",
        "start": 399,
        "end": 411,
        "startLoc": {
          "line": 399,
          "column": 2,
          "position": 4616
        },
        "endLoc": {
          "line": 411,
          "column": 2,
          "position": 4773
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "(nn.Module):\n    \"\"\"\n    Transformer model for flow matching on sequences.\n    \"\"\"\n\n    def __init__(self, image_model=None, final_layer=True, dtype=None, device=None, operations=None, **kwargs):\n        super().__init__()\n        self.dtype = dtype\n        params = FluxParams",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 37,
        "end": 45,
        "startLoc": {
          "line": 37,
          "column": 5,
          "position": 179
        },
        "endLoc": {
          "line": 45,
          "column": 11,
          "position": 251
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 163,
        "end": 171,
        "startLoc": {
          "line": 163,
          "column": 13,
          "position": 1499
        },
        "endLoc": {
          "line": 171,
          "column": 19,
          "position": 1571
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "if params.hidden_size % params.num_heads != 0:\n            raise ValueError(\n                f\"Hidden size {params.hidden_size} must be divisible by num_heads {params.num_heads}\"\n            )\n        pe_dim = params.hidden_size // params.num_heads\n        if sum(params.axes_dim) != pe_dim:\n            raise ValueError(f\"Got {params.axes_dim} but expected positional dim {pe_dim}\")\n        self.hidden_size = params.hidden_size\n        self.num_heads = params.num_heads\n        self.pe_embedder = EmbedND(dim=pe_dim, theta=params.theta, axes_dim=params.axes_dim)\n        self.img_in = operations",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 50,
        "end": 60,
        "startLoc": {
          "line": 50,
          "column": 9,
          "position": 324
        },
        "endLoc": {
          "line": 60,
          "column": 11,
          "position": 450
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 176,
        "end": 187,
        "startLoc": {
          "line": 176,
          "column": 9,
          "position": 1620
        },
        "endLoc": {
          "line": 187,
          "column": 6,
          "position": 1747
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ")\n        self.time_in = MLPEmbedder(in_dim=256, hidden_dim=self.hidden_size, dtype=dtype, device=device, operations=operations)\n        self.vector_in = MLPEmbedder(params.vec_in_dim, self.hidden_size, dtype=dtype, device=device, operations=operations)\n        self.guidance_in = (\n            MLPEmbedder(in_dim=256, hidden_dim=self.hidden_size, dtype=dtype, device=device, operations=operations) if params.guidance_embed else nn.Identity()\n        )\n        self.txt_in = operations",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 60,
        "end": 66,
        "startLoc": {
          "line": 60,
          "column": 7,
          "position": 477
        },
        "endLoc": {
          "line": 66,
          "column": 11,
          "position": 612
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 187,
        "end": 194,
        "startLoc": {
          "line": 187,
          "column": 11,
          "position": 1795
        },
        "endLoc": {
          "line": 194,
          "column": 13,
          "position": 1931
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": ",\n                    dtype=dtype, device=device, operations=operations\n                )\n                for _ in range(params.depth)\n            ]\n        )\n\n        self.single_blocks = nn.ModuleList(\n            [\n                SingleStreamBlock(self.hidden_size, self.num_heads, mlp_ratio=params.mlp_ratio, dtype=dtype, device=device, operations=operations)\n                for _ in range(params.depth_single_blocks)\n            ]\n        )\n\n        if final_layer:\n            self.final_layer = LastLayer(self.hidden_size, 1",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 74,
        "end": 89,
        "startLoc": {
          "line": 74,
          "column": 9,
          "position": 682
        },
        "endLoc": {
          "line": 89,
          "column": 2,
          "position": 814
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 203,
        "end": 218,
        "startLoc": {
          "line": 203,
          "column": 5,
          "position": 2018
        },
        "endLoc": {
          "line": 218,
          "column": 5,
          "position": 2150
        }
      }
    },
    {
      "format": "python",
      "lines": 30,
      "fragment": "= None\n\n        blocks_replace = patches_replace.get(\"dit\", {})\n        for i, block in enumerate(self.double_blocks):\n            if (\"double_block\", i) in blocks_replace:\n                def block_wrap(args):\n                    out = {}\n                    out[\"img\"], out[\"txt\"] = block(img=args[\"img\"],\n                                                   txt=args[\"txt\"],\n                                                   vec=args[\"vec\"],\n                                                   pe=args[\"pe\"],\n                                                   attn_mask=args.get(\"attn_mask\"))\n                    return out\n\n                out = blocks_replace[(\"double_block\", i)]({\"img\": img,\n                                                           \"txt\": txt,\n                                                           \"vec\": vec,\n                                                           \"pe\": pe,\n                                                           \"attn_mask\": attn_mask},\n                                                          {\"original_block\": block_wrap})\n                txt = out[\"txt\"]\n                img = out[\"img\"]\n            else:\n                img, txt = block(img=img,\n                                 txt=txt,\n                                 vec=vec,\n                                 pe=pe,\n                                 attn_mask=attn_mask)\n\n            if",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 126,
        "end": 155,
        "startLoc": {
          "line": 126,
          "column": 2,
          "position": 1219
        },
        "endLoc": {
          "line": 155,
          "column": 3,
          "position": 1483
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 280,
        "end": 112,
        "startLoc": {
          "line": 280,
          "column": 2,
          "position": 2986
        },
        "endLoc": {
          "line": 112,
          "column": 4,
          "position": 1004
        }
      }
    },
    {
      "format": "python",
      "lines": 22,
      "fragment": "img = torch.cat((txt, img), 1)\n\n        for i, block in enumerate(self.single_blocks):\n            if (\"single_block\", i) in blocks_replace:\n                def block_wrap(args):\n                    out = {}\n                    out[\"img\"] = block(args[\"img\"],\n                                       vec=args[\"vec\"],\n                                       pe=args[\"pe\"],\n                                       attn_mask=args.get(\"attn_mask\"))\n                    return out\n\n                out = blocks_replace[(\"single_block\", i)]({\"img\": img,\n                                                           \"vec\": vec,\n                                                           \"pe\": pe,\n                                                           \"attn_mask\": attn_mask},\n                                                          {\"original_block\": block_wrap})\n                img = out[\"img\"]\n            else:\n                img = block(img, vec=vec, pe=pe, attn_mask=attn_mask)\n\n            if",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 162,
        "end": 183,
        "startLoc": {
          "line": 162,
          "column": 9,
          "position": 1552
        },
        "endLoc": {
          "line": 183,
          "column": 3,
          "position": 1767
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/model.py",
        "start": 112,
        "end": 133,
        "startLoc": {
          "line": 112,
          "column": 9,
          "position": 1004
        },
        "endLoc": {
          "line": 133,
          "column": 4,
          "position": 1219
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "Tensor:\n        n_axes = ids.shape[-1]\n        emb = torch.cat(\n            [rope(ids[..., i], self.axes_dim[i], self.theta) for i in range(n_axes)],\n            dim=-3,\n        )\n\n        return emb.unsqueeze(1",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 19,
        "end": 26,
        "startLoc": {
          "line": 19,
          "column": 2,
          "position": 148
        },
        "endLoc": {
          "line": 26,
          "column": 2,
          "position": 233
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hidream/model.py",
        "start": 26,
        "end": 32,
        "startLoc": {
          "line": 26,
          "column": 2,
          "position": 219
        },
        "endLoc": {
          "line": 32,
          "column": 2,
          "position": 303
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ")\n\n    args = t[:, None].float() * freqs[None]\n    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n    if dim % 2:\n        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n    if",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 40,
        "end": 46,
        "startLoc": {
          "line": 40,
          "column": 5,
          "position": 342
        },
        "endLoc": {
          "line": 46,
          "column": 3,
          "position": 448
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/genmo/joint_model/layers.py",
        "start": 54,
        "end": 247,
        "startLoc": {
          "line": 54,
          "column": 2,
          "position": 446
        },
        "endLoc": {
          "line": 247,
          "column": 5,
          "position": 2182
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "= nn.Sequential(\n            operations.Linear(hidden_size, mlp_hidden_dim, bias=True, dtype=dtype, device=device),\n            nn.GELU(approximate=\"tanh\"),\n            operations.Linear(mlp_hidden_dim, hidden_size, bias=True, dtype=dtype, device=device),\n        )\n        self.flipped_img_txt",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 155,
        "end": 160,
        "startLoc": {
          "line": 155,
          "column": 2,
          "position": 2056
        },
        "endLoc": {
          "line": 160,
          "column": 16,
          "position": 2134
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 144,
        "end": 150,
        "startLoc": {
          "line": 144,
          "column": 2,
          "position": 1831
        },
        "endLoc": {
          "line": 150,
          "column": 8,
          "position": 1910
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ", dtype=None, device=None, operations=None):\n        super().__init__()\n        self.norm_final = operations.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n        self.linear = operations.Linear(hidden_size, patch_size * patch_size * out_channels, bias=True, dtype=dtype, device=device)\n        self.adaLN_modulation = nn.Sequential(nn.SiLU(), operations.Linear(hidden_size, 2 * hidden_size, bias=True, dtype=dtype, device=device))\n\n    def forward(self, x:",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 265,
        "end": 271,
        "startLoc": {
          "line": 265,
          "column": 4,
          "position": 3707
        },
        "endLoc": {
          "line": 271,
          "column": 2,
          "position": 3868
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/pixart/blocks.py",
        "start": 183,
        "end": 192,
        "startLoc": {
          "line": 183,
          "column": 13,
          "position": 1968
        },
        "endLoc": {
          "line": 192,
          "column": 2,
          "position": 2134
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ", dtype=dtype, device=device),\n            nn.SiLU(),\n            operations.Conv2d(16, 16, 3, padding=1, dtype=dtype, device=device),\n            nn.SiLU(),\n            operations.Conv2d(16, 16, 3, padding=1, stride=2, dtype=dtype, device=device),\n            nn.SiLU(),\n            operations.Conv2d(16, 16, 3, padding=1, dtype=dtype, device=device),\n            nn.SiLU(),\n            operations.Conv2d(16, 16, 3, padding=1, stride=2, dtype=dtype, device=device),\n            nn.SiLU(),\n            operations.Conv2d(16, 16, 1",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/controlnet.py",
        "start": 24,
        "end": 34,
        "startLoc": {
          "line": 24,
          "column": 2,
          "position": 252
        },
        "endLoc": {
          "line": 34,
          "column": 2,
          "position": 446
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/controlnet.py",
        "start": 20,
        "end": 26,
        "startLoc": {
          "line": 20,
          "column": 2,
          "position": 171
        },
        "endLoc": {
          "line": 26,
          "column": 2,
          "position": 284
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", dtype=dtype, device=device),\n            nn.SiLU(),\n            operations.Conv2d(16, 16, 1, dtype=dtype, device=device),\n            nn.SiLU(),\n            operations.Conv2d(16, 16, 3, padding=1, dtype=dtype, device=device)\n        )",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/controlnet.py",
        "start": 32,
        "end": 37,
        "startLoc": {
          "line": 32,
          "column": 2,
          "position": 414
        },
        "endLoc": {
          "line": 37,
          "column": 2,
          "position": 498
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/controlnet.py",
        "start": 18,
        "end": 22,
        "startLoc": {
          "line": 18,
          "column": 2,
          "position": 138
        },
        "endLoc": {
          "line": 22,
          "column": 2,
          "position": 220
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": "1, dtype=dtype, device=device),\n                    nn.SiLU(),\n                    operations.Conv2d(16, 16, 3, padding=1, dtype=dtype, device=device),\n                    nn.SiLU(),\n                    operations.Conv2d(16, 16, 3, padding=1, stride=2, dtype=dtype, device=device),\n                    nn.SiLU(),\n                    operations.Conv2d(16, 16, 3, padding=1, dtype=dtype, device=device),\n                    nn.SiLU(),\n                    operations.Conv2d(16, 16, 3, padding=1, stride=2, dtype=dtype, device=device),\n                    nn.SiLU(),\n                    operations.Conv2d(16, 16, 3, padding=1, dtype=dtype, device=device),\n                    nn.SiLU(),\n                    operations.Conv2d(16, 16, 3, padding=1, stride=2, dtype=dtype, device=device),\n                    nn.SiLU(),\n                    operations.Conv2d(16, 16, 3, padding=1, dtype=dtype, device=device)\n                )",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/controlnet.py",
        "start": 92,
        "end": 107,
        "startLoc": {
          "line": 92,
          "column": 2,
          "position": 1156
        },
        "endLoc": {
          "line": 107,
          "column": 2,
          "position": 1451
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/controlnet.py",
        "start": 20,
        "end": 26,
        "startLoc": {
          "line": 20,
          "column": 2,
          "position": 170
        },
        "endLoc": {
          "line": 26,
          "column": 2,
          "position": 301
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "x = comfy.ldm.common_dit.pad_to_patch_size(x, (patch_size, patch_size))\n\n        img = rearrange(x, \"b c (h ph) (w pw) -> b (h w) (c ph pw)\", ph=patch_size, pw=patch_size)\n\n        h_len = ((h + (patch_size // 2)) // patch_size)\n        w_len = ((w + (patch_size // 2)) // patch_size)\n        img_ids = torch.zeros((h_len, w_len, 3), device=x.device, dtype=x.dtype)\n        img_ids[.",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/controlnet.py",
        "start": 194,
        "end": 201,
        "startLoc": {
          "line": 194,
          "column": 9,
          "position": 2504
        },
        "endLoc": {
          "line": 201,
          "column": 2,
          "position": 2639
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 198,
        "end": 205,
        "startLoc": {
          "line": 198,
          "column": 9,
          "position": 1973
        },
        "endLoc": {
          "line": 205,
          "column": 2,
          "position": 2108
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "mean = self.latent_mean.view(latent_ch, -1)\n        std = self.latent_std.view(latent_ch, -1)\n\n        mean = mean.repeat(1, math.ceil(latent_t / mean.shape[-1]))[:, : latent_t].reshape([1, latent_ch, -1, 1, 1]).to(dtype=in_dtype, device=z.device)\n        std = std.repeat(1, math.ceil(latent_t / std.shape[-1]))[:, : latent_t].reshape([1, latent_ch, -1, 1, 1]).to(dtype=in_dtype, device=z.device)\n\n        z",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/vae.py",
        "start": 121,
        "end": 127,
        "startLoc": {
          "line": 121,
          "column": 9,
          "position": 1115
        },
        "endLoc": {
          "line": 127,
          "column": 2,
          "position": 1297
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/vae.py",
        "start": 110,
        "end": 115,
        "startLoc": {
          "line": 110,
          "column": 9,
          "position": 865
        },
        "endLoc": {
          "line": 115,
          "column": 7,
          "position": 1046
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "fps: Optional[torch.Tensor] = None,\n        image_size: Optional[torch.Tensor] = None,\n        padding_mask: Optional[torch.Tensor] = None,\n        scalar_feature: Optional[torch.Tensor] = None,\n        data_type: Optional[DataType] = DataType.VIDEO,\n        latent_condition: Optional[torch.Tensor] = None,\n        latent_condition_sigma: Optional[torch.Tensor] = None,\n        condition_video_augment_sigma",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/model.py",
        "start": 429,
        "end": 436,
        "startLoc": {
          "line": 429,
          "column": 9,
          "position": 3026
        },
        "endLoc": {
          "line": 436,
          "column": 30,
          "position": 3138
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/model.py",
        "start": 346,
        "end": 353,
        "startLoc": {
          "line": 346,
          "column": 9,
          "position": 2338
        },
        "endLoc": {
          "line": 353,
          "column": 3,
          "position": 2450
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": ")\n            )\n\n    def forward(\n        self,\n        x: torch.Tensor,\n        emb_B_D: torch.Tensor,\n        crossattn_emb: torch.Tensor,\n        crossattn_mask: Optional[torch.Tensor] = None,\n        rope_emb_L_1_1_D: Optional[torch.Tensor] = None,\n        adaln_lora_B_3D: Optional[torch.Tensor] = None,\n    ) -> torch.Tensor:\n        for",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/blocks.py",
        "start": 786,
        "end": 798,
        "startLoc": {
          "line": 786,
          "column": 17,
          "position": 5536
        },
        "endLoc": {
          "line": 798,
          "column": 4,
          "position": 5639
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cosmos/blocks.py",
        "start": 668,
        "end": 692,
        "startLoc": {
          "line": 668,
          "column": 12,
          "position": 4834
        },
        "endLoc": {
          "line": 692,
          "column": 12,
          "position": 4935
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "(nn.Module):\n    \"\"\"\n    Transformer model for flow matching on sequences.\n    \"\"\"\n\n    def __init__(self, image_model=None, final_layer=True, dtype=None, device=None, operations=None, **kwargs):\n        super().__init__()\n        self.dtype = dtype\n        params = ChromaParams",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/model.py",
        "start": 46,
        "end": 54,
        "startLoc": {
          "line": 46,
          "column": 7,
          "position": 215
        },
        "endLoc": {
          "line": 54,
          "column": 13,
          "position": 287
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 163,
        "end": 171,
        "startLoc": {
          "line": 163,
          "column": 13,
          "position": 1499
        },
        "endLoc": {
          "line": 171,
          "column": 19,
          "position": 1571
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": "(**kwargs)\n        self.params = params\n        self.patch_size = params.patch_size\n        self.in_channels = params.in_channels\n        self.out_channels = params.out_channels\n        if params.hidden_size % params.num_heads != 0:\n            raise ValueError(\n                f\"Hidden size {params.hidden_size} must be divisible by num_heads {params.num_heads}\"\n            )\n        pe_dim = params.hidden_size // params.num_heads\n        if sum(params.axes_dim) != pe_dim:\n            raise ValueError(f\"Got {params.axes_dim} but expected positional dim {pe_dim}\")\n        self.hidden_size = params.hidden_size\n        self.num_heads = params.num_heads\n        self.in_dim",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/model.py",
        "start": 54,
        "end": 68,
        "startLoc": {
          "line": 54,
          "column": 13,
          "position": 288
        },
        "endLoc": {
          "line": 68,
          "column": 7,
          "position": 430
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 171,
        "end": 185,
        "startLoc": {
          "line": 171,
          "column": 19,
          "position": 1572
        },
        "endLoc": {
          "line": 185,
          "column": 12,
          "position": 1714
        }
      }
    },
    {
      "format": "python",
      "lines": 27,
      "fragment": ")\n\n\n        self.double_blocks = nn.ModuleList(\n            [\n                DoubleStreamBlock(\n                    self.hidden_size,\n                    self.num_heads,\n                    mlp_ratio=params.mlp_ratio,\n                    qkv_bias=params.qkv_bias,\n                    dtype=dtype, device=device, operations=operations\n                )\n                for _ in range(params.depth)\n            ]\n        )\n\n        self.single_blocks = nn.ModuleList(\n            [\n                SingleStreamBlock(self.hidden_size, self.num_heads, mlp_ratio=params.mlp_ratio, dtype=dtype, device=device, operations=operations)\n                for _ in range(params.depth_single_blocks)\n            ]\n        )\n\n        if final_layer:\n            self.final_layer = LastLayer(self.hidden_size, 1, self.out_channels, dtype=dtype, device=device, operations=operations)\n\n        self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/model.py",
        "start": 82,
        "end": 108,
        "startLoc": {
          "line": 82,
          "column": 17,
          "position": 627
        },
        "endLoc": {
          "line": 108,
          "column": 5,
          "position": 833
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 66,
        "end": 91,
        "startLoc": {
          "line": 66,
          "column": 7,
          "position": 634
        },
        "endLoc": {
          "line": 91,
          "column": 4,
          "position": 839
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "if (\"double_block\", i) in blocks_replace:\n                    def block_wrap(args):\n                        out = {}\n                        out[\"img\"], out[\"txt\"] = block(img=args[\"img\"],\n                                                       txt=args[\"txt\"],\n                                                       vec=args[\"vec\"],\n                                                       pe=args[\"pe\"],\n                                                       attn_mask=args.get(\"attn_mask\"))\n                        return out\n\n                    out = blocks_replace[(\"double_block\", i)]({\"img\": img,\n                                                               \"txt\": txt,\n                                                               \"vec\": double_mod",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/model.py",
        "start": 188,
        "end": 200,
        "startLoc": {
          "line": 188,
          "column": 17,
          "position": 1692
        },
        "endLoc": {
          "line": 200,
          "column": 11,
          "position": 1824
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan_video/model.py",
        "start": 284,
        "end": 99,
        "startLoc": {
          "line": 284,
          "column": 13,
          "position": 3026
        },
        "endLoc": {
          "line": 99,
          "column": 4,
          "position": 912
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": ",\n                                     pe=pe,\n                                     attn_mask=attn_mask)\n\n                if control is not None: # Controlnet\n                    control_i = control.get(\"input\")\n                    if i < len(control_i):\n                        add = control_i[i]\n                        if add is not None:\n                            img += add\n\n        img = torch.cat((txt, img), 1)\n\n        for i, block in enumerate(self.single_blocks):\n            if i",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/model.py",
        "start": 209,
        "end": 223,
        "startLoc": {
          "line": 209,
          "column": 11,
          "position": 1900
        },
        "endLoc": {
          "line": 223,
          "column": 2,
          "position": 2026
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 151,
        "end": 165,
        "startLoc": {
          "line": 151,
          "column": 4,
          "position": 1467
        },
        "endLoc": {
          "line": 165,
          "column": 2,
          "position": 1593
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "if (\"single_block\", i) in blocks_replace:\n                    def block_wrap(args):\n                        out = {}\n                        out[\"img\"] = block(args[\"img\"],\n                                           vec=args[\"vec\"],\n                                           pe=args[\"pe\"],\n                                           attn_mask=args.get(\"attn_mask\"))\n                        return out\n\n                    out = blocks_replace[(\"single_block\", i)]({\"img\": img,\n                                                               \"vec\": single_mod",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/model.py",
        "start": 225,
        "end": 235,
        "startLoc": {
          "line": 225,
          "column": 17,
          "position": 2058
        },
        "endLoc": {
          "line": 235,
          "column": 11,
          "position": 2166
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/hunyuan3d/model.py",
        "start": 115,
        "end": 125,
        "startLoc": {
          "line": 115,
          "column": 13,
          "position": 1043
        },
        "endLoc": {
          "line": 125,
          "column": 4,
          "position": 1151
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ", pe=pe, attn_mask=attn_mask)\n\n                if control is not None: # Controlnet\n                    control_o = control.get(\"output\")\n                    if i < len(control_o):\n                        add = control_o[i]\n                        if add is not None:\n                            img[:, txt.shape[1] :, ...] += add\n\n        img = img[:, txt.shape[1] :, ...]\n        final_mod",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/model.py",
        "start": 241,
        "end": 251,
        "startLoc": {
          "line": 241,
          "column": 11,
          "position": 2220
        },
        "endLoc": {
          "line": 251,
          "column": 10,
          "position": 2346
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 181,
        "end": 192,
        "startLoc": {
          "line": 181,
          "column": 4,
          "position": 1753
        },
        "endLoc": {
          "line": 192,
          "column": 4,
          "position": 1880
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "x = comfy.ldm.common_dit.pad_to_patch_size(x, (patch_size, patch_size))\n\n        img = rearrange(x, \"b c (h ph) (w pw) -> b (h w) (c ph pw)\", ph=patch_size, pw=patch_size)\n\n        h_len = ((h + (patch_size // 2)) // patch_size)\n        w_len = ((w + (patch_size // 2)) // patch_size)\n        img_ids = torch.zeros((h_len, w_len, 3), device=x.device, dtype=x.dtype)\n        img_ids[:, :, 1] = img_ids[:, :, 1] + torch.linspace(0, h_len - 1, steps=h_len, device=x.device, dtype=x.dtype).unsqueeze(1)\n        img_ids[:, :, 2] = img_ids[:, :, 2] + torch.linspace(0, w_len - 1, steps=w_len, device=x.device, dtype=x.dtype).unsqueeze(0)\n        img_ids = repeat(img_ids, \"h w c -> b (h w) c\", b=bs)\n\n        txt_ids = torch.zeros((bs, context.shape[1], 3), device=x.device, dtype=x.dtype)\n        out = self.forward_orig(img, img_ids, context, txt_ids, timestep, guidance",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/model.py",
        "start": 258,
        "end": 270,
        "startLoc": {
          "line": 258,
          "column": 9,
          "position": 2447
        },
        "endLoc": {
          "line": 270,
          "column": 9,
          "position": 2791
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/model.py",
        "start": 198,
        "end": 210,
        "startLoc": {
          "line": 198,
          "column": 9,
          "position": 1973
        },
        "endLoc": {
          "line": 210,
          "column": 2,
          "position": 2317
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "class DoubleStreamBlock(nn.Module):\n    def __init__(self, hidden_size: int, num_heads: int, mlp_ratio: float, qkv_bias: bool = False, flipped_img_txt=False, dtype=None, device=None, operations=None):\n        super().__init__()\n\n        mlp_hidden_dim = int(hidden_size * mlp_ratio)\n        self.num_heads = num_heads\n        self.hidden_size = hidden_size\n        self.img_norm1",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py",
        "start": 51,
        "end": 58,
        "startLoc": {
          "line": 51,
          "column": 1,
          "position": 551
        },
        "endLoc": {
          "line": 58,
          "column": 10,
          "position": 663
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 132,
        "end": 139,
        "startLoc": {
          "line": 132,
          "column": 1,
          "position": 1573
        },
        "endLoc": {
          "line": 139,
          "column": 8,
          "position": 1685
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "self.img_norm1 = operations.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n        self.img_attn = SelfAttention(dim=hidden_size, num_heads=num_heads, qkv_bias=qkv_bias, dtype=dtype, device=device, operations=operations)\n\n        self.img_norm2 = operations.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n        self.img_mlp = nn.Sequential(\n            operations.Linear(hidden_size, mlp_hidden_dim, bias=True, dtype=dtype, device=device),\n            nn.GELU(approximate=\"tanh\"),\n            operations.Linear(mlp_hidden_dim, hidden_size, bias=True, dtype=dtype, device=device),\n        )\n\n        self.txt_norm1",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py",
        "start": 58,
        "end": 68,
        "startLoc": {
          "line": 58,
          "column": 9,
          "position": 661
        },
        "endLoc": {
          "line": 68,
          "column": 10,
          "position": 856
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 140,
        "end": 150,
        "startLoc": {
          "line": 140,
          "column": 9,
          "position": 1715
        },
        "endLoc": {
          "line": 150,
          "column": 8,
          "position": 1910
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": ")\n\n        self.txt_norm1 = operations.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n        self.txt_attn = SelfAttention(dim=hidden_size, num_heads=num_heads, qkv_bias=qkv_bias, dtype=dtype, device=device, operations=operations)\n\n        self.txt_norm2 = operations.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n        self.txt_mlp = nn.Sequential(\n            operations.Linear(hidden_size, mlp_hidden_dim, bias=True, dtype=dtype, device=device),\n            nn.GELU(approximate=\"tanh\"),\n            operations.Linear(mlp_hidden_dim, hidden_size, bias=True, dtype=dtype, device=device),\n        )\n        self.flipped_img_txt = flipped_img_txt\n\n    def forward(self, img: Tensor, txt: Tensor, pe",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py",
        "start": 66,
        "end": 79,
        "startLoc": {
          "line": 66,
          "column": 9,
          "position": 850
        },
        "endLoc": {
          "line": 79,
          "column": 3,
          "position": 1075
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 150,
        "end": 162,
        "startLoc": {
          "line": 150,
          "column": 11,
          "position": 1937
        },
        "endLoc": {
          "line": 162,
          "column": 4,
          "position": 2161
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ")\n        img_qkv = self.img_attn.qkv(img_modulated)\n        img_q, img_k, img_v = img_qkv.view(img_qkv.shape[0], img_qkv.shape[1], 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n        img_q, img_k = self.img_attn.norm(img_q, img_k, img_v)\n\n        # prepare txt for attention\n        txt_modulated = torch",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py",
        "start": 83,
        "end": 89,
        "startLoc": {
          "line": 83,
          "column": 2,
          "position": 1146
        },
        "endLoc": {
          "line": 89,
          "column": 6,
          "position": 1254
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 168,
        "end": 174,
        "startLoc": {
          "line": 168,
          "column": 20,
          "position": 2262
        },
        "endLoc": {
          "line": 174,
          "column": 5,
          "position": 2370
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ")\n        txt_qkv = self.txt_attn.qkv(txt_modulated)\n        txt_q, txt_k, txt_v = txt_qkv.view(txt_qkv.shape[0], txt_qkv.shape[1], 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n        txt_q, txt_k = self.txt_attn.norm(txt_q, txt_k, txt_v)\n\n        # run actual attention",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py",
        "start": 89,
        "end": 94,
        "startLoc": {
          "line": 89,
          "column": 2,
          "position": 1278
        },
        "endLoc": {
          "line": 94,
          "column": 23,
          "position": 1379
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 175,
        "end": 180,
        "startLoc": {
          "line": 175,
          "column": 20,
          "position": 2404
        },
        "endLoc": {
          "line": 180,
          "column": 3,
          "position": 2505
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "# run actual attention\n        attn = attention(torch.cat((txt_q, img_q), dim=2),\n                         torch.cat((txt_k, img_k), dim=2),\n                         torch.cat((txt_v, img_v), dim=2),\n                         pe=pe, mask=attn_mask)\n\n        txt_attn, img_attn = attn[:, : txt.shape[1]], attn[:, txt.shape[1] :]\n\n        # calculate the img bloks\n        img.",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py",
        "start": 94,
        "end": 103,
        "startLoc": {
          "line": 94,
          "column": 9,
          "position": 1379
        },
        "endLoc": {
          "line": 103,
          "column": 2,
          "position": 1501
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 189,
        "end": 198,
        "startLoc": {
          "line": 189,
          "column": 13,
          "position": 2633
        },
        "endLoc": {
          "line": 198,
          "column": 2,
          "position": 2755
        }
      }
    },
    {
      "format": "python",
      "lines": 44,
      "fragment": ")\n\n        if txt.dtype == torch.float16:\n            txt = torch.nan_to_num(txt, nan=0.0, posinf=65504, neginf=-65504)\n\n        return img, txt\n\n\nclass SingleStreamBlock(nn.Module):\n    \"\"\"\n    A DiT block with parallel linear layers as described in\n    https://arxiv.org/abs/2302.05442 and adapted modulation interface.\n    \"\"\"\n\n    def __init__(\n        self,\n        hidden_size: int,\n        num_heads: int,\n        mlp_ratio: float = 4.0,\n        qk_scale: float = None,\n        dtype=None,\n        device=None,\n        operations=None\n    ):\n        super().__init__()\n        self.hidden_dim = hidden_size\n        self.num_heads = num_heads\n        head_dim = hidden_size // num_heads\n        self.scale = qk_scale or head_dim**-0.5\n\n        self.mlp_hidden_dim = int(hidden_size * mlp_ratio)\n        # qkv and mlp_in\n        self.linear1 = operations.Linear(hidden_size, hidden_size * 3 + self.mlp_hidden_dim, dtype=dtype, device=device)\n        # proj and mlp_out\n        self.linear2 = operations.Linear(hidden_size + self.mlp_hidden_dim, hidden_size, dtype=dtype, device=device)\n\n        self.norm = QKNorm(head_dim, dtype=dtype, device=device, operations=operations)\n\n        self.hidden_size = hidden_size\n        self.pre_norm = operations.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n\n        self.mlp_act = nn.GELU(approximate=\"tanh\")\n\n    def",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py",
        "start": 108,
        "end": 151,
        "startLoc": {
          "line": 108,
          "column": 2,
          "position": 1625
        },
        "endLoc": {
          "line": 151,
          "column": 4,
          "position": 2002
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 203,
        "end": 245,
        "startLoc": {
          "line": 203,
          "column": 20,
          "position": 2924
        },
        "endLoc": {
          "line": 245,
          "column": 5,
          "position": 3300
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "), [3 * self.hidden_size, self.mlp_hidden_dim], dim=-1)\n\n        q, k, v = qkv.view(qkv.shape[0], qkv.shape[1], 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n        q, k = self.norm(q, k, v)\n\n        # compute attention\n        attn = attention(q, k, v, pe=pe, mask=attn_mask)\n        # compute activation in mlp stream, cat again and run second linear layer\n        output = self.linear2(torch.cat((attn, self.mlp_act(mlp)), 2))\n        x.",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py",
        "start": 154,
        "end": 163,
        "startLoc": {
          "line": 154,
          "column": 6,
          "position": 2093
        },
        "endLoc": {
          "line": 163,
          "column": 2,
          "position": 2265
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 249,
        "end": 258,
        "startLoc": {
          "line": 249,
          "column": 2,
          "position": 3433
        },
        "endLoc": {
          "line": 258,
          "column": 3,
          "position": 3606
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ")\n        if x.dtype == torch.float16:\n            x = torch.nan_to_num(x, nan=0.0, posinf=65504, neginf=-65504)\n        return x\n\n\nclass LastLayer(nn.Module):\n    def __init__(self, hidden_size: int, patch_size: int, out_channels: int, dtype=None, device=None, operations=None):\n        super().__init__()\n        self.norm_final = operations.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n        self.linear = operations.Linear(hidden_size, out_channels",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/chroma/layers.py",
        "start": 163,
        "end": 173,
        "startLoc": {
          "line": 163,
          "column": 7,
          "position": 2274
        },
        "endLoc": {
          "line": 173,
          "column": 13,
          "position": 2436
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/flux/layers.py",
        "start": 258,
        "end": 186,
        "startLoc": {
          "line": 258,
          "column": 16,
          "position": 3622
        },
        "endLoc": {
          "line": 186,
          "column": 11,
          "position": 2045
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "nn.GELU(),\n            nn.BatchNorm2d(c_hidden // 4),\n\n            ops.Conv2d(c_hidden // 4, c_hidden // 4, kernel_size=3, padding=1),\n            nn.GELU(),\n            nn.BatchNorm2d(c_hidden // 4),\n\n            ops.Conv2d",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c_coder.py",
        "start": 75,
        "end": 82,
        "startLoc": {
          "line": 75,
          "column": 13,
          "position": 702
        },
        "endLoc": {
          "line": 82,
          "column": 7,
          "position": 778
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c_coder.py",
        "start": 67,
        "end": 74,
        "startLoc": {
          "line": 67,
          "column": 13,
          "position": 596
        },
        "endLoc": {
          "line": 74,
          "column": 16,
          "position": 672
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "if cnet is not None:\n                            next_cnet = cnet.pop()\n                            if next_cnet is not None:\n                                x = x + nn.functional.interpolate(next_cnet, size=x.shape[-2:], mode='bilinear',\n                                                                  align_corners=True).to(x.dtype)\n                        x = block(x,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 229,
        "end": 234,
        "startLoc": {
          "line": 229,
          "column": 25,
          "position": 3083
        },
        "endLoc": {
          "line": 234,
          "column": 2,
          "position": 3173
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 195,
        "end": 200,
        "startLoc": {
          "line": 195,
          "column": 25,
          "position": 2554
        },
        "endLoc": {
          "line": 200,
          "column": 2,
          "position": 2644
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": ")\n                    elif isinstance(block, AttnBlock) or (\n                            hasattr(block, '_fsdp_wrapped_module') and isinstance(block._fsdp_wrapped_module,\n                                                                                  AttnBlock)):\n                        x = block(x, clip)\n                    elif isinstance(block, TimestepBlock) or (\n                            hasattr(block, '_fsdp_wrapped_module') and isinstance(block._fsdp_wrapped_module,\n                                                                                  TimestepBlock)):\n                        x = block(x, r_embed)\n                    else:\n                        x = block(x)\n                if j",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 234,
        "end": 245,
        "startLoc": {
          "line": 234,
          "column": 5,
          "position": 3176
        },
        "endLoc": {
          "line": 245,
          "column": 2,
          "position": 3299
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 200,
        "end": 211,
        "startLoc": {
          "line": 200,
          "column": 2,
          "position": 2644
        },
        "endLoc": {
          "line": 211,
          "column": 2,
          "position": 2767
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "], stable_cascade_stage=None, dtype=None, device=None, operations=None):\n        super().__init__()\n        self.dtype = dtype\n        self.c_r = c_r\n        self.t_conds = t_conds\n        self.c_clip_seq = c_clip_seq\n        if not isinstance(dropout, list):\n            dropout = [dropout] * len(c_hidden)\n        if not isinstance(self_attn, list):\n            self_attn = [self_attn] * len(c_hidden)\n\n        # CONDITIONING\n        self.effnet_mapper",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 29,
        "end": 41,
        "startLoc": {
          "line": 29,
          "column": 6,
          "position": 252
        },
        "endLoc": {
          "line": 41,
          "column": 14,
          "position": 388
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 44,
        "end": 57,
        "startLoc": {
          "line": 44,
          "column": 6,
          "position": 441
        },
        "endLoc": {
          "line": 57,
          "column": 16,
          "position": 578
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", c_hidden[0] * 4, kernel_size=1, dtype=dtype, device=device),\n            nn.GELU(),\n            operations.Conv2d(c_hidden[0] * 4, c_hidden[0], kernel_size=1, dtype=dtype, device=device),\n            LayerNorm2d_op(operations)(c_hidden[0], elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n        )\n        self.clip_mapper",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 48,
        "end": 53,
        "startLoc": {
          "line": 48,
          "column": 9,
          "position": 531
        },
        "endLoc": {
          "line": 53,
          "column": 12,
          "position": 644
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 42,
        "end": 47,
        "startLoc": {
          "line": 42,
          "column": 9,
          "position": 403
        },
        "endLoc": {
          "line": 47,
          "column": 14,
          "position": 516
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ", c_cond * c_clip_seq, dtype=dtype, device=device)\n        self.clip_norm = operations.LayerNorm(c_cond, elementwise_affine=False, eps=1e-6, dtype=dtype, device=device)\n\n        self.embedding = nn.Sequential(\n            nn.PixelUnshuffle(patch_size),\n            operations.Conv2d(c_in * (patch_size ** 2), c_hidden[0], kernel_size=1, dtype=dtype, device=device),\n            LayerNorm2d_op(operations)(c_hidden[0], elementwise_affine=False, eps=1e-6,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 53,
        "end": 59,
        "startLoc": {
          "line": 53,
          "column": 7,
          "position": 653
        },
        "endLoc": {
          "line": 59,
          "column": 2,
          "position": 792
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 59,
        "end": 65,
        "startLoc": {
          "line": 59,
          "column": 11,
          "position": 645
        },
        "endLoc": {
          "line": 65,
          "column": 2,
          "position": 784
        }
      }
    },
    {
      "format": "python",
      "lines": 24,
      "fragment": ")\n        )\n\n        def get_block(block_type, c_hidden, nhead, c_skip=0, dropout=0, self_attn=True):\n            if block_type == 'C':\n                return ResBlock(c_hidden, c_skip, kernel_size=kernel_size, dropout=dropout, dtype=dtype, device=device, operations=operations)\n            elif block_type == 'A':\n                return AttnBlock(c_hidden, c_cond, nhead, self_attn=self_attn, dropout=dropout, dtype=dtype, device=device, operations=operations)\n            elif block_type == 'F':\n                return FeedForwardBlock(c_hidden, dropout=dropout, dtype=dtype, device=device, operations=operations)\n            elif block_type == 'T':\n                return TimestepBlock(c_hidden, c_r, conds=t_conds, dtype=dtype, device=device, operations=operations)\n            else:\n                raise Exception(f'Block type {block_type} not supported')\n\n        # BLOCKS\n        # -- down blocks\n        self.down_blocks = nn.ModuleList()\n        self.down_downscalers = nn.ModuleList()\n        self.down_repeat_mappers = nn.ModuleList()\n        for i in range(len(c_hidden)):\n            if i > 0:\n                self.down_downscalers.append(nn.Sequential(\n                    LayerNorm2d_op(operations)(c_hidden[i - 1], elementwise_affine=False, eps=1e-6,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 59,
        "end": 82,
        "startLoc": {
          "line": 59,
          "column": 7,
          "position": 802
        },
        "endLoc": {
          "line": 82,
          "column": 2,
          "position": 1135
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 65,
        "end": 88,
        "startLoc": {
          "line": 65,
          "column": 2,
          "position": 784
        },
        "endLoc": {
          "line": 88,
          "column": 2,
          "position": 1117
        }
      }
    },
    {
      "format": "python",
      "lines": 23,
      "fragment": "))\n            else:\n                self.down_downscalers.append(nn.Identity())\n            down_block = nn.ModuleList()\n            for _ in range(blocks[0][i]):\n                for block_type in level_config[i]:\n                    block = get_block(block_type, c_hidden[i], nhead[i], dropout=dropout[i], self_attn=self_attn[i])\n                    down_block.append(block)\n            self.down_blocks.append(down_block)\n            if block_repeat is not None:\n                block_repeat_mappers = nn.ModuleList()\n                for _ in range(block_repeat[0][i] - 1):\n                    block_repeat_mappers.append(operations.Conv2d(c_hidden[i], c_hidden[i], kernel_size=1, dtype=dtype, device=device))\n                self.down_repeat_mappers.append(block_repeat_mappers)\n\n        # -- up blocks\n        self.up_blocks = nn.ModuleList()\n        self.up_upscalers = nn.ModuleList()\n        self.up_repeat_mappers = nn.ModuleList()\n        for i in reversed(range(len(c_hidden))):\n            if i > 0:\n                self.up_upscalers.append(nn.Sequential(\n                    LayerNorm2d_op(operations)(c_hidden[i], elementwise_affine=False, eps=1e-6,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 84,
        "end": 106,
        "startLoc": {
          "line": 84,
          "column": 17,
          "position": 1191
        },
        "endLoc": {
          "line": 106,
          "column": 2,
          "position": 1510
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 90,
        "end": 112,
        "startLoc": {
          "line": 90,
          "column": 17,
          "position": 1172
        },
        "endLoc": {
          "line": 112,
          "column": 2,
          "position": 1491
        }
      }
    },
    {
      "format": "python",
      "lines": 27,
      "fragment": "))\n            else:\n                self.up_upscalers.append(nn.Identity())\n            up_block = nn.ModuleList()\n            for j in range(blocks[1][::-1][i]):\n                for k, block_type in enumerate(level_config[i]):\n                    c_skip = c_hidden[i] if i < len(c_hidden) - 1 and j == k == 0 else 0\n                    block = get_block(block_type, c_hidden[i], nhead[i], c_skip=c_skip, dropout=dropout[i],\n                                      self_attn=self_attn[i])\n                    up_block.append(block)\n            self.up_blocks.append(up_block)\n            if block_repeat is not None:\n                block_repeat_mappers = nn.ModuleList()\n                for _ in range(block_repeat[1][::-1][i] - 1):\n                    block_repeat_mappers.append(operations.Conv2d(c_hidden[i], c_hidden[i], kernel_size=1, dtype=dtype, device=device))\n                self.up_repeat_mappers.append(block_repeat_mappers)\n\n        # OUTPUT\n        self.clf = nn.Sequential(\n            LayerNorm2d_op(operations)(c_hidden[0], elementwise_affine=False, eps=1e-6, dtype=dtype, device=device),\n            operations.Conv2d(c_hidden[0], c_out * (patch_size ** 2), kernel_size=1, dtype=dtype, device=device),\n            nn.PixelShuffle(patch_size),\n        )\n\n        # --- WEIGHT INIT ---\n    #     self.apply(self._init_weights)  # General init\n    #     nn.init.normal_(self.clip_mapper.weight, std=0.02)  # conditionings",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 108,
        "end": 134,
        "startLoc": {
          "line": 108,
          "column": 17,
          "position": 1566
        },
        "endLoc": {
          "line": 134,
          "column": 74,
          "position": 1955
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 114,
        "end": 140,
        "startLoc": {
          "line": 114,
          "column": 17,
          "position": 1546
        },
        "endLoc": {
          "line": 140,
          "column": 78,
          "position": 1935
        }
      }
    },
    {
      "format": "python",
      "lines": 31,
      "fragment": "#     torch.nn.init.xavier_uniform_(self.embedding[1].weight, 0.02)  # inputs\n    #     nn.init.constant_(self.clf[1].weight, 0)  # outputs\n    #\n    #     # blocks\n    #     for level_block in self.down_blocks + self.up_blocks:\n    #         for block in level_block:\n    #             if isinstance(block, ResBlock) or isinstance(block, FeedForwardBlock):\n    #                 block.channelwise[-1].weight.data *= np.sqrt(1 / sum(blocks[0]))\n    #             elif isinstance(block, TimestepBlock):\n    #                 for layer in block.modules():\n    #                     if isinstance(layer, nn.Linear):\n    #                         nn.init.constant_(layer.weight, 0)\n    #\n    # def _init_weights(self, m):\n    #     if isinstance(m, (nn.Conv2d, nn.Linear)):\n    #         torch.nn.init.xavier_uniform_(m.weight)\n    #         if m.bias is not None:\n    #             nn.init.constant_(m.bias, 0)\n\n    def gen_r_embedding(self, r, max_positions=10000):\n        r = r * max_positions\n        half_dim = self.c_r // 2\n        emb = math.log(max_positions) / (half_dim - 1)\n        emb = torch.arange(half_dim, device=r.device).float().mul(-emb).exp()\n        emb = r[:, None] * emb[None, :]\n        emb = torch.cat([emb.sin(), emb.cos()], dim=1)\n        if self.c_r % 2 == 1:  # zero pad\n            emb = nn.functional.pad(emb, (0, 1), mode='constant')\n        return emb\n\n    def gen_c_embeddings(self, clip",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 139,
        "end": 169,
        "startLoc": {
          "line": 139,
          "column": 5,
          "position": 1970
        },
        "endLoc": {
          "line": 169,
          "column": 5,
          "position": 2232
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 143,
        "end": 173,
        "startLoc": {
          "line": 143,
          "column": 5,
          "position": 1944
        },
        "endLoc": {
          "line": 173,
          "column": 9,
          "position": 2206
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "):\n        level_outputs = []\n        block_group = zip(self.down_blocks, self.down_downscalers, self.down_repeat_mappers)\n        for down_block, downscaler, repmap in block_group:\n            x = downscaler(x)\n            for i in range(len(repmap) + 1):\n                for block in down_block:\n                    if isinstance(block, ResBlock) or (\n                            hasattr(block, '_fsdp_wrapped_module') and isinstance(block._fsdp_wrapped_module,\n                                                                                  ResBlock)):\n                        x",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 176,
        "end": 186,
        "startLoc": {
          "line": 176,
          "column": 5,
          "position": 2336
        },
        "endLoc": {
          "line": 186,
          "column": 2,
          "position": 2465
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 185,
        "end": 195,
        "startLoc": {
          "line": 185,
          "column": 5,
          "position": 2425
        },
        "endLoc": {
          "line": 195,
          "column": 3,
          "position": 2554
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": "x = block(x)\n                    elif isinstance(block, AttnBlock) or (\n                            hasattr(block, '_fsdp_wrapped_module') and isinstance(block._fsdp_wrapped_module,\n                                                                                  AttnBlock)):\n                        x = block(x, clip)\n                    elif isinstance(block, TimestepBlock) or (\n                            hasattr(block, '_fsdp_wrapped_module') and isinstance(block._fsdp_wrapped_module,\n                                                                                  TimestepBlock)):\n                        x = block(x, r_embed)\n                    else:\n                        x = block(x)\n                if i < len(repmap):\n                    x = repmap[i](x)\n            level_outputs.insert(0, x)\n        return level_outputs\n\n    def _up_decode(self, level_outputs, r_embed, clip)",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 186,
        "end": 202,
        "startLoc": {
          "line": 186,
          "column": 25,
          "position": 2465
        },
        "endLoc": {
          "line": 202,
          "column": 2,
          "position": 2650
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 200,
        "end": 216,
        "startLoc": {
          "line": 200,
          "column": 25,
          "position": 2637
        },
        "endLoc": {
          "line": 216,
          "column": 2,
          "position": 2822
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "):\n        x = level_outputs[0]\n        block_group = zip(self.up_blocks, self.up_upscalers, self.up_repeat_mappers)\n        for i, (up_block, upscaler, repmap) in enumerate(block_group):\n            for j in range(len(repmap) + 1):\n                for k, block in enumerate(up_block):\n                    if isinstance(block, ResBlock) or (\n                            hasattr(block, '_fsdp_wrapped_module') and isinstance(block._fsdp_wrapped_module,\n                                                                                  ResBlock)):\n                        skip = level_outputs[i] if k == 0 and i > 0 else None\n                        if skip is not None and (x.size(-1) != skip.size(-1) or x.size(-2) != skip.size(-2)):\n                            x = torch.nn.functional.interpolate(x, skip.shape[-2:], mode='bilinear',\n                                                                align_corners=True)\n                        x",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 202,
        "end": 215,
        "startLoc": {
          "line": 202,
          "column": 5,
          "position": 2650
        },
        "endLoc": {
          "line": 215,
          "column": 2,
          "position": 2906
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 216,
        "end": 229,
        "startLoc": {
          "line": 216,
          "column": 5,
          "position": 2827
        },
        "endLoc": {
          "line": 229,
          "column": 3,
          "position": 3083
        }
      }
    },
    {
      "format": "python",
      "lines": 18,
      "fragment": ")\n                        x = block(x, skip)\n                    elif isinstance(block, AttnBlock) or (\n                            hasattr(block, '_fsdp_wrapped_module') and isinstance(block._fsdp_wrapped_module,\n                                                                                  AttnBlock)):\n                        x = block(x, clip)\n                    elif isinstance(block, TimestepBlock) or (\n                            hasattr(block, '_fsdp_wrapped_module') and isinstance(block._fsdp_wrapped_module,\n                                                                                  TimestepBlock)):\n                        x = block(x, r_embed)\n                    else:\n                        x = block(x)\n                if j < len(repmap):\n                    x = repmap[j](x)\n            x = upscaler(x)\n        return x\n\n    def forward(self, x, r, effnet",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 214,
        "end": 231,
        "startLoc": {
          "line": 214,
          "column": 5,
          "position": 2903
        },
        "endLoc": {
          "line": 231,
          "column": 7,
          "position": 3092
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 233,
        "end": 250,
        "startLoc": {
          "line": 233,
          "column": 6,
          "position": 3163
        },
        "endLoc": {
          "line": 250,
          "column": 10,
          "position": 3352
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "# Process the conditioning embeddings\n        r_embed = self.gen_r_embedding(r).to(dtype=x.dtype)\n        for c in self.t_conds:\n            t_cond = kwargs.get(c, torch.zeros_like(r))\n            r_embed = torch.cat([r_embed, self.gen_r_embedding(t_cond).to(dtype=x.dtype)], dim=1)\n        clip = self.gen_c_embeddings(clip",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 235,
        "end": 240,
        "startLoc": {
          "line": 235,
          "column": 9,
          "position": 3146
        },
        "endLoc": {
          "line": 240,
          "column": 5,
          "position": 3246
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 251,
        "end": 256,
        "startLoc": {
          "line": 251,
          "column": 9,
          "position": 3372
        },
        "endLoc": {
          "line": 256,
          "column": 10,
          "position": 3472
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ")\n        return self.clf(x)\n\n    def update_weights_ema(self, src_model, beta=0.999):\n        for self_params, src_params in zip(self.parameters(), src_model.parameters()):\n            self_params.data = self_params.data * beta + src_params.data.clone().to(self_params.device) * (1 - beta)\n        for self_buffers, src_buffers in zip(self.buffers(), src_model.buffers()):\n            self_buffers.data = self_buffers.data * beta + src_buffers.data.clone().to(self_buffers.device) * (1 - beta)",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_b.py",
        "start": 249,
        "end": 256,
        "startLoc": {
          "line": 249,
          "column": 5,
          "position": 3392
        },
        "endLoc": {
          "line": 256,
          "column": 2,
          "position": 3558
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/stage_c.py",
        "start": 266,
        "end": 273,
        "startLoc": {
          "line": 266,
          "column": 5,
          "position": 3573
        },
        "endLoc": {
          "line": 273,
          "column": 2,
          "position": 3739
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ", c * 4, dtype=dtype, device=device),\n            nn.GELU(),\n            GlobalResponseNorm(c * 4, dtype=dtype, device=device),\n            nn.Dropout(dropout),\n            operations.Linear(c * 4, c, dtype=dtype, device=device)\n        )\n\n    def forward(self, x)",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/common.py",
        "start": 128,
        "end": 135,
        "startLoc": {
          "line": 128,
          "column": 2,
          "position": 1656
        },
        "endLoc": {
          "line": 135,
          "column": 2,
          "position": 1752
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/cascade/common.py",
        "start": 90,
        "end": 97,
        "startLoc": {
          "line": 90,
          "column": 7,
          "position": 1086
        },
        "endLoc": {
          "line": 97,
          "column": 2,
          "position": 1182
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "(nn.Module):\n    def __init__(self, dim, n_heads, mh_qknorm=False, dtype=None, device=None, operations=None):\n        super().__init__()\n\n        self.n_heads = n_heads\n        self.head_dim = dim // n_heads\n\n        # this is for cond\n        self.w1q = operations.Linear(dim, dim, bias=False, dtype=dtype, device=device)\n        self.w1k = operations.Linear(dim, dim, bias=False, dtype=dtype, device=device)\n        self.w1v = operations.Linear(dim, dim, bias=False, dtype=dtype, device=device)\n        self.w1o = operations.Linear(dim, dim, bias=False, dtype=dtype, device=device)\n\n        # this is for x",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/aura/mmdit.py",
        "start": 103,
        "end": 116,
        "startLoc": {
          "line": 103,
          "column": 16,
          "position": 1292
        },
        "endLoc": {
          "line": 116,
          "column": 16,
          "position": 1500
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/aura/mmdit.py",
        "start": 62,
        "end": 75,
        "startLoc": {
          "line": 62,
          "column": 16,
          "position": 690
        },
        "endLoc": {
          "line": 75,
          "column": 5,
          "position": 898
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "= operations.Linear(dim, dim, bias=False, dtype=dtype, device=device)\n\n        self.q_norm1 = (\n            MultiHeadLayerNorm((self.n_heads, self.head_dim), dtype=dtype, device=device)\n            if mh_qknorm\n            else operations.LayerNorm(self.head_dim, elementwise_affine=False, dtype=dtype, device=device)\n        )\n        self.k_norm1 = (\n            MultiHeadLayerNorm((self.n_heads, self.head_dim), dtype=dtype, device=device)\n            if mh_qknorm\n            else operations.LayerNorm(self.head_dim, elementwise_affine=False, dtype=dtype, device=device)\n        )\n\n        self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/aura/mmdit.py",
        "start": 120,
        "end": 133,
        "startLoc": {
          "line": 120,
          "column": 2,
          "position": 1603
        },
        "endLoc": {
          "line": 133,
          "column": 5,
          "position": 1771
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/aura/mmdit.py",
        "start": 73,
        "end": 86,
        "startLoc": {
          "line": 73,
          "column": 2,
          "position": 869
        },
        "endLoc": {
          "line": 86,
          "column": 18,
          "position": 1037
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "= (\n            MultiHeadLayerNorm((self.n_heads, self.head_dim), dtype=dtype, device=device)\n            if mh_qknorm\n            else operations.LayerNorm(self.head_dim, elementwise_affine=False, dtype=dtype, device=device)\n        )\n\n\n    #@torch.compile()\n    def forward(self, c,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/aura/mmdit.py",
        "start": 138,
        "end": 146,
        "startLoc": {
          "line": 138,
          "column": 2,
          "position": 1844
        },
        "endLoc": {
          "line": 146,
          "column": 2,
          "position": 1922
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/aura/mmdit.py",
        "start": 80,
        "end": 87,
        "startLoc": {
          "line": 80,
          "column": 2,
          "position": 971
        },
        "endLoc": {
          "line": 87,
          "column": 2,
          "position": 1048
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "* freqs[None]\n        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n        if dim % 2:\n            embedding = torch.cat(\n                [embedding, torch.zeros_like(embedding[:, :1])], dim=-1\n            )\n        return embedding\n\n    #@torch.compile()",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/aura/mmdit.py",
        "start": 290,
        "end": 298,
        "startLoc": {
          "line": 290,
          "column": 2,
          "position": 3892
        },
        "endLoc": {
          "line": 298,
          "column": 18,
          "position": 3988
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/util.py",
        "start": 243,
        "end": 63,
        "startLoc": {
          "line": 243,
          "column": 2,
          "position": 2096
        },
        "endLoc": {
          "line": 63,
          "column": 4,
          "position": 561
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ": Optional[torch.Tensor] = None,\n        text_attention_mask: Optional[torch.LongTensor] = None,\n        speaker_embeds: Optional[torch.FloatTensor] = None,\n        lyric_token_idx: Optional[torch.LongTensor] = None,\n        lyric_mask: Optional[torch.LongTensor] = None,\n        block_controlnet_hidden_states",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/model.py",
        "start": 351,
        "end": 356,
        "startLoc": {
          "line": 351,
          "column": 8,
          "position": 3534
        },
        "endLoc": {
          "line": 356,
          "column": 31,
          "position": 3613
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/model.py",
        "start": 271,
        "end": 276,
        "startLoc": {
          "line": 271,
          "column": 27,
          "position": 2855
        },
        "endLoc": {
          "line": 276,
          "column": 16,
          "position": 2934
        }
      }
    },
    {
      "format": "python",
      "lines": 42,
      "fragment": "def apply_rotary_emb(\n        self,\n        x: torch.Tensor,\n        freqs_cis: Union[torch.Tensor, Tuple[torch.Tensor]],\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Apply rotary embeddings to input tensors using the given frequency tensor. This function applies rotary embeddings\n        to the given query or key 'x' tensors using the provided frequency tensor 'freqs_cis'. The input tensors are\n        reshaped as complex numbers, and the frequency tensor is reshaped for broadcasting compatibility. The resulting\n        tensors contain rotary embeddings and are returned as real tensors.\n\n        Args:\n            x (`torch.Tensor`):\n                Query or key tensor to apply rotary embeddings. [B, H, S, D] xk (torch.Tensor): Key tensor to apply\n            freqs_cis (`Tuple[torch.Tensor]`): Precomputed frequency tensor for complex exponentials. ([S, D], [S, D],)\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor]: Tuple of modified query tensor and key tensor with rotary embeddings.\n        \"\"\"\n        cos, sin = freqs_cis  # [S, D]\n        cos = cos[None, None]\n        sin = sin[None, None]\n        cos, sin = cos.to(x.device), sin.to(x.device)\n\n        x_real, x_imag = x.reshape(*x.shape[:-1], -1, 2).unbind(-1)  # [B, S, H, D//2]\n        x_rotated = torch.stack([-x_imag, x_real], dim=-1).flatten(3)\n        out = (x.float() * cos + x_rotated.float() * sin).to(x.dtype)\n\n        return out\n\n    def __call__(\n        self,\n        attn: Attention,\n        hidden_states: torch.FloatTensor,\n        encoder_hidden_states: torch.FloatTensor = None,\n        attention_mask: Optional[torch.FloatTensor] = None,\n        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n        rotary_freqs_cis: Union[torch.Tensor, Tuple[torch.Tensor]] = None,\n        rotary_freqs_cis_cross: Union[torch.Tensor, Tuple[torch.Tensor]] = None,\n        *args,\n        **kwargs,\n    ) -> torch.Tensor",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/attention.py",
        "start": 330,
        "end": 371,
        "startLoc": {
          "line": 330,
          "column": 5,
          "position": 3400
        },
        "endLoc": {
          "line": 371,
          "column": 7,
          "position": 3773
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/attention.py",
        "start": 155,
        "end": 196,
        "startLoc": {
          "line": 155,
          "column": 5,
          "position": 1450
        },
        "endLoc": {
          "line": 196,
          "column": 12,
          "position": 1823
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "if attn.norm_q is not None:\n            query = attn.norm_q(query)\n        if attn.norm_k is not None:\n            key = attn.norm_k(key)\n\n        # Apply RoPE if needed\n        if rotary_freqs_cis is not None:\n            query = self.apply_rotary_emb(query, rotary_freqs_cis)\n            if not attn.is_cross_attention:\n                key = self.apply_rotary_emb(key, rotary_freqs_cis)\n            elif rotary_freqs_cis_cross is not None and has_encoder_hidden_state_proj:\n                key = self.apply_rotary_emb(key, rotary_freqs_cis_cross)\n\n        if",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/attention.py",
        "start": 407,
        "end": 420,
        "startLoc": {
          "line": 407,
          "column": 9,
          "position": 4168
        },
        "endLoc": {
          "line": 420,
          "column": 3,
          "position": 4308
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/ace/attention.py",
        "start": 246,
        "end": 259,
        "startLoc": {
          "line": 246,
          "column": 9,
          "position": 2416
        },
        "endLoc": {
          "line": 259,
          "column": 44,
          "position": 2556
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "def fake_dirname(path):\n        return str(tmp_path) if path.endswith(dummy_yaml_name) else os.path.dirname(path)\n\n    monkeypatch.setattr(os.path, \"abspath\", fake_abspath)\n    monkeypatch.setattr(os.path, \"dirname\", fake_dirname)\n\n    load_extra_path_config(dummy_yaml_name)\n\n    expected_clip",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/utils/extra_config_test.py",
        "start": 286,
        "end": 294,
        "startLoc": {
          "line": 286,
          "column": 5,
          "position": 1949
        },
        "endLoc": {
          "line": 294,
          "column": 14,
          "position": 2027
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/utils/extra_config_test.py",
        "start": 240,
        "end": 248,
        "startLoc": {
          "line": 240,
          "column": 5,
          "position": 1573
        },
        "endLoc": {
          "line": 248,
          "column": 88,
          "position": 1651
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "(aiohttp_client, app, tmp_path):\n    os.makedirs(tmp_path / \"test_dir\")\n    with open(tmp_path / \"test_dir\" / \"file1.txt\", \"w\") as f:\n        f.write(\"test content\")\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/userdata?dir=test_dir&full_info=true\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/prompt_server_test/user_manager_test.py",
        "start": 60,
        "end": 66,
        "startLoc": {
          "line": 60,
          "column": 28,
          "position": 524
        },
        "endLoc": {
          "line": 66,
          "column": 40,
          "position": 603
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests-unit/prompt_server_test/user_manager_test.py",
        "start": 36,
        "end": 42,
        "startLoc": {
          "line": 36,
          "column": 29,
          "position": 244
        },
        "endLoc": {
          "line": 42,
          "column": 25,
          "position": 323
        }
      }
    },
    {
      "format": "python",
      "lines": 28,
      "fragment": "def connect(self,\n                    listen:str = '127.0.0.1',\n                    port:Union[str,int] = 8188,\n                    client_id: str = str(uuid.uuid4())\n                    ):\n        self.client_id = client_id\n        self.server_address = f\"{listen}:{port}\"\n        ws = websocket.WebSocket()\n        ws.connect(\"ws://{}/ws?clientId={}\".format(self.server_address, self.client_id))\n        self.ws = ws\n\n    def queue_prompt(self, prompt):\n        p = {\"prompt\": prompt, \"client_id\": self.client_id}\n        data = json.dumps(p).encode('utf-8')\n        req =  urllib.request.Request(\"http://{}/prompt\".format(self.server_address), data=data)\n        return json.loads(urllib.request.urlopen(req).read())\n\n    def get_image(self, filename, subfolder, folder_type):\n        data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n        url_values = urllib.parse.urlencode(data)\n        with urllib.request.urlopen(\"http://{}/view?{}\".format(self.server_address, url_values)) as response:\n            return response.read()\n\n    def get_history(self, prompt_id):\n        with urllib.request.urlopen(\"http://{}/history/{}\".format(self.server_address, prompt_id)) as response:\n            return json.loads(response.read())\n\n    def set_test_name",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_execution.py",
        "start": 43,
        "end": 70,
        "startLoc": {
          "line": 43,
          "column": 5,
          "position": 336
        },
        "endLoc": {
          "line": 70,
          "column": 14,
          "position": 696
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_inference.py",
        "start": 62,
        "end": 89,
        "startLoc": {
          "line": 62,
          "column": 5,
          "position": 451
        },
        "endLoc": {
          "line": 89,
          "column": 11,
          "position": 811
        }
      }
    },
    {
      "format": "python",
      "lines": 22,
      "fragment": ")\n        yield\n        p.kill()\n        torch.cuda.empty_cache()\n\n    def start_client(self, listen:str, port:int):\n        # Start client\n        comfy_client = ComfyClient()\n        # Connect to server (with retries)\n        n_tries = 5\n        for i in range(n_tries):\n            time.sleep(4)\n            try:\n                comfy_client.connect(listen=listen, port=port)\n            except ConnectionRefusedError as e:\n                print(e)  # noqa: T201\n                print(f\"({i+1}/{n_tries}) Retrying...\")  # noqa: T201\n            else:\n                break\n        return comfy_client\n\n    @fixture",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_execution.py",
        "start": 138,
        "end": 159,
        "startLoc": {
          "line": 138,
          "column": 6,
          "position": 1318
        },
        "endLoc": {
          "line": 159,
          "column": 9,
          "position": 1462
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_inference.py",
        "start": 159,
        "end": 180,
        "startLoc": {
          "line": 159,
          "column": 2,
          "position": 1410
        },
        "endLoc": {
          "line": 180,
          "column": 2,
          "position": 1554
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "(self, client: ComfyClient, builder: GraphBuilder):\n        g = builder\n        input1 = g.node(\"StubImage\", content=\"BLACK\", height=512, width=512, batch_size=1)\n        input2 = g.node(\"StubImage\", content=\"NOISE\", height=512, width=512, batch_size=1)\n        mask = g.node(\"StubMask\", value=0.5, height=512, width=512, batch_size=1)\n\n        lazy_mix = g.node(\"TestLazyMixImages\", image1=input1.out(0), image2=input2.out(0), mask=mask.out(0))\n        g.node(\"SaveImage\", images=lazy_mix.out(0))\n\n        client.run(g)\n        mask",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_execution.py",
        "start": 206,
        "end": 216,
        "startLoc": {
          "line": 206,
          "column": 19,
          "position": 2120
        },
        "endLoc": {
          "line": 216,
          "column": 5,
          "position": 2311
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_execution.py",
        "start": 192,
        "end": 202,
        "startLoc": {
          "line": 192,
          "column": 16,
          "position": 1878
        },
        "endLoc": {
          "line": 202,
          "column": 8,
          "position": 2069
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ", batch_size=1)\n        mask = g.node(\"StubMask\", value=0.5, height=512, width=512, batch_size=1)\n\n        lazy_mix = g.node(\"TestLazyMixImages\", image1=input1.out(0), image2=input2.out(0), mask=mask.out(0))\n        g.node(\"SaveImage\", images=lazy_mix.out(0))\n\n        try",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_execution.py",
        "start": 225,
        "end": 231,
        "startLoc": {
          "line": 225,
          "column": 4,
          "position": 2453
        },
        "endLoc": {
          "line": 231,
          "column": 4,
          "position": 2555
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_execution.py",
        "start": 195,
        "end": 201,
        "startLoc": {
          "line": 195,
          "column": 4,
          "position": 1959
        },
        "endLoc": {
          "line": 201,
          "column": 7,
          "position": 2061
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": ".out(0))\n\n        if expect_error:\n            with pytest.raises(urllib.error.HTTPError):\n                client.run(g)\n        else:\n            client.run(g)\n\n    @pytest.mark.parametrize(\"test_type, test_value, expect_error\", [\n        (\"StubInt\", 5, True),\n        (\"StubFloat\", 5.0, False)\n    ])\n    def test_validation_error_edge4",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_execution.py",
        "start": 290,
        "end": 302,
        "startLoc": {
          "line": 290,
          "column": 12,
          "position": 3229
        },
        "endLoc": {
          "line": 302,
          "column": 28,
          "position": 3321
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_execution.py",
        "start": 274,
        "end": 286,
        "startLoc": {
          "line": 274,
          "column": 12,
          "position": 3048
        },
        "endLoc": {
          "line": 286,
          "column": 28,
          "position": 3140
        }
      }
    },
    {
      "format": "yaml",
      "lines": 41,
      "fragment": "out_channels: 4\n        model_channels: 320\n        attention_resolutions: [ 4, 2, 1 ]\n        num_res_blocks: 2\n        channel_mult: [ 1, 2, 4, 4 ]\n        num_head_channels: 64 # need to fix for flash-attn\n        use_spatial_transformer: True\n        use_linear_in_transformer: True\n        transformer_depth: 1\n        context_dim: 1024\n        legacy: False\n\n    first_stage_config:\n      target: ldm.models.autoencoder.AutoencoderKL\n      params:\n        embed_dim: 4\n        monitor: val/rec_loss\n        ddconfig:\n          #attn_type: \"vanilla-xformers\"\n          double_z: true\n          z_channels: 4\n          resolution: 256\n          in_channels: 3\n          out_ch: 3\n          ch: 128\n          ch_mult:\n          - 1\n          - 2\n          - 4\n          - 4\n          num_res_blocks: 2\n          attn_resolutions: []\n          dropout: 0.0\n        lossconfig:\n          target: torch.nn.Identity\n\n    cond_stage_config:\n      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder\n      params:\n        freeze: True\n        layer: \"penultimate\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference_fp32.yaml",
        "start": 27,
        "end": 67,
        "startLoc": {
          "line": 27,
          "column": 9,
          "position": 145
        },
        "endLoc": {
          "line": 67,
          "column": 14,
          "position": 380
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inpainting-inference.yaml",
        "start": 27,
        "end": 67,
        "startLoc": {
          "line": 27,
          "column": 9,
          "position": 144
        },
        "endLoc": {
          "line": 67,
          "column": 14,
          "position": 380
        }
      }
    },
    {
      "format": "yaml",
      "lines": 24,
      "fragment": "model:\n  base_learning_rate: 1.0e-4\n  target: ldm.models.diffusion.ddpm.LatentDiffusion\n  params:\n    linear_start: 0.00085\n    linear_end: 0.0120\n    num_timesteps_cond: 1\n    log_every_t: 200\n    timesteps: 1000\n    first_stage_key: \"jpg\"\n    cond_stage_key: \"txt\"\n    image_size: 64\n    channels: 4\n    cond_stage_trainable: false\n    conditioning_key: crossattn\n    monitor: val/loss_simple_ema\n    scale_factor: 0.18215\n    use_ema: False # we set this to false because this is an inference only config\n\n    unet_config:\n      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n      params:\n        use_checkpoint: True\n        use_fp16: True",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference.yaml",
        "start": 1,
        "end": 24,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 24,
          "column": 5,
          "position": 129
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference_fp32.yaml",
        "start": 1,
        "end": 24,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 24,
          "column": 6,
          "position": 129
        }
      }
    },
    {
      "format": "yaml",
      "lines": 43,
      "fragment": "image_size: 32 # unused\n        in_channels: 4\n        out_channels: 4\n        model_channels: 320\n        attention_resolutions: [ 4, 2, 1 ]\n        num_res_blocks: 2\n        channel_mult: [ 1, 2, 4, 4 ]\n        num_head_channels: 64 # need to fix for flash-attn\n        use_spatial_transformer: True\n        use_linear_in_transformer: True\n        transformer_depth: 1\n        context_dim: 1024\n        legacy: False\n\n    first_stage_config:\n      target: ldm.models.autoencoder.AutoencoderKL\n      params:\n        embed_dim: 4\n        monitor: val/rec_loss\n        ddconfig:\n          #attn_type: \"vanilla-xformers\"\n          double_z: true\n          z_channels: 4\n          resolution: 256\n          in_channels: 3\n          out_ch: 3\n          ch: 128\n          ch_mult:\n          - 1\n          - 2\n          - 4\n          - 4\n          num_res_blocks: 2\n          attn_resolutions: []\n          dropout: 0.0\n        lossconfig:\n          target: torch.nn.Identity\n\n    cond_stage_config:\n      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder\n      params:\n        freeze: True\n        layer: \"penultimate\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference.yaml",
        "start": 25,
        "end": 67,
        "startLoc": {
          "line": 25,
          "column": 9,
          "position": 132
        },
        "endLoc": {
          "line": 67,
          "column": 14,
          "position": 380
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference_fp32.yaml",
        "start": 25,
        "end": 67,
        "startLoc": {
          "line": 25,
          "column": 9,
          "position": 132
        },
        "endLoc": {
          "line": 67,
          "column": 14,
          "position": 380
        }
      }
    },
    {
      "format": "yaml",
      "lines": 63,
      "fragment": "linear_start: 0.00085\n    linear_end: 0.0120\n    num_timesteps_cond: 1\n    log_every_t: 200\n    timesteps: 1000\n    first_stage_key: \"jpg\"\n    cond_stage_key: \"txt\"\n    image_size: 64\n    channels: 4\n    cond_stage_trainable: false\n    conditioning_key: crossattn\n    monitor: val/loss_simple_ema\n    scale_factor: 0.18215\n    use_ema: False # we set this to false because this is an inference only config\n\n    unet_config:\n      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n      params:\n        use_checkpoint: True\n        use_fp16: False\n        image_size: 32 # unused\n        in_channels: 4\n        out_channels: 4\n        model_channels: 320\n        attention_resolutions: [ 4, 2, 1 ]\n        num_res_blocks: 2\n        channel_mult: [ 1, 2, 4, 4 ]\n        num_head_channels: 64 # need to fix for flash-attn\n        use_spatial_transformer: True\n        use_linear_in_transformer: True\n        transformer_depth: 1\n        context_dim: 1024\n        legacy: False\n\n    first_stage_config:\n      target: ldm.models.autoencoder.AutoencoderKL\n      params:\n        embed_dim: 4\n        monitor: val/rec_loss\n        ddconfig:\n          #attn_type: \"vanilla-xformers\"\n          double_z: true\n          z_channels: 4\n          resolution: 256\n          in_channels: 3\n          out_ch: 3\n          ch: 128\n          ch_mult:\n          - 1\n          - 2\n          - 4\n          - 4\n          num_res_blocks: 2\n          attn_resolutions: []\n          dropout: 0.0\n        lossconfig:\n          target: torch.nn.Identity\n\n    cond_stage_config:\n      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder\n      params:\n        freeze: True\n        layer: \"penultimate\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference-v_fp32.yaml",
        "start": 6,
        "end": 68,
        "startLoc": {
          "line": 6,
          "column": 5,
          "position": 26
        },
        "endLoc": {
          "line": 68,
          "column": 14,
          "position": 386
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference_fp32.yaml",
        "start": 5,
        "end": 67,
        "startLoc": {
          "line": 5,
          "column": 5,
          "position": 20
        },
        "endLoc": {
          "line": 67,
          "column": 14,
          "position": 380
        }
      }
    },
    {
      "format": "yaml",
      "lines": 68,
      "fragment": "model:\n  base_learning_rate: 1.0e-4\n  target: ldm.models.diffusion.ddpm.LatentDiffusion\n  params:\n    parameterization: \"v\"\n    linear_start: 0.00085\n    linear_end: 0.0120\n    num_timesteps_cond: 1\n    log_every_t: 200\n    timesteps: 1000\n    first_stage_key: \"jpg\"\n    cond_stage_key: \"txt\"\n    image_size: 64\n    channels: 4\n    cond_stage_trainable: false\n    conditioning_key: crossattn\n    monitor: val/loss_simple_ema\n    scale_factor: 0.18215\n    use_ema: False # we set this to false because this is an inference only config\n\n    unet_config:\n      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n      params:\n        use_checkpoint: True\n        use_fp16: True\n        image_size: 32 # unused\n        in_channels: 4\n        out_channels: 4\n        model_channels: 320\n        attention_resolutions: [ 4, 2, 1 ]\n        num_res_blocks: 2\n        channel_mult: [ 1, 2, 4, 4 ]\n        num_head_channels: 64 # need to fix for flash-attn\n        use_spatial_transformer: True\n        use_linear_in_transformer: True\n        transformer_depth: 1\n        context_dim: 1024\n        legacy: False\n\n    first_stage_config:\n      target: ldm.models.autoencoder.AutoencoderKL\n      params:\n        embed_dim: 4\n        monitor: val/rec_loss\n        ddconfig:\n          #attn_type: \"vanilla-xformers\"\n          double_z: true\n          z_channels: 4\n          resolution: 256\n          in_channels: 3\n          out_ch: 3\n          ch: 128\n          ch_mult:\n          - 1\n          - 2\n          - 4\n          - 4\n          num_res_blocks: 2\n          attn_resolutions: []\n          dropout: 0.0\n        lossconfig:\n          target: torch.nn.Identity\n\n    cond_stage_config:\n      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder\n      params:\n        freeze: True\n        layer: \"penultimate\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference-v.yaml",
        "start": 1,
        "end": 68,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 68,
          "column": 14,
          "position": 386
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v2-inference-v_fp32.yaml",
        "start": 1,
        "end": 67,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 67,
          "column": 14,
          "position": 380
        }
      }
    },
    {
      "format": "yaml",
      "lines": 37,
      "fragment": "out_channels: 4\n        model_channels: 320\n        attention_resolutions: [ 4, 2, 1 ]\n        num_res_blocks: 2\n        channel_mult: [ 1, 2, 4, 4 ]\n        num_heads: 8\n        use_spatial_transformer: True\n        transformer_depth: 1\n        context_dim: 768\n        use_checkpoint: True\n        legacy: False\n\n    first_stage_config:\n      target: ldm.models.autoencoder.AutoencoderKL\n      params:\n        embed_dim: 4\n        monitor: val/rec_loss\n        ddconfig:\n          double_z: true\n          z_channels: 4\n          resolution: 256\n          in_channels: 3\n          out_ch: 3\n          ch: 128\n          ch_mult:\n          - 1\n          - 2\n          - 4\n          - 4\n          num_res_blocks: 2\n          attn_resolutions: []\n          dropout: 0.0\n        lossconfig:\n          target: torch.nn.Identity\n\n    cond_stage_config:\n      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_fp16.yaml",
        "start": 35,
        "end": 71,
        "startLoc": {
          "line": 35,
          "column": 9,
          "position": 203
        },
        "endLoc": {
          "line": 71,
          "column": 48,
          "position": 418
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inpainting-inference.yaml",
        "start": 34,
        "end": 70,
        "startLoc": {
          "line": 34,
          "column": 9,
          "position": 202
        },
        "endLoc": {
          "line": 70,
          "column": 48,
          "position": 417
        }
      }
    },
    {
      "format": "yaml",
      "lines": 71,
      "fragment": "model:\n  base_learning_rate: 1.0e-04\n  target: ldm.models.diffusion.ddpm.LatentDiffusion\n  params:\n    linear_start: 0.00085\n    linear_end: 0.0120\n    num_timesteps_cond: 1\n    log_every_t: 200\n    timesteps: 1000\n    first_stage_key: \"jpg\"\n    cond_stage_key: \"txt\"\n    image_size: 64\n    channels: 4\n    cond_stage_trainable: false   # Note: different from the one we trained before\n    conditioning_key: crossattn\n    monitor: val/loss_simple_ema\n    scale_factor: 0.18215\n    use_ema: False\n\n    scheduler_config: # 10000 warmup steps\n      target: ldm.lr_scheduler.LambdaLinearScheduler\n      params:\n        warm_up_steps: [ 10000 ]\n        cycle_lengths: [ 10000000000000 ] # incredibly large number to prevent corner cases\n        f_start: [ 1.e-6 ]\n        f_max: [ 1. ]\n        f_min: [ 1. ]\n\n    unet_config:\n      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n      params:\n        use_fp16: True\n        image_size: 32 # unused\n        in_channels: 4\n        out_channels: 4\n        model_channels: 320\n        attention_resolutions: [ 4, 2, 1 ]\n        num_res_blocks: 2\n        channel_mult: [ 1, 2, 4, 4 ]\n        num_heads: 8\n        use_spatial_transformer: True\n        transformer_depth: 1\n        context_dim: 768\n        use_checkpoint: True\n        legacy: False\n\n    first_stage_config:\n      target: ldm.models.autoencoder.AutoencoderKL\n      params:\n        embed_dim: 4\n        monitor: val/rec_loss\n        ddconfig:\n          double_z: true\n          z_channels: 4\n          resolution: 256\n          in_channels: 3\n          out_ch: 3\n          ch: 128\n          ch_mult:\n          - 1\n          - 2\n          - 4\n          - 4\n          num_res_blocks: 2\n          attn_resolutions: []\n          dropout: 0.0\n        lossconfig:\n          target: torch.nn.Identity\n\n    cond_stage_config:\n      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_clip_skip_2_fp16.yaml",
        "start": 1,
        "end": 71,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 71,
          "column": 48,
          "position": 418
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_fp16.yaml",
        "start": 1,
        "end": 70,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 70,
          "column": 48,
          "position": 417
        }
      }
    },
    {
      "format": "yaml",
      "lines": 32,
      "fragment": "model:\n  base_learning_rate: 1.0e-04\n  target: ldm.models.diffusion.ddpm.LatentDiffusion\n  params:\n    linear_start: 0.00085\n    linear_end: 0.0120\n    num_timesteps_cond: 1\n    log_every_t: 200\n    timesteps: 1000\n    first_stage_key: \"jpg\"\n    cond_stage_key: \"txt\"\n    image_size: 64\n    channels: 4\n    cond_stage_trainable: false   # Note: different from the one we trained before\n    conditioning_key: crossattn\n    monitor: val/loss_simple_ema\n    scale_factor: 0.18215\n    use_ema: False\n\n    scheduler_config: # 10000 warmup steps\n      target: ldm.lr_scheduler.LambdaLinearScheduler\n      params:\n        warm_up_steps: [ 10000 ]\n        cycle_lengths: [ 10000000000000 ] # incredibly large number to prevent corner cases\n        f_start: [ 1.e-6 ]\n        f_max: [ 1. ]\n        f_min: [ 1. ]\n\n    unet_config:\n      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n      params:\n        image_size",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_clip_skip_2.yaml",
        "start": 1,
        "end": 32,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 32,
          "column": 11,
          "position": 184
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_fp16.yaml",
        "start": 1,
        "end": 32,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 32,
          "column": 9,
          "position": 184
        }
      }
    },
    {
      "format": "yaml",
      "lines": 42,
      "fragment": "image_size: 32 # unused\n        in_channels: 4\n        out_channels: 4\n        model_channels: 320\n        attention_resolutions: [ 4, 2, 1 ]\n        num_res_blocks: 2\n        channel_mult: [ 1, 2, 4, 4 ]\n        num_heads: 8\n        use_spatial_transformer: True\n        transformer_depth: 1\n        context_dim: 768\n        use_checkpoint: True\n        legacy: False\n\n    first_stage_config:\n      target: ldm.models.autoencoder.AutoencoderKL\n      params:\n        embed_dim: 4\n        monitor: val/rec_loss\n        ddconfig:\n          double_z: true\n          z_channels: 4\n          resolution: 256\n          in_channels: 3\n          out_ch: 3\n          ch: 128\n          ch_mult:\n          - 1\n          - 2\n          - 4\n          - 4\n          num_res_blocks: 2\n          attn_resolutions: []\n          dropout: 0.0\n        lossconfig:\n          target: torch.nn.Identity\n\n    cond_stage_config:\n      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n      params:\n        layer: \"hidden\"\n        layer_idx: -2",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_clip_skip_2.yaml",
        "start": 32,
        "end": 73,
        "startLoc": {
          "line": 32,
          "column": 9,
          "position": 184
        },
        "endLoc": {
          "line": 73,
          "column": 3,
          "position": 428
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_fp16.yaml",
        "start": 33,
        "end": 74,
        "startLoc": {
          "line": 33,
          "column": 9,
          "position": 190
        },
        "endLoc": {
          "line": 74,
          "column": 3,
          "position": 434
        }
      }
    },
    {
      "format": "yaml",
      "lines": 70,
      "fragment": "model:\n  base_learning_rate: 1.0e-04\n  target: ldm.models.diffusion.ddpm.LatentDiffusion\n  params:\n    linear_start: 0.00085\n    linear_end: 0.0120\n    num_timesteps_cond: 1\n    log_every_t: 200\n    timesteps: 1000\n    first_stage_key: \"jpg\"\n    cond_stage_key: \"txt\"\n    image_size: 64\n    channels: 4\n    cond_stage_trainable: false   # Note: different from the one we trained before\n    conditioning_key: crossattn\n    monitor: val/loss_simple_ema\n    scale_factor: 0.18215\n    use_ema: False\n\n    scheduler_config: # 10000 warmup steps\n      target: ldm.lr_scheduler.LambdaLinearScheduler\n      params:\n        warm_up_steps: [ 10000 ]\n        cycle_lengths: [ 10000000000000 ] # incredibly large number to prevent corner cases\n        f_start: [ 1.e-6 ]\n        f_max: [ 1. ]\n        f_min: [ 1. ]\n\n    unet_config:\n      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n      params:\n        image_size: 32 # unused\n        in_channels: 4\n        out_channels: 4\n        model_channels: 320\n        attention_resolutions: [ 4, 2, 1 ]\n        num_res_blocks: 2\n        channel_mult: [ 1, 2, 4, 4 ]\n        num_heads: 8\n        use_spatial_transformer: True\n        transformer_depth: 1\n        context_dim: 768\n        use_checkpoint: True\n        legacy: False\n\n    first_stage_config:\n      target: ldm.models.autoencoder.AutoencoderKL\n      params:\n        embed_dim: 4\n        monitor: val/rec_loss\n        ddconfig:\n          double_z: true\n          z_channels: 4\n          resolution: 256\n          in_channels: 3\n          out_ch: 3\n          ch: 128\n          ch_mult:\n          - 1\n          - 2\n          - 4\n          - 4\n          num_res_blocks: 2\n          attn_resolutions: []\n          dropout: 0.0\n        lossconfig:\n          target: torch.nn.Identity\n\n    cond_stage_config:\n      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference.yaml",
        "start": 1,
        "end": 70,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 70,
          "column": 48,
          "position": 412
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_fp16.yaml",
        "start": 1,
        "end": 70,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 70,
          "column": 48,
          "position": 417
        }
      }
    },
    {
      "format": "yaml",
      "lines": 73,
      "fragment": "model:\n  base_learning_rate: 1.0e-04\n  target: ldm.models.diffusion.ddpm.LatentDiffusion\n  params:\n    linear_start: 0.00085\n    linear_end: 0.0120\n    num_timesteps_cond: 1\n    log_every_t: 200\n    timesteps: 1000\n    first_stage_key: \"jpg\"\n    cond_stage_key: \"txt\"\n    image_size: 64\n    channels: 4\n    cond_stage_trainable: false   # Note: different from the one we trained before\n    conditioning_key: crossattn\n    monitor: val/loss_simple_ema\n    scale_factor: 0.18215\n    use_ema: False\n\n    scheduler_config: # 10000 warmup steps\n      target: ldm.lr_scheduler.LambdaLinearScheduler\n      params:\n        warm_up_steps: [ 10000 ]\n        cycle_lengths: [ 10000000000000 ] # incredibly large number to prevent corner cases\n        f_start: [ 1.e-6 ]\n        f_max: [ 1. ]\n        f_min: [ 1. ]\n\n    unet_config:\n      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n      params:\n        image_size: 32 # unused\n        in_channels: 4\n        out_channels: 4\n        model_channels: 320\n        attention_resolutions: [ 4, 2, 1 ]\n        num_res_blocks: 2\n        channel_mult: [ 1, 2, 4, 4 ]\n        num_heads: 8\n        use_spatial_transformer: True\n        transformer_depth: 1\n        context_dim: 768\n        use_checkpoint: True\n        legacy: False\n\n    first_stage_config:\n      target: ldm.models.autoencoder.AutoencoderKL\n      params:\n        embed_dim: 4\n        monitor: val/rec_loss\n        ddconfig:\n          double_z: true\n          z_channels: 4\n          resolution: 256\n          in_channels: 3\n          out_ch: 3\n          ch: 128\n          ch_mult:\n          - 1\n          - 2\n          - 4\n          - 4\n          num_res_blocks: 2\n          attn_resolutions: []\n          dropout: 0.0\n        lossconfig:\n          target: torch.nn.Identity\n\n    cond_stage_config:\n      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n      params:\n        layer: \"hidden\"\n        layer_idx: -2",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/anything_v3.yaml",
        "start": 1,
        "end": 73,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 73,
          "column": 3,
          "position": 428
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/models/configs/v1-inference_fp16.yaml",
        "start": 1,
        "end": 74,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 74,
          "column": 3,
          "position": 434
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ")\n    face_limit: Optional[int] = Field(None, description='The number of faces to limit the generation to')\n    texture: Optional[bool] = Field(True, description='Whether to apply texture to the generated model')\n    pbr: Optional[bool] = Field(True, description='Whether to apply PBR to the generated model')\n    model_seed: Optional[int] = Field(None, description='The seed for the model')\n    texture_seed: Optional[int] = Field(None, description='The seed for the texture')\n    texture_quality: Optional[TripoTextureQuality] = TripoTextureQuality.standard\n    texture_alignment: Optional[TripoTextureAlignment] = TripoTextureAlignment",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/tripo_api.py",
        "start": 162,
        "end": 169,
        "startLoc": {
          "line": 162,
          "column": 41,
          "position": 1525
        },
        "endLoc": {
          "line": 169,
          "column": 22,
          "position": 1658
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/tripo_api.py",
        "start": 145,
        "end": 152,
        "startLoc": {
          "line": 145,
          "column": 42,
          "position": 1218
        },
        "endLoc": {
          "line": 152,
          "column": 6,
          "position": 1351
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "(BaseModel):\n    prompt: str = Field(...)\n    negative_prompt: Optional[str] = Field(None)\n    seed: Optional[int] = Field(None)\n    output_format: Optional[str] = Field(StabilityFormat.png.value)\n    image: Optional[str] = Field(None)\n    creativity: Optional[confloat(ge=0.1",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/stability_api.py",
        "start": 88,
        "end": 94,
        "startLoc": {
          "line": 88,
          "column": 32,
          "position": 714
        },
        "endLoc": {
          "line": 94,
          "column": 4,
          "position": 812
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/stability_api.py",
        "start": 79,
        "end": 85,
        "startLoc": {
          "line": 79,
          "column": 36,
          "position": 595
        },
        "endLoc": {
          "line": 85,
          "column": 4,
          "position": 693
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "prompt: str = Field(...)\n    negative_prompt: Optional[str] = Field(None)\n    aspect_ratio: Optional[str] = Field(None)\n    seed: Optional[int] = Field(None)\n    output_format: Optional[str] = Field(StabilityFormat.png.value)\n    image: Optional[str] = Field(None)\n    style_preset: Optional[str] = Field(None)\n    strength",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/stability_api.py",
        "start": 99,
        "end": 106,
        "startLoc": {
          "line": 99,
          "column": 5,
          "position": 855
        },
        "endLoc": {
          "line": 106,
          "column": 9,
          "position": 970
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/stability_api.py",
        "start": 68,
        "end": 75,
        "startLoc": {
          "line": 68,
          "column": 5,
          "position": 435
        },
        "endLoc": {
          "line": 75,
          "column": 10,
          "position": 550
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": "= Field(...)\n    model: Optional[str] = Field(\"v3.5\")\n    motion_mode: Optional[PixverseMotionMode] = Field(PixverseMotionMode.normal)\n    prompt: str = Field(...)\n    negative_prompt: Optional[str] = Field(None)\n    seed: Optional[int] = Field(None)\n    style: Optional[str] = Field(None)\n    template_id: Optional[int] = Field(None)\n    water_mark: Optional[bool] = Field(None)\n\n\nclass PixverseTransitionVideoRequest",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/pixverse_api.py",
        "start": 81,
        "end": 92,
        "startLoc": {
          "line": 81,
          "column": 2,
          "position": 567
        },
        "endLoc": {
          "line": 92,
          "column": 31,
          "position": 709
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/pixverse_api.py",
        "start": 67,
        "end": 78,
        "startLoc": {
          "line": 67,
          "column": 2,
          "position": 383
        },
        "endLoc": {
          "line": 78,
          "column": 26,
          "position": 525
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ")\n    steps: conint(ge=15, le=50) = Field(..., description='Number of steps for the image generation process')\n    guidance: confloat(ge=1.5, le=100) = Field(..., description='Guidance strength for the image generation process')\n    safety_tolerance: Optional[conint(ge=0, le=6)] = Field(\n        6, description='Tolerance level for input and output moderation. Between 0 and 6, 0 being most strict, 6 being least strict. Defaults to 2.'\n    )\n    output_format: Optional[BFLOutputFormat] = Field(\n        BFLOutputFormat.png, description=\"Output format for the generated image. Can be 'jpeg' or 'png'.\", examples=['png']\n    )\n    image: str = Field(None, description='A Base64-encoded string representing the image you wish to modify. Can contain alpha mask if desired.'",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/bfl_api.py",
        "start": 40,
        "end": 49,
        "startLoc": {
          "line": 40,
          "column": 38,
          "position": 493
        },
        "endLoc": {
          "line": 49,
          "column": 104,
          "position": 639
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/bfl_api.py",
        "start": 23,
        "end": 32,
        "startLoc": {
          "line": 23,
          "column": 60,
          "position": 270
        },
        "endLoc": {
          "line": 32,
          "column": 68,
          "position": 416
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ", le=100) = Field(..., description='Guidance strength for the image generation process')\n    safety_tolerance: Optional[conint(ge=0, le=6)] = Field(\n        6, description='Tolerance level for input and output moderation. Between 0 and 6, 0 being most strict, 6 being least strict. Defaults to 2.'\n    )\n    output_format: Optional[BFLOutputFormat] = Field(\n        BFLOutputFormat.png, description=\"Output format for the generated image. Can be 'jpeg' or 'png'.\", examples=['png']\n    )\n    control_image",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/bfl_api.py",
        "start": 62,
        "end": 69,
        "startLoc": {
          "line": 62,
          "column": 2,
          "position": 817
        },
        "endLoc": {
          "line": 69,
          "column": 14,
          "position": 908
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/bfl_api.py",
        "start": 25,
        "end": 32,
        "startLoc": {
          "line": 25,
          "column": 4,
          "position": 311
        },
        "endLoc": {
          "line": 32,
          "column": 6,
          "position": 402
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ")\n    prompt_upsampling: Optional[bool] = Field(\n        None, description='Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation.'\n    )\n    seed: Optional[int] = Field(None, description='The seed value for reproducibility.')\n    steps: conint(ge=15, le=50) = Field(..., description='Number of steps for the image generation process')\n    guidance: confloat(ge=1",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/bfl_api.py",
        "start": 74,
        "end": 80,
        "startLoc": {
          "line": 74,
          "column": 35,
          "position": 977
        },
        "endLoc": {
          "line": 80,
          "column": 2,
          "position": 1063
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/bfl_api.py",
        "start": 36,
        "end": 42,
        "startLoc": {
          "line": 36,
          "column": 174,
          "position": 447
        },
        "endLoc": {
          "line": 42,
          "column": 4,
          "position": 533
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": ")\n    seed: Optional[int] = Field(None, description='The seed value for reproducibility.')\n    steps: conint(ge=15, le=50) = Field(..., description='Number of steps for the image generation process')\n    guidance: confloat(ge=1, le=100) = Field(..., description='Guidance strength for the image generation process')\n    safety_tolerance: Optional[conint(ge=0, le=6)] = Field(\n        6, description='Tolerance level for input and output moderation. Between 0 and 6, 0 being most strict, 6 being least strict. Defaults to 2.'\n    )\n    output_format: Optional[BFLOutputFormat] = Field(\n        BFLOutputFormat.png, description=\"Output format for the generated image. Can be 'jpeg' or 'png'.\", examples=['png']\n    )\n    control_image: Optional[str] = Field(None, description='Base64 encoded image to use as control input if no preprocessed image is provided')\n    preprocessed_image: Optional[str] = Field(None, description='Optional pre-processed image that will bypass the control preprocessing step')\n\n\nclass BFLFluxProGenerateRequest",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/bfl_api.py",
        "start": 77,
        "end": 91,
        "startLoc": {
          "line": 77,
          "column": 5,
          "position": 1002
        },
        "endLoc": {
          "line": 91,
          "column": 26,
          "position": 1200
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/apis/bfl_api.py",
        "start": 59,
        "end": 73,
        "startLoc": {
          "line": 59,
          "column": 42,
          "position": 755
        },
        "endLoc": {
          "line": 73,
          "column": 25,
          "position": 953
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "def __init__(self, loaded_keys, weights):\n        self.loaded_keys = loaded_keys\n        self.weights = weights\n\n    @classmethod\n    def load(\n        cls,\n        x: str,\n        lora: dict[str, torch.Tensor],\n        alpha: float,\n        dora_scale: torch.Tensor,\n        loaded_keys: set[str] = None,\n    ) -> Optional[\"LoRAAdapter\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/lora.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 57
        },
        "endLoc": {
          "line": 24,
          "column": 14,
          "position": 164
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 54
        },
        "endLoc": {
          "line": 24,
          "column": 13,
          "position": 161
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "def __init__(self, loaded_keys, weights):\n        self.loaded_keys = loaded_keys\n        self.weights = weights\n\n    @classmethod\n    def load(\n        cls,\n        x: str,\n        lora: dict[str, torch.Tensor],\n        alpha: float,\n        dora_scale: torch.Tensor,\n        loaded_keys: set[str] = None,\n    ) -> Optional[\"LoKrAdapter\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/lokr.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 54
        },
        "endLoc": {
          "line": 24,
          "column": 14,
          "position": 161
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 54
        },
        "endLoc": {
          "line": 24,
          "column": 13,
          "position": 161
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "def __init__(self, loaded_keys, weights):\n        self.loaded_keys = loaded_keys\n        self.weights = weights\n\n    @classmethod\n    def load(\n        cls,\n        x: str,\n        lora: dict[str, torch.Tensor],\n        alpha: float,\n        dora_scale: torch.Tensor,\n        loaded_keys: set[str] = None,\n    ) -> Optional[\"LoHaAdapter\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/loha.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 54
        },
        "endLoc": {
          "line": 24,
          "column": 14,
          "position": 161
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 54
        },
        "endLoc": {
          "line": 24,
          "column": 13,
          "position": 161
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ").reshape(weight.shape)\n            if dora_scale is not None:\n                weight = weight_decompose(dora_scale, weight, lora_diff, alpha, strength, intermediate_dtype, function)\n            else:\n                weight += function(((strength * alpha) * lora_diff).type(weight.dtype))\n        except Exception as e:\n            logging.error(\"ERROR {} {} {}\".format(self.name, key, e))\n        return weight",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/loha.py",
        "start": 93,
        "end": 100,
        "startLoc": {
          "line": 93,
          "column": 3,
          "position": 876
        },
        "endLoc": {
          "line": 100,
          "column": 7,
          "position": 992
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/lokr.py",
        "start": 126,
        "end": 133,
        "startLoc": {
          "line": 126,
          "column": 3,
          "position": 1175
        },
        "endLoc": {
          "line": 133,
          "column": 7,
          "position": 1291
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "def __init__(self, loaded_keys, weights):\n        self.loaded_keys = loaded_keys\n        self.weights = weights\n\n    @classmethod\n    def load(\n        cls,\n        x: str,\n        lora: dict[str, torch.Tensor],\n        alpha: float,\n        dora_scale: torch.Tensor,\n        loaded_keys: set[str] = None,\n    ) -> Optional[\"GLoRAAdapter\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/glora.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 54
        },
        "endLoc": {
          "line": 24,
          "column": 15,
          "position": 161
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 54
        },
        "endLoc": {
          "line": 24,
          "column": 13,
          "position": 161
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": ").reshape(weight.shape)\n\n            if dora_scale is not None:\n                weight = weight_decompose(dora_scale, weight, lora_diff, alpha, strength, intermediate_dtype, function)\n            else:\n                weight += function(((strength * alpha) * lora_diff).type(weight.dtype))\n        except Exception as e:\n            logging.error(\"ERROR {} {} {}\".format(self.name, key, e))\n        return weight",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/glora.py",
        "start": 85,
        "end": 93,
        "startLoc": {
          "line": 85,
          "column": 3,
          "position": 963
        },
        "endLoc": {
          "line": 93,
          "column": 7,
          "position": 1080
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/lokr.py",
        "start": 126,
        "end": 133,
        "startLoc": {
          "line": 126,
          "column": 3,
          "position": 1175
        },
        "endLoc": {
          "line": 133,
          "column": 7,
          "position": 1291
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "def __init__(self, loaded_keys, weights):\n        self.loaded_keys = loaded_keys\n        self.weights = weights\n\n    @classmethod\n    def load(\n        cls,\n        x: str,\n        lora: dict[str, torch.Tensor],\n        alpha: float,\n        dora_scale: torch.Tensor,\n        loaded_keys: set[str] = None,\n    ) -> Optional[\"BOFTAdapter\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/boft.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 54
        },
        "endLoc": {
          "line": 24,
          "column": 14,
          "position": 161
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py",
        "start": 12,
        "end": 24,
        "startLoc": {
          "line": 12,
          "column": 5,
          "position": 54
        },
        "endLoc": {
          "line": 24,
          "column": 13,
          "position": 161
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "]:\n        if loaded_keys is None:\n            loaded_keys = set()\n        blocks_name = \"{}.oft_blocks\".format(x)\n        rescale_name = \"{}.rescale\".format(x)\n\n        blocks = None\n        if blocks_name in lora.keys():\n            blocks = lora[blocks_name]\n            if blocks.ndim == 4",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/boft.py",
        "start": 24,
        "end": 33,
        "startLoc": {
          "line": 24,
          "column": 14,
          "position": 162
        },
        "endLoc": {
          "line": 33,
          "column": 2,
          "position": 249
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py",
        "start": 24,
        "end": 33,
        "startLoc": {
          "line": 24,
          "column": 13,
          "position": 162
        },
        "endLoc": {
          "line": 33,
          "column": 2,
          "position": 249
        }
      }
    },
    {
      "format": "python",
      "lines": 37,
      "fragment": ":\n                loaded_keys.add(blocks_name)\n            else:\n                blocks = None\n        if blocks is None:\n            return None\n\n        rescale = None\n        if rescale_name in lora.keys():\n            rescale = lora[rescale_name]\n            loaded_keys.add(rescale_name)\n\n        weights = (blocks, rescale, alpha, dora_scale)\n        return cls(loaded_keys, weights)\n\n    def calculate_weight(\n        self,\n        weight,\n        key,\n        strength,\n        strength_model,\n        offset,\n        function,\n        intermediate_dtype=torch.float32,\n        original_weight=None,\n    ):\n        v = self.weights\n        blocks = v[0]\n        rescale = v[1]\n        alpha = v[2]\n        dora_scale = v[3]\n\n        blocks = comfy.model_management.cast_to_device(blocks, weight.device, intermediate_dtype)\n        if rescale is not None:\n            rescale = comfy.model_management.cast_to_device(rescale, weight.device, intermediate_dtype)\n\n        boft_m",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/boft.py",
        "start": 33,
        "end": 69,
        "startLoc": {
          "line": 33,
          "column": 2,
          "position": 250
        },
        "endLoc": {
          "line": 69,
          "column": 7,
          "position": 517
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py",
        "start": 33,
        "end": 69,
        "startLoc": {
          "line": 33,
          "column": 2,
          "position": 250
        },
        "endLoc": {
          "line": 69,
          "column": 10,
          "position": 517
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "q_norm = torch.norm(q) + 1e-8\n                if q_norm > alpha:\n                    normed_q = q * alpha / q_norm\n            # use float() to prevent unsupported type in .inverse()\n            r = (I + normed_q) @ (I - normed_q).float().inverse()\n            r = r.to(weight)\n            inp",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/boft.py",
        "start": 78,
        "end": 84,
        "startLoc": {
          "line": 78,
          "column": 17,
          "position": 613
        },
        "endLoc": {
          "line": 84,
          "column": 4,
          "position": 702
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py",
        "start": 78,
        "end": 84,
        "startLoc": {
          "line": 78,
          "column": 17,
          "position": 608
        },
        "endLoc": {
          "line": 84,
          "column": 2,
          "position": 697
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ")\n            if dora_scale is not None:\n                weight = weight_decompose(dora_scale, weight, lora_diff, alpha, strength, intermediate_dtype, function)\n            else:\n                weight += function((strength * lora_diff).type(weight.dtype))\n        except Exception as e:\n            logging.error(\"ERROR {} {} {}\".format(self.name, key, e))\n        return weight",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/boft.py",
        "start": 108,
        "end": 115,
        "startLoc": {
          "line": 108,
          "column": 19,
          "position": 992
        },
        "endLoc": {
          "line": 115,
          "column": 7,
          "position": 1095
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/oft.py",
        "start": 89,
        "end": 96,
        "startLoc": {
          "line": 89,
          "column": 6,
          "position": 768
        },
        "endLoc": {
          "line": 96,
          "column": 7,
          "position": 871
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "= operations.Linear(model_dim, ff_dim, bias=False, dtype=dtype, device=device)\n        self.wo = operations.Linear(ff_dim, model_dim, bias=False, dtype=dtype, device=device)\n        # self.dropout = nn.Dropout(config.dropout_rate)\n        self.act = activations[ff_activation]\n\n    def forward(self, x):\n        hidden_gelu",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5.py",
        "start": 40,
        "end": 46,
        "startLoc": {
          "line": 40,
          "column": 2,
          "position": 515
        },
        "endLoc": {
          "line": 46,
          "column": 12,
          "position": 603
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/t5.py",
        "start": 25,
        "end": 31,
        "startLoc": {
          "line": 25,
          "column": 2,
          "position": 305
        },
        "endLoc": {
          "line": 31,
          "column": 2,
          "position": 393
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "(nn.Module):\n    def __init__(self, config: Llama2Config, device=None, dtype=None, ops: Any = None):\n        super().__init__()\n        self.self_attn = Attention(config, device=device, dtype=dtype, ops=ops)\n        self.mlp = MLP(config, device=device, dtype=dtype, ops=ops)\n        self.input_layernorm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps, add",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/llama.py",
        "start": 179,
        "end": 184,
        "startLoc": {
          "line": 179,
          "column": 23,
          "position": 2200
        },
        "endLoc": {
          "line": 184,
          "column": 4,
          "position": 2326
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/llama.py",
        "start": 145,
        "end": 150,
        "startLoc": {
          "line": 145,
          "column": 17,
          "position": 1845
        },
        "endLoc": {
          "line": 150,
          "column": 7,
          "position": 1971
        }
      }
    },
    {
      "format": "python",
      "lines": 20,
      "fragment": ", device=device, dtype=dtype)\n\n    def forward(\n        self,\n        x: torch.Tensor,\n        attention_mask: Optional[torch.Tensor] = None,\n        freqs_cis: Optional[torch.Tensor] = None,\n        optimized_attention=None,\n    ):\n        # Self Attention\n        residual = x\n        x = self.input_layernorm(x)\n        x = self.self_attn(\n            hidden_states=x,\n            attention_mask=attention_mask,\n            freqs_cis=freqs_cis,\n            optimized_attention=optimized_attention,\n        )\n\n        x = self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/llama.py",
        "start": 187,
        "end": 206,
        "startLoc": {
          "line": 187,
          "column": 13,
          "position": 2445
        },
        "endLoc": {
          "line": 206,
          "column": 5,
          "position": 2584
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/llama.py",
        "start": 151,
        "end": 169,
        "startLoc": {
          "line": 151,
          "column": 13,
          "position": 2000
        },
        "endLoc": {
          "line": 169,
          "column": 9,
          "position": 2138
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ", tokenizer_data=tokenizer_data)\n\n    def tokenize_with_weights(self, text:str, return_word_ids=False, **kwargs):\n        out = {}\n        out[\"g\"] = self.clip_g.tokenize_with_weights(text, return_word_ids, **kwargs)\n        out[\"l\"] = self.clip_l.tokenize_with_weights(text, return_word_ids, **kwargs)\n        t5xxl",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hidream.py",
        "start": 15,
        "end": 21,
        "startLoc": {
          "line": 15,
          "column": 7,
          "position": 170
        },
        "endLoc": {
          "line": 21,
          "column": 6,
          "position": 258
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd3_clip.py",
        "start": 44,
        "end": 50,
        "startLoc": {
          "line": 44,
          "column": 20,
          "position": 588
        },
        "endLoc": {
          "line": 50,
          "column": 4,
          "position": 676
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": ", model_options=model_options)\n            self.dtypes.add(dtype)\n        else:\n            self.clip_l = None\n\n        if clip_g:\n            self.clip_g = sdxl_clip.SDXLClipG(device=device, dtype=dtype, model_options=model_options)\n            self.dtypes.add(dtype)\n        else:\n            self.clip_g = None\n\n        if t5:\n            dtype_t5 = comfy.model_management.pick_weight_dtype(dtype_t5, dtype, device)\n            self.t5xxl",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hidream.py",
        "start": 38,
        "end": 51,
        "startLoc": {
          "line": 38,
          "column": 5,
          "position": 484
        },
        "endLoc": {
          "line": 51,
          "column": 6,
          "position": 600
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd3_clip.py",
        "start": 64,
        "end": 77,
        "startLoc": {
          "line": 64,
          "column": 6,
          "position": 874
        },
        "endLoc": {
          "line": 77,
          "column": 18,
          "position": 990
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "))\n\n    def set_clip_options(self, options):\n        if self.clip_l is not None:\n            self.clip_l.set_clip_options(options)\n        if self.clip_g is not None:\n            self.clip_g.set_clip_options(options)\n        if self.t5xxl is not None:\n            self.t5xxl.set_clip_options(options)\n        if",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hidream.py",
        "start": 65,
        "end": 74,
        "startLoc": {
          "line": 65,
          "column": 12,
          "position": 801
        },
        "endLoc": {
          "line": 74,
          "column": 3,
          "position": 890
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd3_clip.py",
        "start": 83,
        "end": 93,
        "startLoc": {
          "line": 83,
          "column": 9,
          "position": 1070
        },
        "endLoc": {
          "line": 93,
          "column": 4,
          "position": 1160
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ".set_clip_options(options)\n\n    def reset_clip_options(self):\n        if self.clip_l is not None:\n            self.clip_l.reset_clip_options()\n        if self.clip_g is not None:\n            self.clip_g.reset_clip_options()\n        if self.t5xxl is not None:\n            self.t5xxl.reset_clip_options()\n        if",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hidream.py",
        "start": 75,
        "end": 84,
        "startLoc": {
          "line": 75,
          "column": 6,
          "position": 907
        },
        "endLoc": {
          "line": 84,
          "column": 3,
          "position": 993
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd3_clip.py",
        "start": 91,
        "end": 101,
        "startLoc": {
          "line": 91,
          "column": 6,
          "position": 1152
        },
        "endLoc": {
          "line": 101,
          "column": 4,
          "position": 1239
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": "= None\n        extra = {}\n\n        if len(token_weight_pairs_g) > 0 or len(token_weight_pairs_l) > 0:\n            if self.clip_l is not None:\n                lg_out, l_pooled = self.clip_l.encode_token_weights(token_weight_pairs_l)\n            else:\n                l_pooled = torch.zeros((1, 768), device=comfy.model_management.intermediate_device())\n\n            if self.clip_g is not None:\n                g_out, g_pooled = self.clip_g.encode_token_weights(token_weight_pairs_g)\n            else",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/hidream.py",
        "start": 93,
        "end": 104,
        "startLoc": {
          "line": 93,
          "column": 2,
          "position": 1078
        },
        "endLoc": {
          "line": 104,
          "column": 5,
          "position": 1211
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd3_clip.py",
        "start": 107,
        "end": 118,
        "startLoc": {
          "line": 107,
          "column": 2,
          "position": 1297
        },
        "endLoc": {
          "line": 118,
          "column": 3,
          "position": 1430
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "(sd1_clip.SD1ClipModel):\n    def __init__(self, device=\"cpu\", dtype=None, model_options={}):\n        super().__init__(device=device, dtype=dtype, name=\"t5xxl\", clip_model=T5XXLModel, model_options=model_options)\n\n\nclass T5XXLTokenizer(sd1_clip.SDTokenizer):\n    def __init__(self, embedding_directory=None, tokenizer_data={}):\n        tokenizer_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"t5_tokenizer\")\n        super().__init__(tokenizer_path, embedding_directory=embedding_directory, pad_with_end=False, embedding_size=4096, embedding_key='t5xxl', tokenizer_class=T5TokenizerFast, has_start_token=False, pad_to_max_length=False, max_length=99999999, min_length=256",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/genmo.py",
        "start": 13,
        "end": 21,
        "startLoc": {
          "line": 13,
          "column": 11,
          "position": 83
        },
        "endLoc": {
          "line": 21,
          "column": 4,
          "position": 262
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/pixart_t5.py",
        "start": 20,
        "end": 27,
        "startLoc": {
          "line": 20,
          "column": 12,
          "position": 169
        },
        "endLoc": {
          "line": 27,
          "column": 2,
          "position": 354
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "):\n        def __init__(self, device=\"cpu\", dtype=None, model_options={}):\n            if t5xxl_scaled_fp8 is not None and \"t5xxl_scaled_fp8\" not in model_options:\n                model_options = model_options.copy()\n                model_options[\"t5xxl_scaled_fp8\"] = t5xxl_scaled_fp8\n            if dtype is None:\n                dtype = dtype_t5\n            super().__init__(device=device, dtype=dtype, model_options=model_options)\n    return MochiTEModel_",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/genmo.py",
        "start": 30,
        "end": 38,
        "startLoc": {
          "line": 30,
          "column": 11,
          "position": 352
        },
        "endLoc": {
          "line": 38,
          "column": 14,
          "position": 465
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/pixart_t5.py",
        "start": 34,
        "end": 42,
        "startLoc": {
          "line": 34,
          "column": 12,
          "position": 451
        },
        "endLoc": {
          "line": 42,
          "column": 15,
          "position": 572
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "class T5XXLTokenizer(sd1_clip.SDTokenizer):\n    def __init__(self, embedding_directory=None, tokenizer_data={}):\n        tokenizer_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"t5_tokenizer\")\n        super().__init__(tokenizer_path, embedding_directory=embedding_directory, pad_with_end=False, embedding_size=4096, embedding_key='t5xxl', tokenizer_class=T5TokenizerFast, has_start_token=False, pad_to_max_length=False, max_length=99999999, min_length=256, tokenizer_data=tokenizer_data)\n\n\nclass FluxTokenizer",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/flux.py",
        "start": 9,
        "end": 15,
        "startLoc": {
          "line": 9,
          "column": 1,
          "position": 47
        },
        "endLoc": {
          "line": 15,
          "column": 14,
          "position": 172
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/pixart_t5.py",
        "start": 24,
        "end": 24,
        "startLoc": {
          "line": 24,
          "column": 1,
          "position": 238
        },
        "endLoc": {
          "line": 24,
          "column": 17,
          "position": 274
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "):\n        def __init__(self, device=\"cpu\", dtype=None, model_options={}):\n            if t5xxl_scaled_fp8 is not None and \"t5xxl_scaled_fp8\" not in model_options:\n                model_options = model_options.copy()\n                model_options[\"t5xxl_scaled_fp8\"] = t5xxl_scaled_fp8\n            super().__init__(dtype_t5",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/flux.py",
        "start": 64,
        "end": 69,
        "startLoc": {
          "line": 64,
          "column": 14,
          "position": 722
        },
        "endLoc": {
          "line": 69,
          "column": 9,
          "position": 800
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd3_clip.py",
        "start": 160,
        "end": 165,
        "startLoc": {
          "line": 160,
          "column": 13,
          "position": 1969
        },
        "endLoc": {
          "line": 165,
          "column": 7,
          "position": 2047
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "(sd1_clip.SD1ClipModel):\n    def __init__(self, device=\"cpu\", dtype=None, model_options={}):\n        super().__init__(device=device, dtype=dtype, name=\"t5xxl\", clip_model=T5XXLModel, model_options=model_options)\n\n\nclass T5XXLTokenizer(sd1_clip.SDTokenizer):\n    def __init__(self, embedding_directory=None, tokenizer_data={}):\n        tokenizer_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"t5_tokenizer\")\n        super().__init__(tokenizer_path, embedding_directory=embedding_directory, pad_with_end=False, embedding_size=1024",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/cosmos.py",
        "start": 17,
        "end": 25,
        "startLoc": {
          "line": 17,
          "column": 12,
          "position": 243
        },
        "endLoc": {
          "line": 25,
          "column": 5,
          "position": 392
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/pixart_t5.py",
        "start": 20,
        "end": 27,
        "startLoc": {
          "line": 20,
          "column": 12,
          "position": 169
        },
        "endLoc": {
          "line": 27,
          "column": 5,
          "position": 324
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "):\n        def __init__(self, device=\"cpu\", dtype=None, model_options={}):\n            if t5xxl_scaled_fp8 is not None and \"t5xxl_scaled_fp8\" not in model_options:\n                model_options = model_options.copy()\n                model_options[\"t5xxl_scaled_fp8\"] = t5xxl_scaled_fp8\n            if dtype is None:\n                dtype = dtype_t5\n            super().__init__(device=device, dtype=dtype, model_options=model_options)\n    return CosmosTEModel_",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/cosmos.py",
        "start": 34,
        "end": 42,
        "startLoc": {
          "line": 34,
          "column": 12,
          "position": 512
        },
        "endLoc": {
          "line": 42,
          "column": 15,
          "position": 625
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/pixart_t5.py",
        "start": 34,
        "end": 42,
        "startLoc": {
          "line": 34,
          "column": 12,
          "position": 451
        },
        "endLoc": {
          "line": 42,
          "column": 15,
          "position": 572
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ")\n        mask = None\n        if attention_mask is not None:\n            mask = 1.0 - attention_mask.to(x.dtype).reshape((attention_mask.shape[0], 1, -1, attention_mask.shape[-1])).expand(attention_mask.shape[0], 1, attention_mask.shape[-1], attention_mask.shape[-1])\n            mask = mask.masked_fill(mask.to(torch.bool), -torch.finfo(x.dtype).max)\n\n        x",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/bert.py",
        "start": 120,
        "end": 126,
        "startLoc": {
          "line": 120,
          "column": 6,
          "position": 1713
        },
        "endLoc": {
          "line": 126,
          "column": 2,
          "position": 1845
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/llama.py",
        "start": 256,
        "end": 208,
        "startLoc": {
          "line": 256,
          "column": 7,
          "position": 3061
        },
        "endLoc": {
          "line": 208,
          "column": 13,
          "position": 2557
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": ")\n\n\ndef avg_pool_nd(dims, *args, **kwargs):\n    \"\"\"\n    Create a 1D, 2D, or 3D average pooling module.\n    \"\"\"\n    if dims == 1:\n        return nn.AvgPool1d(*args, **kwargs)\n    elif dims == 2:\n        return nn.AvgPool2d(*args, **kwargs)\n    elif dims == 3:\n        return nn.AvgPool3d(*args, **kwargs)\n    raise ValueError(f\"unsupported dimensions: {dims}\")\n\n\nclass Downsample",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/t2i_adapter/adapter.py",
        "start": 17,
        "end": 33,
        "startLoc": {
          "line": 17,
          "column": 33,
          "position": 127
        },
        "endLoc": {
          "line": 33,
          "column": 11,
          "position": 238
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/util.py",
        "start": 274,
        "end": 290,
        "startLoc": {
          "line": 274,
          "column": 2,
          "position": 2335
        },
        "endLoc": {
          "line": 290,
          "column": 18,
          "position": 2446
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.dims = dims\n        stride = 2 if dims != 3 else (1, 2, 2)\n        if use_conv:\n            self.op = conv_nd",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/t2i_adapter/adapter.py",
        "start": 42,
        "end": 50,
        "startLoc": {
          "line": 42,
          "column": 2,
          "position": 277
        },
        "endLoc": {
          "line": 50,
          "column": 8,
          "position": 369
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 116,
        "end": 124,
        "startLoc": {
          "line": 116,
          "column": 4,
          "position": 1049
        },
        "endLoc": {
          "line": 124,
          "column": 11,
          "position": 1141
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": "if not 0. <= warmup < 1:\n            raise ValueError('Invalid value for warmup')\n        self.warmup = warmup\n        self.min_lr = min_lr\n        super().__init__(optimizer, last_epoch, verbose)\n\n    def get_lr(self):\n        if not self._get_lr_called_within_step:\n            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n                          \"please use `get_last_lr()`.\")\n\n        return self._get_closed_form_lr()\n\n    def _get_closed_form_lr(self):\n        warmup = 1 - self.warmup ** (self.last_epoch + 1)\n        lr_mult = (self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/k_diffusion/utils.py",
        "start": 198,
        "end": 213,
        "startLoc": {
          "line": 198,
          "column": 9,
          "position": 1390
        },
        "endLoc": {
          "line": 213,
          "column": 5,
          "position": 1530
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/k_diffusion/utils.py",
        "start": 157,
        "end": 172,
        "startLoc": {
          "line": 157,
          "column": 9,
          "position": 1113
        },
        "endLoc": {
          "line": 172,
          "column": 2,
          "position": 1253
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "(torch.nn.Module):\n    def __init__(self, input_dim, output_dim, layer_norm_eps, dtype, device, operations):\n        super().__init__()\n        self.dense = operations.Linear(input_dim, output_dim, dtype=dtype, device=device)\n\n    def",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/image_encoders/dino2.py",
        "start": 7,
        "end": 12,
        "startLoc": {
          "line": 7,
          "column": 21,
          "position": 41
        },
        "endLoc": {
          "line": 12,
          "column": 4,
          "position": 115
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/bert.py",
        "start": 23,
        "end": 27,
        "startLoc": {
          "line": 23,
          "column": 11,
          "position": 270
        },
        "endLoc": {
          "line": 27,
          "column": 5,
          "position": 343
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "* h_phi_ks[k + 1] * torch.einsum('bkchw,k->bchw', D1s, A_p[k])\n            # now corrector\n            if use_corrector:\n                model_t = self.model_fn(x_t, t)\n                D1_t = (model_t - model_prev_0)\n                x_t = x_t_\n                k = 0\n                for k in range(K - 1):\n                    x_t = x_t - sigma_t",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/extra_samplers/uni_pc.py",
        "start": 567,
        "end": 575,
        "startLoc": {
          "line": 567,
          "column": 2,
          "position": 4572
        },
        "endLoc": {
          "line": 575,
          "column": 8,
          "position": 4678
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/extra_samplers/uni_pc.py",
        "start": 546,
        "end": 554,
        "startLoc": {
          "line": 546,
          "column": 2,
          "position": 4271
        },
        "endLoc": {
          "line": 554,
          "column": 8,
          "position": 4377
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": "ns.marginal_log_mean_coeff(t)\n        alpha_t = torch.exp(log_alpha_t)\n\n        h = lambda_t - lambda_prev_0\n\n        rks = []\n        D1s = []\n        for i in range(1, order):\n            t_prev_i = t_prev_list[-(i + 1)]\n            model_prev_i = model_prev_list[-(i + 1)]\n            lambda_prev_i = ns.marginal_lambda(t_prev_i)\n            rk = ((",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/extra_samplers/uni_pc.py",
        "start": 591,
        "end": 602,
        "startLoc": {
          "line": 591,
          "column": 2,
          "position": 4916
        },
        "endLoc": {
          "line": 602,
          "column": 2,
          "position": 5032
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/extra_samplers/uni_pc.py",
        "start": 488,
        "end": 499,
        "startLoc": {
          "line": 488,
          "column": 2,
          "position": 3679
        },
        "endLoc": {
          "line": 499,
          "column": 14,
          "position": 3795
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "return torch.sqrt(1. - torch.exp(2. * self.marginal_log_mean_coeff(t)))\n\n    def marginal_lambda(self, t):\n        \"\"\"\n        Compute lambda_t = log(alpha_t) - log(sigma_t) of a given continuous-time label t in [0, T].\n        \"\"\"\n        log_mean_coeff = self.marginal_log_mean_coeff(t)\n        log_std = 0.5 * torch.log(1. - torch.exp(2. * log_mean_coeff))\n        return log_mean_coeff - log_std\n\ndef predict_eps_sigma",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/extra_samplers/uni_pc.py",
        "start": 830,
        "end": 840,
        "startLoc": {
          "line": 830,
          "column": 9,
          "position": 7487
        },
        "endLoc": {
          "line": 840,
          "column": 18,
          "position": 7587
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/extra_samplers/uni_pc.py",
        "start": 152,
        "end": 162,
        "startLoc": {
          "line": 152,
          "column": 9,
          "position": 767
        },
        "endLoc": {
          "line": 162,
          "column": 15,
          "position": 868
        }
      }
    },
    {
      "format": "python",
      "lines": 20,
      "fragment": ".float32,\n        num_heads=-1,\n        num_head_channels=-1,\n        num_heads_upsample=-1,\n        use_scale_shift_norm=False,\n        resblock_updown=False,\n        use_new_attention_order=False,\n        use_spatial_transformer=False,    # custom transformer support\n        transformer_depth=1,              # custom transformer support\n        context_dim=None,                 # custom transformer support\n        n_embed=None,                     # custom support for prediction of discrete ids into codebook of first stage vq model\n        legacy=True,\n        disable_self_attentions=None,\n        num_attention_blocks=None,\n        disable_middle_self_attn=False,\n        use_linear_in_transformer=False,\n        adm_in_channels=None,\n        transformer_depth_middle=None,\n        transformer_depth_output=None,\n        attn_precision",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/cldm.py",
        "start": 74,
        "end": 93,
        "startLoc": {
          "line": 74,
          "column": 6,
          "position": 817
        },
        "endLoc": {
          "line": 93,
          "column": 15,
          "position": 941
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 414,
        "end": 433,
        "startLoc": {
          "line": 414,
          "column": 3,
          "position": 3345
        },
        "endLoc": {
          "line": 433,
          "column": 22,
          "position": 3469
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": "if context_dim is not None:\n            assert use_spatial_transformer, 'Fool!! You forgot to use the spatial transformer for your cross-attention conditioning...'\n            # from omegaconf.listconfig import ListConfig\n            # if type(context_dim) == ListConfig:\n            #     context_dim = list(context_dim)\n\n        if num_heads_upsample == -1:\n            num_heads_upsample = num_heads\n\n        if num_heads == -1:\n            assert num_head_channels != -1, 'Either num_heads or num_head_channels has to be set'\n\n        if num_head_channels == -1:\n            assert num_heads != -1, 'Either num_heads or num_head_channels has to be set'\n\n        self.dims",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/cldm.py",
        "start": 104,
        "end": 119,
        "startLoc": {
          "line": 104,
          "column": 9,
          "position": 1020
        },
        "endLoc": {
          "line": 119,
          "column": 5,
          "position": 1121
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 449,
        "end": 464,
        "startLoc": {
          "line": 449,
          "column": 9,
          "position": 3561
        },
        "endLoc": {
          "line": 464,
          "column": 12,
          "position": 3662
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "if isinstance(num_res_blocks, int):\n            self.num_res_blocks = len(channel_mult) * [num_res_blocks]\n        else:\n            if len(num_res_blocks) != len(channel_mult):\n                raise ValueError(\"provide num_res_blocks either as an int (globally constant) or \"\n                                 \"as a list/tuple (per-level) with the same length as channel_mult\")\n            self.num_res_blocks = num_res_blocks\n\n        if disable_self_attentions is not None:\n            # should be a list of booleans, indicating whether to disable self-attention in TransformerBlocks or not\n            assert len(disable_self_attentions) == len(channel_mult)\n        if num_attention_blocks is not None:\n            assert len(num_attention_blocks) == len(self.num_res_blocks)\n            assert",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/cldm.py",
        "start": 124,
        "end": 137,
        "startLoc": {
          "line": 124,
          "column": 9,
          "position": 1156
        },
        "endLoc": {
          "line": 137,
          "column": 7,
          "position": 1286
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 468,
        "end": 482,
        "startLoc": {
          "line": 468,
          "column": 9,
          "position": 3688
        },
        "endLoc": {
          "line": 482,
          "column": 18,
          "position": 3819
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": "[:]\n\n        self.dropout = dropout\n        self.channel_mult = channel_mult\n        self.conv_resample = conv_resample\n        self.num_classes = num_classes\n        self.use_checkpoint = use_checkpoint\n        self.dtype = dtype\n        self.num_heads = num_heads\n        self.num_head_channels = num_head_channels\n        self.num_heads_upsample = num_heads_upsample\n        self.predict_codebook_ids",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/cldm.py",
        "start": 139,
        "end": 150,
        "startLoc": {
          "line": 139,
          "column": 18,
          "position": 1329
        },
        "endLoc": {
          "line": 150,
          "column": 21,
          "position": 1418
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 483,
        "end": 494,
        "startLoc": {
          "line": 483,
          "column": 25,
          "position": 3834
        },
        "endLoc": {
          "line": 494,
          "column": 23,
          "position": 3923
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": "None\n\n        time_embed_dim = model_channels * 4\n        self.time_embed = nn.Sequential(\n            operations.Linear(model_channels, time_embed_dim, dtype=self.dtype, device=device),\n            nn.SiLU(),\n            operations.Linear(time_embed_dim, time_embed_dim, dtype=self.dtype, device=device),\n        )\n\n        if self.num_classes is not None:\n            if isinstance(self.num_classes, int):\n                self.label_emb = nn.Embedding(num_classes, time_embed_dim)",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/cldm.py",
        "start": 150,
        "end": 161,
        "startLoc": {
          "line": 150,
          "column": 2,
          "position": 1428
        },
        "endLoc": {
          "line": 161,
          "column": 2,
          "position": 1557
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 497,
        "end": 508,
        "startLoc": {
          "line": 497,
          "column": 2,
          "position": 3952
        },
        "endLoc": {
          "line": 508,
          "column": 2,
          "position": 4081
        }
      }
    },
    {
      "format": "python",
      "lines": 21,
      "fragment": "self.label_emb = nn.Linear(1, time_embed_dim)\n            elif self.num_classes == \"sequential\":\n                assert adm_in_channels is not None\n                self.label_emb = nn.Sequential(\n                    nn.Sequential(\n                        operations.Linear(adm_in_channels, time_embed_dim, dtype=self.dtype, device=device),\n                        nn.SiLU(),\n                        operations.Linear(time_embed_dim, time_embed_dim, dtype=self.dtype, device=device),\n                    )\n                )\n            else:\n                raise ValueError()\n\n        self.input_blocks = nn.ModuleList(\n            [\n                TimestepEmbedSequential(\n                    operations.conv_nd(dims, in_channels, model_channels, 3, padding=1, dtype=self.dtype, device=device)\n                )\n            ]\n        )\n        self.zero_convs",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/cldm.py",
        "start": 163,
        "end": 183,
        "startLoc": {
          "line": 163,
          "column": 17,
          "position": 1572
        },
        "endLoc": {
          "line": 183,
          "column": 11,
          "position": 1768
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 511,
        "end": 531,
        "startLoc": {
          "line": 511,
          "column": 17,
          "position": 4116
        },
        "endLoc": {
          "line": 531,
          "column": 14,
          "position": 4312
        }
      }
    },
    {
      "format": "python",
      "lines": 29,
      "fragment": "dropout,\n                        out_channels=mult * model_channels,\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                        dtype=self.dtype,\n                        device=device,\n                        operations=operations,\n                    )\n                ]\n                ch = mult * model_channels\n                num_transformers = transformer_depth.pop(0)\n                if num_transformers > 0:\n                    if num_head_channels == -1:\n                        dim_head = ch // num_heads\n                    else:\n                        num_heads = ch // num_head_channels\n                        dim_head = num_head_channels\n                    if legacy:\n                        #num_heads = 1\n                        dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n                    if exists(disable_self_attentions):\n                        disabled_sa = disable_self_attentions[level]\n                    else:\n                        disabled_sa = False\n\n                    if not exists(num_attention_blocks) or nr < num_attention_blocks[level]:\n                        layers.append(\n                            SpatialTransformer",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/cldm.py",
        "start": 213,
        "end": 241,
        "startLoc": {
          "line": 213,
          "column": 25,
          "position": 2254
        },
        "endLoc": {
          "line": 241,
          "column": 19,
          "position": 2476
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 633,
        "end": 660,
        "startLoc": {
          "line": 633,
          "column": 2,
          "position": 4936
        },
        "endLoc": {
          "line": 660,
          "column": 20,
          "position": 5156
        }
      }
    },
    {
      "format": "python",
      "lines": 19,
      "fragment": "dropout,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            down=True,\n                            dtype=self.dtype,\n                            device=device,\n                            operations=operations\n                        )\n                        if resblock_updown\n                        else Downsample(\n                            ch, conv_resample, dims=dims, out_channels=out_ch, dtype=self.dtype, device=device, operations=operations\n                        )\n                    )\n                )\n                ch = out_ch\n                input_block_chans.append(ch)\n                self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/cldm/cldm.py",
        "start": 258,
        "end": 276,
        "startLoc": {
          "line": 258,
          "column": 29,
          "position": 2655
        },
        "endLoc": {
          "line": 276,
          "column": 5,
          "position": 2779
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ldm/modules/diffusionmodules/openaimodel.py",
        "start": 677,
        "end": 695,
        "startLoc": {
          "line": 677,
          "column": 2,
          "position": 5297
        },
        "endLoc": {
          "line": 695,
          "column": 3,
          "position": 5421
        }
      }
    },
    {
      "format": "yaml",
      "lines": 10,
      "fragment": "runs-on: ${{ matrix.runner_label }}\n    steps:\n      - name: Test Workflows\n        uses: comfy-org/comfy-action@main\n        with:\n          os: ${{ matrix.os }}\n          python_version: ${{ matrix.python_version }}\n          torch_version: ${{ matrix.torch_version }}\n          google_credentials: ${{ secrets.GCS_SERVICE_ACCOUNT_JSON }}\n          comfyui_flags: ${{ matrix.flags }}",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/test-ci.yml",
        "start": 87,
        "end": 96,
        "startLoc": {
          "line": 87,
          "column": 5,
          "position": 498
        },
        "endLoc": {
          "line": 96,
          "column": 2,
          "position": 601
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/test-ci.yml",
        "start": 38,
        "end": 47,
        "startLoc": {
          "line": 38,
          "column": 5,
          "position": 213
        },
        "endLoc": {
          "line": 47,
          "column": 2,
          "position": 316
        }
      }
    },
    {
      "format": "yaml",
      "lines": 18,
      "fragment": "git clone --depth 1 https://github.com/comfyanonymous/taesd\n          cp taesd/*.safetensors ./ComfyUI_copy/models/vae_approx/\n\n          mkdir ComfyUI_windows_portable\n          mv python_embeded ComfyUI_windows_portable\n          mv ComfyUI_copy ComfyUI_windows_portable/ComfyUI\n\n          cd ComfyUI_windows_portable\n\n          mkdir update\n          cp -r ComfyUI/.ci/update_windows/* ./update/\n          cp -r ComfyUI/.ci/windows_base_files/* ./\n          cp ../update_comfyui_and_python_dependencies.bat ./update/\n\n          cd ..\n\n          \"C:\\Program Files\\7-Zip\\7z.exe\" a -t7z -m0=lzma2 -mx=9 -mfb=128 -md=512m -ms=on -mf=BCJ2 ComfyUI_windows_portable.7z ComfyUI_windows_portable\n          mv ComfyUI_windows_portable.7z ComfyUI/ComfyUI_windows_portable_nvidia.7z",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/stable-release.yml",
        "start": 72,
        "end": 89,
        "startLoc": {
          "line": 72,
          "column": 11,
          "position": 295
        },
        "endLoc": {
          "line": 89,
          "column": 43,
          "position": 423
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/windows_release_package.yml",
        "start": 69,
        "end": 86,
        "startLoc": {
          "line": 69,
          "column": 13,
          "position": 266
        },
        "endLoc": {
          "line": 86,
          "column": 48,
          "position": 394
        }
      }
    },
    {
      "format": "yaml",
      "lines": 12,
      "fragment": "cd ComfyUI_windows_portable\n          python_embeded/python.exe -s ComfyUI/main.py --quick-test-for-ci --cpu\n\n          python_embeded/python.exe -s ./update/update.py ComfyUI/\n\n          ls\n\n      - name: Upload binaries to release\n        uses: svenstaro/upload-release-action@v2\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ComfyUI_windows_portable_nvidia.7z",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/stable-release.yml",
        "start": 91,
        "end": 102,
        "startLoc": {
          "line": 91,
          "column": 11,
          "position": 427
        },
        "endLoc": {
          "line": 102,
          "column": 35,
          "position": 514
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/windows_release_package.yml",
        "start": 88,
        "end": 99,
        "startLoc": {
          "line": 88,
          "column": 13,
          "position": 406
        },
        "endLoc": {
          "line": 99,
          "column": 40,
          "position": 493
        }
      }
    },
    {
      "format": "yaml",
      "lines": 12,
      "fragment": "]\n        python_version: [\"3.9\", \"3.10\", \"3.11\", \"3.12\"]\n        cuda_version: [\"12.1\"]\n        torch_version: [\"stable\"]\n        include:\n          - os: macos\n            runner_label: [self-hosted, macOS]\n            flags: \"--use-pytorch-cross-attention\"\n          - os: linux\n            runner_label: [self-hosted, Linux]\n            flags: \"\"\n          -",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/pullrequest-ci-run.yml",
        "start": 14,
        "end": 25,
        "startLoc": {
          "line": 14,
          "column": 8,
          "position": 87
        },
        "endLoc": {
          "line": 25,
          "column": 2,
          "position": 181
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/test-ci.yml",
        "start": 24,
        "end": 35,
        "startLoc": {
          "line": 24,
          "column": 6,
          "position": 110
        },
        "endLoc": {
          "line": 35,
          "column": 16,
          "position": 204
        }
      }
    },
    {
      "format": "yaml",
      "lines": 13,
      "fragment": "]\n            flags: \"\"\n    runs-on: ${{ matrix.runner_label }}\n    steps:\n      - name: Test Workflows\n        uses: comfy-org/comfy-action@main\n        with:\n          os: ${{ matrix.os }}\n          python_version: ${{ matrix.python_version }}\n          torch_version: ${{ matrix.torch_version }}\n          google_credentials: ${{ secrets.GCS_SERVICE_ACCOUNT_JSON }}\n          comfyui_flags: ${{ matrix.flags }}\n          use_prior_commit",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/pullrequest-ci-run.yml",
        "start": 26,
        "end": 38,
        "startLoc": {
          "line": 26,
          "column": 8,
          "position": 199
        },
        "endLoc": {
          "line": 38,
          "column": 17,
          "position": 314
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/workflows/test-ci.yml",
        "start": 85,
        "end": 49,
        "startLoc": {
          "line": 85,
          "column": 6,
          "position": 489
        },
        "endLoc": {
          "line": 49,
          "column": 20,
          "position": 320
        }
      }
    },
    {
      "format": "yaml",
      "lines": 12,
      "fragment": "If unsure, ask on the [ComfyUI Matrix Space](https://app.element.io/#/room/%23comfyui_space%3Amatrix.org) or the [Comfy Org Discord](https://discord.gg/comfyorg) first.\n  - type: checkboxes\n    id: custom-nodes-test\n    attributes:\n      label: Custom Node Testing\n      description: Please confirm you have tried to reproduce the issue with all custom nodes disabled.\n      options:\n        - label: I have tried disabling custom nodes and the issue persists (see [how to disable custom nodes](https://docs.comfy.org/troubleshooting/custom-node-issues#step-1%3A-test-with-all-custom-nodes-disabled) if you need help)\n          required: true\n  - type: textarea\n    attributes:\n      label: Expected",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/ISSUE_TEMPLATE/bug-report.yml",
        "start": 17,
        "end": 28,
        "startLoc": {
          "line": 17,
          "column": 9,
          "position": 264
        },
        "endLoc": {
          "line": 28,
          "column": 9,
          "position": 425
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/.github/ISSUE_TEMPLATE/user-support.yml",
        "start": 13,
        "end": 24,
        "startLoc": {
          "line": 13,
          "column": 17,
          "position": 132
        },
        "endLoc": {
          "line": 24,
          "column": 5,
          "position": 293
        }
      }
    },
    {
      "format": "python",
      "lines": 29,
      "fragment": "import websocket #NOTE: websocket-client (https://github.com/websocket-client/websocket-client)\nimport uuid\nimport json\nimport urllib.request\nimport urllib.parse\n\nserver_address = \"127.0.0.1:8188\"\nclient_id = str(uuid.uuid4())\n\ndef queue_prompt(prompt):\n    p = {\"prompt\": prompt, \"client_id\": client_id}\n    data = json.dumps(p).encode('utf-8')\n    req =  urllib.request.Request(\"http://{}/prompt\".format(server_address), data=data)\n    return json.loads(urllib.request.urlopen(req).read())\n\ndef get_image(filename, subfolder, folder_type):\n    data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n    url_values = urllib.parse.urlencode(data)\n    with urllib.request.urlopen(\"http://{}/view?{}\".format(server_address, url_values)) as response:\n        return response.read()\n\ndef get_history(prompt_id):\n    with urllib.request.urlopen(\"http://{}/history/{}\".format(server_address, prompt_id)) as response:\n        return json.loads(response.read())\n\ndef get_images(ws, prompt):\n    prompt_id = queue_prompt(prompt)['prompt_id']\n    output_images = {}\n    while",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/script_examples/websockets_api_example.py",
        "start": 4,
        "end": 32,
        "startLoc": {
          "line": 4,
          "column": 1,
          "position": 5
        },
        "endLoc": {
          "line": 32,
          "column": 6,
          "position": 309
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/script_examples/websockets_api_example_ws_images.py",
        "start": 4,
        "end": 32,
        "startLoc": {
          "line": 4,
          "column": 1,
          "position": 5
        },
        "endLoc": {
          "line": 32,
          "column": 13,
          "position": 309
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "ws.recv()\n        if isinstance(out, str):\n            message = json.loads(out)\n            if message['type'] == 'executing':\n                data = message['data']\n                if data['node'] is None and data['prompt_id'] == prompt_id:\n                    break #Execution is done\n        else:\n            # If you want to be able to decode the binary stream for latent previews, here is how you can do it:",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/script_examples/websockets_api_example.py",
        "start": 33,
        "end": 41,
        "startLoc": {
          "line": 33,
          "column": 2,
          "position": 319
        },
        "endLoc": {
          "line": 41,
          "column": 101,
          "position": 406
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/tests/inference/test_inference.py",
        "start": 100,
        "end": 108,
        "startLoc": {
          "line": 100,
          "column": 2,
          "position": 919
        },
        "endLoc": {
          "line": 108,
          "column": 9,
          "position": 1006
        }
      }
    },
    {
      "format": "python",
      "lines": 19,
      "fragment": "prompt = json.loads(prompt_text)\n#set the text prompt for our positive CLIPTextEncode\nprompt[\"6\"][\"inputs\"][\"text\"] = \"masterpiece best quality man\"\n\n#set the seed for our KSampler node\nprompt[\"3\"][\"inputs\"][\"seed\"] = 5\n\nws = websocket.WebSocket()\nws.connect(\"ws://{}/ws?clientId={}\".format(server_address, client_id))\nimages = get_images(ws, prompt)\nws.close() # for in case this example is used in an environment where it will be repeatedly called, like in a Gradio app. otherwise, you'll randomly receive connection timeouts\n#Commented out code to display the output images:\n\n# for node_id in images:\n#     for image_data in images[node_id]:\n#         from PIL import Image\n#         import io\n#         image = Image.open(io.BytesIO(image_data))\n#         image.show()",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/script_examples/websockets_api_example.py",
        "start": 147,
        "end": 165,
        "startLoc": {
          "line": 147,
          "column": 1,
          "position": 547
        },
        "endLoc": {
          "line": 165,
          "column": 23,
          "position": 652
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/script_examples/websockets_api_example_ws_images.py",
        "start": 140,
        "end": 158,
        "startLoc": {
          "line": 140,
          "column": 1,
          "position": 490
        },
        "endLoc": {
          "line": 158,
          "column": 23,
          "position": 595
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"positive\": (\"CONDITIONING\", ),\n                             \"negative\": (\"CONDITIONING\", ),\n                             \"vae\": (\"VAE\", ),\n                             \"width\": (\"INT\", {\"default\": 832, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"height\": (\"INT\", {\"default\": 480, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"length\": (\"INT\", {\"default\": 81, \"min\": 1, \"max\": nodes.MAX_RESOLUTION, \"step\": 4}),\n                             \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                },\n                \"optional\": {\"clip_vision_output\": (\"CLIP_VISION_OUTPUT\", ),\n                             \"start_image\": (\"IMAGE\", ),\n                             \"control_video\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 54,
        "end": 67,
        "startLoc": {
          "line": 54,
          "column": 21,
          "position": 805
        },
        "endLoc": {
          "line": 67,
          "column": 16,
          "position": 1031
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 10,
        "end": 23,
        "startLoc": {
          "line": 10,
          "column": 16,
          "position": 41
        },
        "endLoc": {
          "line": 23,
          "column": 2,
          "position": 267
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ": (\"IMAGE\", ),\n                }}\n\n    RETURN_TYPES = (\"CONDITIONING\", \"CONDITIONING\", \"LATENT\")\n    RETURN_NAMES = (\"positive\", \"negative\", \"latent\")\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning/video_models\"\n\n    def encode(self, positive, negative, vae, width, height, length, batch_size, start_image=None, clip_vision_output=None,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 67,
        "end": 76,
        "startLoc": {
          "line": 67,
          "column": 16,
          "position": 1032
        },
        "endLoc": {
          "line": 76,
          "column": 2,
          "position": 1129
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 22,
        "end": 31,
        "startLoc": {
          "line": 22,
          "column": 14,
          "position": 257
        },
        "endLoc": {
          "line": 31,
          "column": 2,
          "position": 354
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "})\n\n        if clip_vision_output is not None:\n            positive = node_helpers.conditioning_set_values(positive, {\"clip_vision_output\": clip_vision_output})\n            negative = node_helpers.conditioning_set_values(negative, {\"clip_vision_output\": clip_vision_output})\n\n        out_latent = {}\n        out_latent[\"samples\"] = latent\n        return (positive, negative, out_latent)\n\nclass WanFirstLastFrameToVideo",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 93,
        "end": 103,
        "startLoc": {
          "line": 93,
          "column": 14,
          "position": 1579
        },
        "endLoc": {
          "line": 103,
          "column": 25,
          "position": 1670
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 43,
        "end": 54,
        "startLoc": {
          "line": 43,
          "column": 5,
          "position": 712
        },
        "endLoc": {
          "line": 54,
          "column": 21,
          "position": 804
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"positive\": (\"CONDITIONING\", ),\n                             \"negative\": (\"CONDITIONING\", ),\n                             \"vae\": (\"VAE\", ),\n                             \"width\": (\"INT\", {\"default\": 832, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"height\": (\"INT\", {\"default\": 480, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"length\": (\"INT\", {\"default\": 81, \"min\": 1, \"max\": nodes.MAX_RESOLUTION, \"step\": 4}),\n                             \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                },\n                \"optional\": {\"clip_vision_start_image\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 103,
        "end": 114,
        "startLoc": {
          "line": 103,
          "column": 25,
          "position": 1671
        },
        "endLoc": {
          "line": 114,
          "column": 26,
          "position": 1875
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 10,
        "end": 21,
        "startLoc": {
          "line": 10,
          "column": 16,
          "position": 41
        },
        "endLoc": {
          "line": 21,
          "column": 21,
          "position": 245
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ": (\"IMAGE\", ),\n                }}\n\n    RETURN_TYPES = (\"CONDITIONING\", \"CONDITIONING\", \"LATENT\")\n    RETURN_NAMES = (\"positive\", \"negative\", \"latent\")\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning/video_models\"\n\n    def encode(self, positive, negative, vae, width, height, length, batch_size, start_image=None, end_image",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 117,
        "end": 126,
        "startLoc": {
          "line": 117,
          "column": 12,
          "position": 1909
        },
        "endLoc": {
          "line": 126,
          "column": 10,
          "position": 2003
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 22,
        "end": 31,
        "startLoc": {
          "line": 22,
          "column": 14,
          "position": 257
        },
        "endLoc": {
          "line": 31,
          "column": 19,
          "position": 351
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "if clip_vision_output is not None:\n            positive = node_helpers.conditioning_set_values(positive, {\"clip_vision_output\": clip_vision_output})\n            negative = node_helpers.conditioning_set_values(negative, {\"clip_vision_output\": clip_vision_output})\n\n        out_latent = {}\n        out_latent[\"samples\"] = latent\n        return (positive, negative, out_latent)\n\n\nclass WanFunInpaintToVideo",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 160,
        "end": 169,
        "startLoc": {
          "line": 160,
          "column": 9,
          "position": 2620
        },
        "endLoc": {
          "line": 169,
          "column": 21,
          "position": 2707
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 45,
        "end": 54,
        "startLoc": {
          "line": 45,
          "column": 9,
          "position": 717
        },
        "endLoc": {
          "line": 54,
          "column": 21,
          "position": 804
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"positive\": (\"CONDITIONING\", ),\n                             \"negative\": (\"CONDITIONING\", ),\n                             \"vae\": (\"VAE\", ),\n                             \"width\": (\"INT\", {\"default\": 832, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"height\": (\"INT\", {\"default\": 480, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"length\": (\"INT\", {\"default\": 81, \"min\": 1, \"max\": nodes.MAX_RESOLUTION, \"step\": 4}),\n                             \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                },\n                \"optional\": {\"clip_vision_output\": (\"CLIP_VISION_OUTPUT\", ),\n                             \"start_image\": (\"IMAGE\", ),\n                             \"end_image\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 169,
        "end": 182,
        "startLoc": {
          "line": 169,
          "column": 21,
          "position": 2708
        },
        "endLoc": {
          "line": 182,
          "column": 12,
          "position": 2934
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 10,
        "end": 23,
        "startLoc": {
          "line": 10,
          "column": 16,
          "position": 41
        },
        "endLoc": {
          "line": 23,
          "column": 2,
          "position": 267
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": ": (\"CLIP_VISION_OUTPUT\", ),\n                             \"start_image\": (\"IMAGE\", ),\n                             \"end_image\": (\"IMAGE\", ),\n                }}\n\n    RETURN_TYPES = (\"CONDITIONING\", \"CONDITIONING\", \"LATENT\")\n    RETURN_NAMES = (\"positive\", \"negative\", \"latent\")\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning/video_models\"\n\n    def encode(self, positive, negative, vae, width, height, length, batch_size, start_image=None, end_image=None, clip_vision_output",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 180,
        "end": 191,
        "startLoc": {
          "line": 180,
          "column": 21,
          "position": 2913
        },
        "endLoc": {
          "line": 191,
          "column": 19,
          "position": 3034
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 115,
        "end": 126,
        "startLoc": {
          "line": 115,
          "column": 24,
          "position": 1887
        },
        "endLoc": {
          "line": 126,
          "column": 24,
          "position": 2008
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"positive\": (\"CONDITIONING\", ),\n                             \"negative\": (\"CONDITIONING\", ),\n                             \"vae\": (\"VAE\", ),\n                             \"width\": (\"INT\", {\"default\": 832, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"height\": (\"INT\", {\"default\": 480, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"length\": (\"INT\", {\"default\": 81, \"min\": 1, \"max\": nodes.MAX_RESOLUTION, \"step\": 4}),\n                             \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                             \"strength\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 196,
        "end": 206,
        "startLoc": {
          "line": 196,
          "column": 15,
          "position": 3097
        },
        "endLoc": {
          "line": 206,
          "column": 11,
          "position": 3293
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 10,
        "end": 20,
        "startLoc": {
          "line": 10,
          "column": 16,
          "position": 41
        },
        "endLoc": {
          "line": 20,
          "column": 2,
          "position": 237
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"positive\": (\"CONDITIONING\", ),\n                             \"negative\": (\"CONDITIONING\", ),\n                             \"vae\": (\"VAE\", ),\n                             \"width\": (\"INT\", {\"default\": 832, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"height\": (\"INT\", {\"default\": 480, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"length\": (\"INT\", {\"default\": 81, \"min\": 1, \"max\": nodes.MAX_RESOLUTION, \"step\": 4}),\n                             \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                },\n                \"optional\": {\"clip_vision_output\": (\"CLIP_VISION_OUTPUT\", ),\n                             \"start_image\": (\"IMAGE\", ),\n                             \"camera_conditions\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 301,
        "end": 314,
        "startLoc": {
          "line": 301,
          "column": 22,
          "position": 4725
        },
        "endLoc": {
          "line": 314,
          "column": 20,
          "position": 4951
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 10,
        "end": 23,
        "startLoc": {
          "line": 10,
          "column": 16,
          "position": 41
        },
        "endLoc": {
          "line": 23,
          "column": 2,
          "position": 267
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ", ),\n                }}\n\n    RETURN_TYPES = (\"CONDITIONING\", \"CONDITIONING\", \"LATENT\")\n    RETURN_NAMES = (\"positive\", \"negative\", \"latent\")\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning/video_models\"\n\n    def encode(self, positive, negative, vae, width, height, length, batch_size, start_image=None, clip_vision_output=None, camera_conditions",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 314,
        "end": 323,
        "startLoc": {
          "line": 314,
          "column": 23,
          "position": 4956
        },
        "endLoc": {
          "line": 323,
          "column": 18,
          "position": 5051
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 22,
        "end": 76,
        "startLoc": {
          "line": 22,
          "column": 8,
          "position": 261
        },
        "endLoc": {
          "line": 76,
          "column": 14,
          "position": 1131
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "=None):\n        latent = torch.zeros([batch_size, 16, ((length - 1) // 4) + 1, height // 8, width // 8], device=comfy.model_management.intermediate_device())\n        concat_latent = torch.zeros([batch_size, 16, ((length - 1) // 4) + 1, height // 8, width // 8], device=comfy.model_management.intermediate_device())\n        concat_latent = comfy.latent_formats.Wan21().process_out(concat_latent)\n\n        if",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 323,
        "end": 328,
        "startLoc": {
          "line": 323,
          "column": 18,
          "position": 5052
        },
        "endLoc": {
          "line": 328,
          "column": 3,
          "position": 5199
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 76,
        "end": 80,
        "startLoc": {
          "line": 76,
          "column": 14,
          "position": 1132
        },
        "endLoc": {
          "line": 80,
          "column": 14,
          "position": 1278
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ")\n\n        if start_image is not None:\n            start_image = comfy.utils.common_upscale(start_image[:length].movedim(-1, 1), width, height, \"bilinear\", \"center\").movedim(1, -1)\n            concat_latent_image = vae.encode(start_image[:, :, :, :3])\n            concat_latent[:,:",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 326,
        "end": 331,
        "startLoc": {
          "line": 326,
          "column": 14,
          "position": 5195
        },
        "endLoc": {
          "line": 331,
          "column": 2,
          "position": 5288
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 80,
        "end": 85,
        "startLoc": {
          "line": 80,
          "column": 2,
          "position": 1299
        },
        "endLoc": {
          "line": 85,
          "column": 3,
          "position": 1392
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ",:concat_latent_image.shape[2]] = concat_latent_image[:,:,:concat_latent.shape[2]]\n\n            positive = node_helpers.conditioning_set_values(positive, {\"concat_latent_image\": concat_latent})\n            negative = node_helpers.conditioning_set_values(negative, {\"concat_latent_image\": concat_latent})\n\n        if camera_conditions",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 331,
        "end": 336,
        "startLoc": {
          "line": 331,
          "column": 2,
          "position": 5289
        },
        "endLoc": {
          "line": 336,
          "column": 18,
          "position": 5361
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 90,
        "end": 95,
        "startLoc": {
          "line": 90,
          "column": 3,
          "position": 1514
        },
        "endLoc": {
          "line": 95,
          "column": 19,
          "position": 1586
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "})\n\n        if clip_vision_output is not None:\n            positive = node_helpers.conditioning_set_values(positive, {\"clip_vision_output\": clip_vision_output})\n            negative = node_helpers.conditioning_set_values(negative, {\"clip_vision_output\": clip_vision_output})\n\n        out_latent = {}\n        out_latent[\"samples\"] = latent\n        return (positive, negative, out_latent)\n\nclass WanPhantomSubjectToVideo",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 338,
        "end": 348,
        "startLoc": {
          "line": 338,
          "column": 18,
          "position": 5407
        },
        "endLoc": {
          "line": 348,
          "column": 25,
          "position": 5498
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 43,
        "end": 54,
        "startLoc": {
          "line": 43,
          "column": 5,
          "position": 712
        },
        "endLoc": {
          "line": 54,
          "column": 21,
          "position": 804
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"positive\": (\"CONDITIONING\", ),\n                             \"negative\": (\"CONDITIONING\", ),\n                             \"vae\": (\"VAE\", ),\n                             \"width\": (\"INT\", {\"default\": 832, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"height\": (\"INT\", {\"default\": 480, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                             \"length\": (\"INT\", {\"default\": 81, \"min\": 1, \"max\": nodes.MAX_RESOLUTION, \"step\": 4}),\n                             \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                },\n                \"optional\": {\"images\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 348,
        "end": 359,
        "startLoc": {
          "line": 348,
          "column": 25,
          "position": 5499
        },
        "endLoc": {
          "line": 359,
          "column": 9,
          "position": 5703
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_wan.py",
        "start": 10,
        "end": 21,
        "startLoc": {
          "line": 10,
          "column": 16,
          "position": 41
        },
        "endLoc": {
          "line": 21,
          "column": 21,
          "position": 245
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"model\": (\"MODEL\",),\n                              \"min_cfg\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.5, \"round\": 0.01}),\n                              }}\n    RETURN_TYPES = (\"MODEL\",)\n    FUNCTION = \"patch\"\n\n    CATEGORY = \"sampling/video_models\"\n\n    def patch(self, model, min_cfg):\n        def linear_cfg(args):\n            cond = args[\"cond\"]\n            uncond = args[\"uncond\"]\n            cond_scale = args[\"cond_scale\"]\n            period",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_video_model.py",
        "start": 83,
        "end": 99,
        "startLoc": {
          "line": 83,
          "column": 25,
          "position": 1071
        },
        "endLoc": {
          "line": 99,
          "column": 7,
          "position": 1229
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_video_model.py",
        "start": 59,
        "end": 76,
        "startLoc": {
          "line": 59,
          "column": 23,
          "position": 810
        },
        "endLoc": {
          "line": 76,
          "column": 6,
          "position": 969
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "):\n        output = clip_vision.encode_image(init_image)\n        pooled = output.image_embeds.unsqueeze(0)\n        pixels = comfy.utils.common_upscale(init_image.movedim(-1,1), width, height, \"bilinear\", \"center\").movedim(1,-1)\n        encode_pixels = pixels[:,:,:,:3]\n        t",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 42,
        "end": 47,
        "startLoc": {
          "line": 42,
          "column": 8,
          "position": 494
        },
        "endLoc": {
          "line": 47,
          "column": 2,
          "position": 583
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_video_model.py",
        "start": 46,
        "end": 51,
        "startLoc": {
          "line": 46,
          "column": 19,
          "position": 548
        },
        "endLoc": {
          "line": 51,
          "column": 3,
          "position": 637
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"clip_vision\": (\"CLIP_VISION\",),\n                              \"init_image\": (\"IMAGE\",),\n                              \"vae\": (\"VAE\",),\n                              \"width\": (\"INT\", {\"default\": 256, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 8}),\n                              \"height\": (\"INT\", {\"default\": 256, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 8}),\n                              \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                              \"elevation\": (\"FLOAT\", {\"default\": 0.0, \"min\": -180.0, \"max\": 180.0, \"step\": 0.1, \"round\": False}),\n                              \"azimuth\": (\"FLOAT\", {\"default\": 0.0, \"min\": -180.0, \"max\": 180.0, \"step\": 0.1, \"round\": False}),\n                              \"elevation_batch_increment\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 56,
        "end": 67,
        "startLoc": {
          "line": 56,
          "column": 35,
          "position": 756
        },
        "endLoc": {
          "line": 67,
          "column": 28,
          "position": 997
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 23,
        "end": 34,
        "startLoc": {
          "line": 23,
          "column": 27,
          "position": 173
        },
        "endLoc": {
          "line": 34,
          "column": 2,
          "position": 414
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ": (\"FLOAT\", {\"default\": 0.0, \"min\": -180.0, \"max\": 180.0, \"step\": 0.1, \"round\": False}),\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\", \"CONDITIONING\", \"LATENT\")\n    RETURN_NAMES = (\"positive\", \"negative\", \"latent\")\n\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning/3d_models\"\n\n    def encode(self, clip_vision, init_image, vae, width, height, batch_size, elevation, azimuth,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 68,
        "end": 77,
        "startLoc": {
          "line": 68,
          "column": 26,
          "position": 1040
        },
        "endLoc": {
          "line": 77,
          "column": 2,
          "position": 1161
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 33,
        "end": 42,
        "startLoc": {
          "line": 33,
          "column": 10,
          "position": 373
        },
        "endLoc": {
          "line": 42,
          "column": 2,
          "position": 494
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "):\n        output = clip_vision.encode_image(init_image)\n        pooled = output.image_embeds.unsqueeze(0)\n        pixels = comfy.utils.common_upscale(init_image.movedim(-1,1), width, height, \"bilinear\", \"center\").movedim(1,-1)\n        encode_pixels = pixels[:,:,:,:3]\n        t = vae.encode(encode_pixels)\n\n        cam_embeds = [",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 77,
        "end": 84,
        "startLoc": {
          "line": 77,
          "column": 24,
          "position": 1167
        },
        "endLoc": {
          "line": 84,
          "column": 2,
          "position": 1273
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_video_model.py",
        "start": 46,
        "end": 48,
        "startLoc": {
          "line": 46,
          "column": 19,
          "position": 548
        },
        "endLoc": {
          "line": 48,
          "column": 18,
          "position": 599
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": "], dim=-1)\n\n        positive = [[cond, {\"concat_latent_image\": t}]]\n        negative = [[torch.zeros_like(pooled), {\"concat_latent_image\": torch.zeros_like(t)}]]\n        latent = torch.zeros([batch_size, 4, height // 8, width // 8])\n        return (positive, negative, {\"samples\":latent,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 91,
        "end": 96,
        "startLoc": {
          "line": 91,
          "column": 11,
          "position": 1359
        },
        "endLoc": {
          "line": 96,
          "column": 2,
          "position": 1462
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 49,
        "end": 54,
        "startLoc": {
          "line": 49,
          "column": 2,
          "position": 646
        },
        "endLoc": {
          "line": 54,
          "column": 2,
          "position": 749
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ", \"step\": 0.1, \"round\": False}),\n                             }}\n    RETURN_TYPES = (\"CONDITIONING\", \"CONDITIONING\", \"LATENT\")\n    RETURN_NAMES = (\"positive\", \"negative\", \"latent\")\n\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning/3d_models\"\n\n    def encode(self, clip_vision, init_image, vae, width, height, video_frames",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 107,
        "end": 116,
        "startLoc": {
          "line": 107,
          "column": 5,
          "position": 1663
        },
        "endLoc": {
          "line": 116,
          "column": 13,
          "position": 1753
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 33,
        "end": 42,
        "startLoc": {
          "line": 33,
          "column": 6,
          "position": 397
        },
        "endLoc": {
          "line": 42,
          "column": 11,
          "position": 487
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "):\n        output = clip_vision.encode_image(init_image)\n        pooled = output.image_embeds.unsqueeze(0)\n        pixels = comfy.utils.common_upscale(init_image.movedim(-1,1), width, height, \"bilinear\", \"center\").movedim(1,-1)\n        encode_pixels = pixels[:,:,:,:3]\n        t = vae.encode(encode_pixels)\n\n        azimuth",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_stable3d.py",
        "start": 116,
        "end": 123,
        "startLoc": {
          "line": 116,
          "column": 10,
          "position": 1757
        },
        "endLoc": {
          "line": 123,
          "column": 8,
          "position": 1859
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_video_model.py",
        "start": 46,
        "end": 48,
        "startLoc": {
          "line": 46,
          "column": 19,
          "position": 548
        },
        "endLoc": {
          "line": 48,
          "column": 11,
          "position": 595
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "(comfy_extras.nodes_model_merging.ModelMergeBlocks):\n    CATEGORY = \"advanced/model_merging/model_specific\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"time_embed.\"] = argument\n        arg_dict[\"label_emb.\"] = argument\n\n        for i in range(9",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 29,
        "end": 42,
        "startLoc": {
          "line": 29,
          "column": 15,
          "position": 236
        },
        "endLoc": {
          "line": 42,
          "column": 2,
          "position": 359
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 3,
        "end": 15,
        "startLoc": {
          "line": 3,
          "column": 14,
          "position": 10
        },
        "endLoc": {
          "line": 15,
          "column": 3,
          "position": 132
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "(comfy_extras.nodes_model_merging.ModelMergeBlocks):\n    CATEGORY = \"advanced/model_merging/model_specific\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"pos_embed.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 55,
        "end": 65,
        "startLoc": {
          "line": 55,
          "column": 17,
          "position": 462
        },
        "endLoc": {
          "line": 65,
          "column": 13,
          "position": 558
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 3,
        "end": 12,
        "startLoc": {
          "line": 3,
          "column": 14,
          "position": 10
        },
        "endLoc": {
          "line": 12,
          "column": 14,
          "position": 105
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "(comfy_extras.nodes_model_merging.ModelMergeBlocks):\n    CATEGORY = \"advanced/model_merging/model_specific\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"init_x_linear.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 79,
        "end": 89,
        "startLoc": {
          "line": 79,
          "column": 19,
          "position": 661
        },
        "endLoc": {
          "line": 89,
          "column": 17,
          "position": 757
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 3,
        "end": 12,
        "startLoc": {
          "line": 3,
          "column": 14,
          "position": 10
        },
        "endLoc": {
          "line": 12,
          "column": 14,
          "position": 105
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "(comfy_extras.nodes_model_merging.ModelMergeBlocks):\n    CATEGORY = \"advanced/model_merging/model_specific\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"img_in.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 106,
        "end": 116,
        "startLoc": {
          "line": 106,
          "column": 16,
          "position": 898
        },
        "endLoc": {
          "line": 116,
          "column": 10,
          "position": 994
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 3,
        "end": 12,
        "startLoc": {
          "line": 3,
          "column": 14,
          "position": 10
        },
        "endLoc": {
          "line": 12,
          "column": 14,
          "position": 105
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": "(comfy_extras.nodes_model_merging.ModelMergeBlocks):\n    CATEGORY = \"advanced/model_merging/model_specific\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"pos_embed.\"] = argument\n        arg_dict[\"x_embedder.\"] = argument\n        arg_dict[\"context_embedder.\"] = argument\n        arg_dict[\"y_embedder.\"] = argument\n        arg_dict[\"t_embedder.\"] = argument\n\n        for i in range(38",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 132,
        "end": 148,
        "startLoc": {
          "line": 132,
          "column": 21,
          "position": 1125
        },
        "endLoc": {
          "line": 148,
          "column": 3,
          "position": 1278
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 3,
        "end": 71,
        "startLoc": {
          "line": 3,
          "column": 14,
          "position": 10
        },
        "endLoc": {
          "line": 71,
          "column": 3,
          "position": 615
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "(comfy_extras.nodes_model_merging.ModelMergeBlocks):\n    CATEGORY = \"advanced/model_merging/model_specific\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"pos_frequencies.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 155,
        "end": 165,
        "startLoc": {
          "line": 155,
          "column": 23,
          "position": 1323
        },
        "endLoc": {
          "line": 165,
          "column": 19,
          "position": 1419
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 3,
        "end": 12,
        "startLoc": {
          "line": 3,
          "column": 14,
          "position": 10
        },
        "endLoc": {
          "line": 12,
          "column": 14,
          "position": 105
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "(comfy_extras.nodes_model_merging.ModelMergeBlocks):\n    CATEGORY = \"advanced/model_merging/model_specific\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"patchify_proj.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 177,
        "end": 187,
        "startLoc": {
          "line": 177,
          "column": 15,
          "position": 1511
        },
        "endLoc": {
          "line": 187,
          "column": 17,
          "position": 1607
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 3,
        "end": 12,
        "startLoc": {
          "line": 3,
          "column": 14,
          "position": 10
        },
        "endLoc": {
          "line": 12,
          "column": 14,
          "position": 105
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "(comfy_extras.nodes_model_merging.ModelMergeBlocks):\n    CATEGORY = \"advanced/model_merging/model_specific\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"pos_embedder.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 199,
        "end": 209,
        "startLoc": {
          "line": 199,
          "column": 19,
          "position": 1699
        },
        "endLoc": {
          "line": 209,
          "column": 16,
          "position": 1795
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 3,
        "end": 12,
        "startLoc": {
          "line": 3,
          "column": 14,
          "position": 10
        },
        "endLoc": {
          "line": 12,
          "column": 14,
          "position": 105
        }
      }
    },
    {
      "format": "python",
      "lines": 18,
      "fragment": "(comfy_extras.nodes_model_merging.ModelMergeBlocks):\n    CATEGORY = \"advanced/model_merging/model_specific\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"pos_embedder.\"] = argument\n        arg_dict[\"extra_pos_embedder.\"] = argument\n        arg_dict[\"x_embedder.\"] = argument\n        arg_dict[\"t_embedder.\"] = argument\n        arg_dict[\"affline_norm.\"] = argument\n\n\n        for i in range(36",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 223,
        "end": 240,
        "startLoc": {
          "line": 223,
          "column": 20,
          "position": 1898
        },
        "endLoc": {
          "line": 240,
          "column": 3,
          "position": 2052
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 3,
        "end": 216,
        "startLoc": {
          "line": 3,
          "column": 14,
          "position": 10
        },
        "endLoc": {
          "line": 216,
          "column": 3,
          "position": 1853
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "@classmethod\n    def INPUT_TYPES(s):\n        arg_dict = { \"model1\": (\"MODEL\",),\n                              \"model2\": (\"MODEL\",)}\n\n        argument = (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01})\n\n        arg_dict[\"patch_embedding.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 251,
        "end": 258,
        "startLoc": {
          "line": 251,
          "column": 5,
          "position": 2122
        },
        "endLoc": {
          "line": 258,
          "column": 19,
          "position": 2200
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging_model_specific.py",
        "start": 5,
        "end": 12,
        "startLoc": {
          "line": 5,
          "column": 5,
          "position": 27
        },
        "endLoc": {
          "line": 12,
          "column": 14,
          "position": 105
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "):\n        m = clip1.clone()\n        kp = clip2.get_key_patches()\n        for k in kp:\n            if k.endswith(\".position_ids\") or k.endswith(\".logit_scale\"):\n                continue\n            m.add_patches({k: kp[k]}, -",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging.py",
        "start": 105,
        "end": 111,
        "startLoc": {
          "line": 105,
          "column": 11,
          "position": 959
        },
        "endLoc": {
          "line": 111,
          "column": 2,
          "position": 1033
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging.py",
        "start": 83,
        "end": 89,
        "startLoc": {
          "line": 83,
          "column": 6,
          "position": 737
        },
        "endLoc": {
          "line": 89,
          "column": 4,
          "position": 811
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "):\n        m = clip1.clone()\n        kp = clip2.get_key_patches()\n        for k in kp:\n            if k.endswith(\".position_ids\") or k.endswith(\".logit_scale\"):\n                continue\n            m.add_patches({k: kp[k]}, 1.0,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging.py",
        "start": 126,
        "end": 132,
        "startLoc": {
          "line": 126,
          "column": 6,
          "position": 1140
        },
        "endLoc": {
          "line": 132,
          "column": 2,
          "position": 1215
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging.py",
        "start": 83,
        "end": 89,
        "startLoc": {
          "line": 83,
          "column": 6,
          "position": 737
        },
        "endLoc": {
          "line": 89,
          "column": 2,
          "position": 813
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "if not args.disable_metadata:\n            metadata[\"prompt\"] = prompt_info\n            if extra_pnginfo is not None:\n                for x in extra_pnginfo:\n                    metadata[x] = json.dumps(extra_pnginfo[x])\n\n        output_checkpoint = f\"{filename}_{counter:05}_.safetensors\"\n        output_checkpoint = os.path.join(full_output_folder, output_checkpoint)\n\n        comfy.utils",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging.py",
        "start": 327,
        "end": 336,
        "startLoc": {
          "line": 327,
          "column": 9,
          "position": 3300
        },
        "endLoc": {
          "line": 336,
          "column": 6,
          "position": 3389
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_merging.py",
        "start": 216,
        "end": 225,
        "startLoc": {
          "line": 216,
          "column": 5,
          "position": 2137
        },
        "endLoc": {
          "line": 225,
          "column": 3,
          "position": 2226
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": ", \"min\": 0.0, \"max\": 1000.0, \"step\":0.001, \"round\": False}),\n                              }}\n\n    RETURN_TYPES = (\"MODEL\",)\n    FUNCTION = \"patch\"\n\n    CATEGORY = \"advanced/model\"\n\n    def patch(self, model, sampling, sigma_max, sigma_min):\n        m = model.clone()\n\n        sigma_data",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_advanced.py",
        "start": 235,
        "end": 246,
        "startLoc": {
          "line": 235,
          "column": 5,
          "position": 2496
        },
        "endLoc": {
          "line": 246,
          "column": 11,
          "position": 2588
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_advanced.py",
        "start": 194,
        "end": 205,
        "startLoc": {
          "line": 194,
          "column": 6,
          "position": 2086
        },
        "endLoc": {
          "line": 205,
          "column": 14,
          "position": 2178
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "}),\n                \"width\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                \"height\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": MAX_RESOLUTION, \"step\": 1}),\n            }\n        }\n\n    CATEGORY = \"mask\"\n\n    RETURN_TYPES = (\"MASK\",)\n\n    FUNCTION = \"crop\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_mask.py",
        "start": 205,
        "end": 215,
        "startLoc": {
          "line": 205,
          "column": 2,
          "position": 2250
        },
        "endLoc": {
          "line": 215,
          "column": 7,
          "position": 2355
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_mask.py",
        "start": 163,
        "end": 173,
        "startLoc": {
          "line": 163,
          "column": 5,
          "position": 1870
        },
        "endLoc": {
          "line": 173,
          "column": 8,
          "position": 1975
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": ") * mm + b\n\n        sampling_base = comfy.model_sampling.ModelSamplingFlux\n        sampling_type = comfy.model_sampling.CONST\n\n        class ModelSamplingAdvanced(sampling_base, sampling_type):\n            pass\n\n        model_sampling = ModelSamplingAdvanced(model.model.model_config)\n        model_sampling.set_parameters(shift=shift)\n        m.add_object_patch(\"model_sampling\", model_sampling)\n\n        return (m, )\n\n\nclass LTXVScheduler",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_lt.py",
        "start": 320,
        "end": 335,
        "startLoc": {
          "line": 320,
          "column": 7,
          "position": 3616
        },
        "endLoc": {
          "line": 335,
          "column": 14,
          "position": 3715
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_advanced.py",
        "start": 174,
        "end": 188,
        "startLoc": {
          "line": 174,
          "column": 2,
          "position": 1880
        },
        "endLoc": {
          "line": 188,
          "column": 27,
          "position": 1978
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "():\n    @classmethod\n    def INPUT_TYPES(s):\n        input_dir = os.path.join(folder_paths.get_input_directory(), \"3d\")\n\n        os.makedirs(input_dir, exist_ok=True)\n\n        files = [normalize_path(os.path.join(\"3d\", f)) for f in os.listdir(input_dir) if f.endswith(('.gltf', '.glb', '.fbx'",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_load_3d.py",
        "start": 57,
        "end": 64,
        "startLoc": {
          "line": 57,
          "column": 16,
          "position": 607
        },
        "endLoc": {
          "line": 64,
          "column": 7,
          "position": 707
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_load_3d.py",
        "start": 12,
        "end": 19,
        "startLoc": {
          "line": 12,
          "column": 7,
          "position": 60
        },
        "endLoc": {
          "line": 19,
          "column": 7,
          "position": 160
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", {}),\n            \"width\": (\"INT\", {\"default\": 1024, \"min\": 1, \"max\": 4096, \"step\": 1}),\n            \"height\": (\"INT\", {\"default\": 1024, \"min\": 1, \"max\": 4096, \"step\": 1}),\n        }}\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\", \"STRING\", \"IMAGE\", \"LOAD3D_CAMERA\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_load_3d.py",
        "start": 68,
        "end": 73,
        "startLoc": {
          "line": 68,
          "column": 20,
          "position": 748
        },
        "endLoc": {
          "line": 73,
          "column": 16,
          "position": 848
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_load_3d.py",
        "start": 23,
        "end": 28,
        "startLoc": {
          "line": 23,
          "column": 10,
          "position": 207
        },
        "endLoc": {
          "line": 28,
          "column": 8,
          "position": 307
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": ", \"camera_info\", \"recording_video\")\n\n    FUNCTION = \"process\"\n    EXPERIMENTAL = True\n\n    CATEGORY = \"3d\"\n\n    def process(self, model_file, image, **kwargs):\n        image_path = folder_paths.get_annotated_filepath(image['image'])\n        mask_path = folder_paths.get_annotated_filepath(image['mask'])\n        normal_path = folder_paths.get_annotated_filepath(image['normal'])\n\n        load_image_node",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_load_3d.py",
        "start": 74,
        "end": 86,
        "startLoc": {
          "line": 74,
          "column": 9,
          "position": 872
        },
        "endLoc": {
          "line": 86,
          "column": 16,
          "position": 970
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_load_3d.py",
        "start": 29,
        "end": 40,
        "startLoc": {
          "line": 29,
          "column": 10,
          "position": 337
        },
        "endLoc": {
          "line": 40,
          "column": 13,
          "position": 434
        }
      }
    },
    {
      "format": "python",
      "lines": 28,
      "fragment": "():\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\n            \"model_file\": (\"STRING\", {\"default\": \"\", \"multiline\": False}),\n        },\n        \"optional\": {\n            \"camera_info\": (\"LOAD3D_CAMERA\", {})\n        }}\n\n    OUTPUT_NODE = True\n    RETURN_TYPES = ()\n\n    CATEGORY = \"3d\"\n\n    FUNCTION = \"process\"\n    EXPERIMENTAL = True\n\n    def process(self, model_file, **kwargs):\n        camera_info = kwargs.get(\"camera_info\", None)\n\n        return {\n            \"ui\": {\n                \"result\": [model_file, camera_info]\n            }\n        }\n\nNODE_CLASS_MAPPINGS",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_load_3d.py",
        "start": 127,
        "end": 154,
        "startLoc": {
          "line": 127,
          "column": 19,
          "position": 1286
        },
        "endLoc": {
          "line": 154,
          "column": 20,
          "position": 1462
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_load_3d.py",
        "start": 100,
        "end": 127,
        "startLoc": {
          "line": 100,
          "column": 10,
          "position": 1107
        },
        "endLoc": {
          "line": 127,
          "column": 6,
          "position": 1283
        }
      }
    },
    {
      "format": "python",
      "lines": 18,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"samples1\": (\"LATENT\",), \"samples2\": (\"LATENT\",)}}\n\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"op\"\n\n    CATEGORY = \"latent/advanced\"\n\n    def op(self, samples1, samples2):\n        samples_out = samples1.copy()\n\n        s1 = samples1[\"samples\"]\n        s2 = samples2[\"samples\"]\n\n        s2 = reshape_latent_to(s1.shape, s2)\n        samples_out[\"samples\"] = s1 -",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_latent.py",
        "start": 35,
        "end": 52,
        "startLoc": {
          "line": 35,
          "column": 15,
          "position": 285
        },
        "endLoc": {
          "line": 52,
          "column": 2,
          "position": 428
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_latent.py",
        "start": 15,
        "end": 32,
        "startLoc": {
          "line": 15,
          "column": 10,
          "position": 126
        },
        "endLoc": {
          "line": 32,
          "column": 2,
          "position": 269
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": ":\n    def __init__(self):\n        self.output_dir = folder_paths.get_output_directory()\n        self.type = \"output\"\n        self.prefix_append = \"\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"images\": (\"IMAGE\", ),\n                     \"filename_prefix\": (\"STRING\", {\"default\": \"ComfyUI\"}),\n                     \"fps\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_images.py",
        "start": 164,
        "end": 175,
        "startLoc": {
          "line": 164,
          "column": 16,
          "position": 1874
        },
        "endLoc": {
          "line": 175,
          "column": 6,
          "position": 1967
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_video.py",
        "start": 16,
        "end": 27,
        "startLoc": {
          "line": 16,
          "column": 9,
          "position": 123
        },
        "endLoc": {
          "line": 27,
          "column": 8,
          "position": 216
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "@classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"images\": (\"IMAGE\", ),\n                     \"filename_prefix\": (\"STRING\", {\"default\": \"ComfyUI\"}),\n                     \"fps\": (\"FLOAT\", {\"default\": 6.0, \"min\": 0.01, \"max\": 1000.0, \"step\": 0.01}),\n                     \"compress_level\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_images.py",
        "start": 170,
        "end": 176,
        "startLoc": {
          "line": 170,
          "column": 5,
          "position": 1918
        },
        "endLoc": {
          "line": 176,
          "column": 17,
          "position": 2002
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_images.py",
        "start": 105,
        "end": 111,
        "startLoc": {
          "line": 105,
          "column": 5,
          "position": 1123
        },
        "endLoc": {
          "line": 111,
          "column": 11,
          "position": 1207
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "pil_images = []\n        for image in images:\n            i = 255. * image.cpu().numpy()\n            img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))\n            pil_images.append(img)\n\n        metadata = None",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_images.py",
        "start": 192,
        "end": 198,
        "startLoc": {
          "line": 192,
          "column": 9,
          "position": 2190
        },
        "endLoc": {
          "line": 198,
          "column": 5,
          "position": 2271
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_images.py",
        "start": 131,
        "end": 137,
        "startLoc": {
          "line": 131,
          "column": 9,
          "position": 1463
        },
        "endLoc": {
          "line": 137,
          "column": 11,
          "position": 1544
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"width\": (\"INT\", {\"default\": 848, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                              \"height\": (\"INT\", {\"default\": 480, \"min\": 16, \"max\": nodes.MAX_RESOLUTION, \"step\": 16}),\n                              \"length\": (\"INT\", {\"default\": 25, \"min\": 1",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hunyuan.py",
        "start": 26,
        "end": 31,
        "startLoc": {
          "line": 26,
          "column": 24,
          "position": 201
        },
        "endLoc": {
          "line": 31,
          "column": 2,
          "position": 316
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_mochi.py",
        "start": 5,
        "end": 10,
        "startLoc": {
          "line": 5,
          "column": 22,
          "position": 18
        },
        "endLoc": {
          "line": 10,
          "column": 2,
          "position": 133
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "}),\n                              \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096})}}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"generate\"\n\n    CATEGORY = \"latent/video\"\n\n    def generate(self, width, height, length, batch_size=1):\n        latent = torch.zeros([batch_size, 16",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hunyuan.py",
        "start": 31,
        "end": 39,
        "startLoc": {
          "line": 31,
          "column": 2,
          "position": 331
        },
        "endLoc": {
          "line": 39,
          "column": 3,
          "position": 427
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_mochi.py",
        "start": 10,
        "end": 18,
        "startLoc": {
          "line": 10,
          "column": 2,
          "position": 148
        },
        "endLoc": {
          "line": 18,
          "column": 3,
          "position": 244
        }
      }
    },
    {
      "format": "python",
      "lines": 19,
      "fragment": "\"positive_NEW\": (\"CONDITIONING\", ),\n                \"negative_NEW\": (\"CONDITIONING\", ),\n                \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                \"set_cond_area\": ([\"default\", \"mask bounds\"],),\n            },\n            \"optional\": {\n                \"mask\": (\"MASK\", ),\n                \"hooks\": (\"HOOKS\",),\n                \"timesteps\": (\"TIMESTEPS_RANGE\",),\n            }\n        }\n\n    EXPERIMENTAL = True\n    RETURN_TYPES = (\"CONDITIONING\", \"CONDITIONING\")\n    RETURN_NAMES = (\"positive\", \"negative\")\n    CATEGORY = \"advanced/hooks/cond pair\"\n    FUNCTION = \"set_properties\"\n\n    def set_properties(self, positive",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 60,
        "end": 78,
        "startLoc": {
          "line": 60,
          "column": 17,
          "position": 480
        },
        "endLoc": {
          "line": 78,
          "column": 9,
          "position": 653
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 25,
        "end": 43,
        "startLoc": {
          "line": 25,
          "column": 17,
          "position": 128
        },
        "endLoc": {
          "line": 43,
          "column": 13,
          "position": 301
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": ": (\"CONDITIONING\", ),\n                \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                \"set_cond_area\": ([\"default\", \"mask bounds\"],),\n            },\n            \"optional\": {\n                \"mask\": (\"MASK\", ),\n                \"hooks\": (\"HOOKS\",),\n                \"timesteps\": (\"TIMESTEPS_RANGE\",),\n            }\n        }\n\n    EXPERIMENTAL = True\n    RETURN_TYPES = (\"CONDITIONING\",)",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 93,
        "end": 105,
        "startLoc": {
          "line": 93,
          "column": 11,
          "position": 827
        },
        "endLoc": {
          "line": 105,
          "column": 2,
          "position": 949
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 26,
        "end": 38,
        "startLoc": {
          "line": 26,
          "column": 15,
          "position": 140
        },
        "endLoc": {
          "line": 38,
          "column": 15,
          "position": 263
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": "\"cond_NEW\": (\"CONDITIONING\", ),\n                \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                \"set_cond_area\": ([\"default\", \"mask bounds\"],),\n            },\n            \"optional\": {\n                \"mask\": (\"MASK\", ),\n                \"hooks\": (\"HOOKS\",),\n                \"timesteps\": (\"TIMESTEPS_RANGE\",),\n            }\n        }\n\n    EXPERIMENTAL = True\n    RETURN_TYPES = (\"CONDITIONING\",)\n    CATEGORY = \"advanced/hooks/cond single\"\n    FUNCTION = \"set_properties\"\n\n    def set_properties(self, cond",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 125,
        "end": 141,
        "startLoc": {
          "line": 125,
          "column": 17,
          "position": 1134
        },
        "endLoc": {
          "line": 141,
          "column": 5,
          "position": 1282
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 93,
        "end": 109,
        "startLoc": {
          "line": 93,
          "column": 17,
          "position": 826
        },
        "endLoc": {
          "line": 109,
          "column": 9,
          "position": 974
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "@classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"lora_name\": (folder_paths.get_filename_list(\"loras\"), ),\n                \"strength_model\": (\"FLOAT\", {\"default\": 1.0, \"min\": -20.0, \"max\": 20.0, \"step\": 0.01}),\n            }",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 340,
        "end": 346,
        "startLoc": {
          "line": 340,
          "column": 5,
          "position": 3074
        },
        "endLoc": {
          "line": 346,
          "column": 2,
          "position": 3150
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 294,
        "end": 300,
        "startLoc": {
          "line": 294,
          "column": 5,
          "position": 2610
        },
        "endLoc": {
          "line": 300,
          "column": 16,
          "position": 2686
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ": (\"FLOAT\", {\"default\": 1.0, \"min\": -20.0, \"max\": 20.0, \"step\": 0.01}),\n            },\n            \"optional\": {\n                \"prev_hooks\": (\"HOOKS\",)\n            }\n        }\n\n    EXPERIMENTAL = True\n    RETURN_TYPES = (\"HOOKS\",)\n    CATEGORY = \"advanced/hooks/create\"\n    FUNCTION = \"create_hook_model_only\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 345,
        "end": 355,
        "startLoc": {
          "line": 345,
          "column": 17,
          "position": 3115
        },
        "endLoc": {
          "line": 355,
          "column": 25,
          "position": 3204
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 300,
        "end": 310,
        "startLoc": {
          "line": 300,
          "column": 16,
          "position": 2687
        },
        "endLoc": {
          "line": 310,
          "column": 14,
          "position": 2776
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": "), ),\n                \"strength_model\": (\"FLOAT\", {\"default\": 1.0, \"min\": -20.0, \"max\": 20.0, \"step\": 0.01}),\n                \"strength_clip\": (\"FLOAT\", {\"default\": 1.0, \"min\": -20.0, \"max\": 20.0, \"step\": 0.01}),\n            },\n            \"optional\": {\n                \"prev_hooks\": (\"HOOKS\",)\n            }\n        }\n\n    EXPERIMENTAL = True\n    RETURN_TYPES = (\"HOOKS\",)\n    CATEGORY = \"advanced/hooks/create\"\n    FUNCTION = \"create_hook\"\n\n    def create_hook(self, ckpt_name",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 373,
        "end": 387,
        "startLoc": {
          "line": 373,
          "column": 14,
          "position": 3347
        },
        "endLoc": {
          "line": 387,
          "column": 10,
          "position": 3491
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 298,
        "end": 312,
        "startLoc": {
          "line": 298,
          "column": 8,
          "position": 2643
        },
        "endLoc": {
          "line": 312,
          "column": 10,
          "position": 2787
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "@classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"ckpt_name\": (folder_paths.get_filename_list(\"checkpoints\"), ),\n                \"strength_model\": (\"FLOAT\", {\"default\": 1.0, \"min\": -20.0, \"max\": 20.0, \"step\": 0.01}),\n            }",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 418,
        "end": 424,
        "startLoc": {
          "line": 418,
          "column": 5,
          "position": 3845
        },
        "endLoc": {
          "line": 424,
          "column": 2,
          "position": 3921
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 369,
        "end": 375,
        "startLoc": {
          "line": 369,
          "column": 5,
          "position": 3314
        },
        "endLoc": {
          "line": 375,
          "column": 16,
          "position": 3390
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "), ),\n                \"strength_model\": (\"FLOAT\", {\"default\": 1.0, \"min\": -20.0, \"max\": 20.0, \"step\": 0.01}),\n            },\n            \"optional\": {\n                \"prev_hooks\": (\"HOOKS\",)\n            }\n        }\n\n    EXPERIMENTAL = True\n    RETURN_TYPES = (\"HOOKS\",)\n    CATEGORY = \"advanced/hooks/create\"\n    FUNCTION = \"create_hook_model_only\"\n\n    def create_hook_model_only(self, ckpt_name",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 422,
        "end": 435,
        "startLoc": {
          "line": 422,
          "column": 14,
          "position": 3878
        },
        "endLoc": {
          "line": 435,
          "column": 10,
          "position": 3986
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 344,
        "end": 357,
        "startLoc": {
          "line": 344,
          "column": 8,
          "position": 3107
        },
        "endLoc": {
          "line": 357,
          "column": 10,
          "position": 3215
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "):\n            guarantee_steps = 0\n            if is_first:\n                guarantee_steps = 1\n                is_first = False\n            prev_hook_kf.add(comfy.hooks.HookKeyframe(strength=strength, start_percent=percent, guarantee_steps=guarantee_steps))\n            if print_keyframes:\n                logging.info(f\"Hook Keyframe - start_percent:{percent} = {strength}\")\n        return (prev_hook_kf,)\n#------------------------------------------",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 585,
        "end": 594,
        "startLoc": {
          "line": 585,
          "column": 16,
          "position": 5576
        },
        "endLoc": {
          "line": 594,
          "column": 44,
          "position": 5656
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 536,
        "end": 546,
        "startLoc": {
          "line": 536,
          "column": 10,
          "position": 5045
        },
        "endLoc": {
          "line": 546,
          "column": 6,
          "position": 5126
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": ": (\"HOOKS\",),\n            }\n        }\n\n    EXPERIMENTAL = True\n    RETURN_TYPES = (\"HOOKS\",)\n    CATEGORY = \"advanced/hooks/combine\"\n    FUNCTION = \"combine_hooks\"\n\n    def combine_hooks(self,\n                      hooks_A: comfy.hooks.HookGroup=None,\n                      hooks_B: comfy.hooks.HookGroup=None,\n                      hooks_C: comfy.hooks.HookGroup=None,\n                      hooks_D: comfy.hooks.HookGroup=None,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 690,
        "end": 703,
        "startLoc": {
          "line": 690,
          "column": 10,
          "position": 6330
        },
        "endLoc": {
          "line": 703,
          "column": 2,
          "position": 6435
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hooks.py",
        "start": 657,
        "end": 670,
        "startLoc": {
          "line": 657,
          "column": 10,
          "position": 6061
        },
        "endLoc": {
          "line": 670,
          "column": 2,
          "position": 6166
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\n            \"clip\": (\"CLIP\", ),\n            \"clip_l\": (\"STRING\", {\"multiline\": True, \"dynamicPrompts\": True}),\n            \"clip_g\": (\"STRING\", {\"multiline\": True, \"dynamicPrompts\": True}),\n            \"t5xxl\": (\"STRING\", {\"multiline\": True, \"dynamicPrompts\": True}),\n            \"llama\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hidream.py",
        "start": 29,
        "end": 37,
        "startLoc": {
          "line": 29,
          "column": 22,
          "position": 275
        },
        "endLoc": {
          "line": 37,
          "column": 8,
          "position": 380
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_sd3.py",
        "start": 48,
        "end": 56,
        "startLoc": {
          "line": 48,
          "column": 18,
          "position": 505
        },
        "endLoc": {
          "line": 56,
          "column": 16,
          "position": 610
        }
      }
    },
    {
      "format": "python",
      "lines": 18,
      "fragment": "import numpy as np\nimport torch\n\ndef loglinear_interp(t_steps, num_steps):\n    \"\"\"\n    Performs log-linear interpolation of a given array of decreasing numbers.\n    \"\"\"\n    xs = np.linspace(0, 1, len(t_steps))\n    ys = np.log(t_steps[::-1])\n\n    new_xs = np.linspace(0, 1, num_steps)\n    new_ys = np.interp(new_xs, xs, ys)\n\n    interped_ys = np.exp(new_ys)[::-1].copy()\n    return interped_ys\n\nNOISE_LEVELS = {\n    0.80",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_gits.py",
        "start": 2,
        "end": 19,
        "startLoc": {
          "line": 2,
          "column": 1,
          "position": 2
        },
        "endLoc": {
          "line": 19,
          "column": 5,
          "position": 141
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_optimalsteps.py",
        "start": 4,
        "end": 21,
        "startLoc": {
          "line": 4,
          "column": 1,
          "position": 4
        },
        "endLoc": {
          "line": 21,
          "column": 7,
          "position": 142
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ", \"max\": 1000}),\n                     \"denoise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                      }\n               }\n    RETURN_TYPES = (\"SIGMAS\",)\n    CATEGORY = \"sampling/custom_sampling/schedulers\"\n\n    FUNCTION = \"get_sigmas\"\n\n    def get_sigmas(self, coeff",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_gits.py",
        "start": 341,
        "end": 350,
        "startLoc": {
          "line": 341,
          "column": 2,
          "position": 11488
        },
        "endLoc": {
          "line": 350,
          "column": 6,
          "position": 11573
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_optimalsteps.py",
        "start": 31,
        "end": 40,
        "startLoc": {
          "line": 31,
          "column": 2,
          "position": 442
        },
        "endLoc": {
          "line": 40,
          "column": 11,
          "position": 527
        }
      }
    },
    {
      "format": "python",
      "lines": 18,
      "fragment": ", \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                             \"s1\": (\"FLOAT\", {\"default\": 0.9, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                             \"s2\": (\"FLOAT\", {\"default\": 0.2, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              }}\n    RETURN_TYPES = (\"MODEL\",)\n    FUNCTION = \"patch\"\n\n    CATEGORY = \"model_patches/unet\"\n\n    def patch(self, model, b1, b2, s1, s2):\n        model_channels = model.model.model_config.unet_config[\"model_channels\"]\n        scale_dict = {model_channels * 4: (b1, s1), model_channels * 2: (b2, s2)}\n        on_cpu_devices = {}\n\n        def output_block_patch(h, hsp, transformer_options):\n            scale = scale_dict.get(int(h.shape[1]), None)\n            if scale is not None:\n                hidden_mean",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_freelunch.py",
        "start": 69,
        "end": 86,
        "startLoc": {
          "line": 69,
          "column": 4,
          "position": 929
        },
        "endLoc": {
          "line": 86,
          "column": 12,
          "position": 1187
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_freelunch.py",
        "start": 30,
        "end": 47,
        "startLoc": {
          "line": 30,
          "column": 4,
          "position": 361
        },
        "endLoc": {
          "line": 47,
          "column": 2,
          "position": 619
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": "if hsp.device not in on_cpu_devices:\n                    try:\n                        hsp = Fourier_filter(hsp, threshold=1, scale=scale[1])\n                    except:\n                        logging.warning(\"Device {} does not support the torch.fft functions used in the FreeU node, switching to CPU.\".format(hsp.device))\n                        on_cpu_devices[hsp.device] = True\n                        hsp = Fourier_filter(hsp.cpu(), threshold=1, scale=scale[1]).to(hsp.device)\n                else:\n                    hsp = Fourier_filter(hsp.cpu(), threshold=1, scale=scale[1]).to(hsp.device)\n\n            return h, hsp\n\n        m = model.clone()\n        m.set_model_output_block_patch(output_block_patch)\n        return (m, )\n\nNODE_CLASS_MAPPINGS",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_freelunch.py",
        "start": 94,
        "end": 110,
        "startLoc": {
          "line": 94,
          "column": 17,
          "position": 1392
        },
        "endLoc": {
          "line": 110,
          "column": 20,
          "position": 1574
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_freelunch.py",
        "start": 48,
        "end": 64,
        "startLoc": {
          "line": 48,
          "column": 17,
          "position": 663
        },
        "endLoc": {
          "line": 64,
          "column": 6,
          "position": 845
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"steps\": (\"INT\", {\"default\": 20, \"min\": 1, \"max\": 10000}),\n                     \"sigma_max\": (\"FLOAT\", {\"default\": 14.614642, \"min\": 0.0, \"max\": 5000.0, \"step\":0.01, \"round\": False}),\n                     \"sigma_min\": (\"FLOAT\", {\"default\": 0.0291675, \"min\": 0.0, \"max\": 5000.0, \"step\":0.01, \"round\": False}),\n                    }",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 57,
        "end": 64,
        "startLoc": {
          "line": 57,
          "column": 21,
          "position": 600
        },
        "endLoc": {
          "line": 64,
          "column": 2,
          "position": 733
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 38,
        "end": 45,
        "startLoc": {
          "line": 38,
          "column": 16,
          "position": 333
        },
        "endLoc": {
          "line": 45,
          "column": 6,
          "position": 466
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"steps\": (\"INT\", {\"default\": 20, \"min\": 1, \"max\": 10000}),\n                     \"sigma_max\": (\"FLOAT\", {\"default\": 14.614642, \"min\": 0.0, \"max\": 5000.0, \"step\":0.01, \"round\": False}),\n                     \"sigma_min\": (\"FLOAT\", {\"default\": 0.0291675, \"min\": 0.0, \"max\": 5000.0, \"step\":0.01, \"round\": False}),\n                     \"rho\": (\"FLOAT\", {\"default\": 1.0",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 75,
        "end": 82,
        "startLoc": {
          "line": 75,
          "column": 25,
          "position": 819
        },
        "endLoc": {
          "line": 82,
          "column": 4,
          "position": 963
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 38,
        "end": 45,
        "startLoc": {
          "line": 38,
          "column": 16,
          "position": 333
        },
        "endLoc": {
          "line": 45,
          "column": 4,
          "position": 477
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ", \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                    }\n               }\n    RETURN_TYPES = (\"SIGMAS\",)\n    CATEGORY = \"sampling/custom_sampling/schedulers\"\n\n    FUNCTION = \"get_sigmas\"\n\n    def get_sigmas(self, steps, sigma_max, sigma_min, rho):\n        sigmas = k_diffusion_sampling.get_sigmas_polyexponential",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 82,
        "end": 91,
        "startLoc": {
          "line": 82,
          "column": 4,
          "position": 964
        },
        "endLoc": {
          "line": 91,
          "column": 27,
          "position": 1051
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 45,
        "end": 54,
        "startLoc": {
          "line": 45,
          "column": 4,
          "position": 478
        },
        "endLoc": {
          "line": 54,
          "column": 18,
          "position": 565
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"steps\": (\"INT\", {\"default\": 20, \"min\": 1, \"max\": 10000}),\n                     \"sigma_max\": (\"FLOAT\", {\"default\": 14.614642, \"min\": 0.0, \"max\": 5000.0, \"step\":0.01, \"round\": False}),\n                     \"sigma_min\": (\"FLOAT\", {\"default\": 0.0291675, \"min\": 0.0, \"max\": 5000.0, \"step\":0.01, \"round\": False}),\n                     \"mu\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 94,
        "end": 101,
        "startLoc": {
          "line": 94,
          "column": 17,
          "position": 1086
        },
        "endLoc": {
          "line": 101,
          "column": 5,
          "position": 1219
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 38,
        "end": 45,
        "startLoc": {
          "line": 38,
          "column": 16,
          "position": 333
        },
        "endLoc": {
          "line": 45,
          "column": 6,
          "position": 466
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "\"eta\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                     \"s_noise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                     \"noise_device\": (['gpu', 'cpu'], ),\n                      }\n               }\n    RETURN_TYPES = (\"SAMPLER\",)\n    CATEGORY = \"sampling/custom_sampling/samplers\"\n\n    FUNCTION = \"get_sampler\"\n\n    def get_sampler(self, solver_type",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 345,
        "end": 355,
        "startLoc": {
          "line": 345,
          "column": 22,
          "position": 3784
        },
        "endLoc": {
          "line": 355,
          "column": 12,
          "position": 3919
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 322,
        "end": 332,
        "startLoc": {
          "line": 322,
          "column": 2,
          "position": 3530
        },
        "endLoc": {
          "line": 332,
          "column": 4,
          "position": 3665
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"eta\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                     \"s_noise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                     \"r\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 364,
        "end": 370,
        "startLoc": {
          "line": 364,
          "column": 17,
          "position": 4008
        },
        "endLoc": {
          "line": 370,
          "column": 4,
          "position": 4112
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 318,
        "end": 324,
        "startLoc": {
          "line": 318,
          "column": 20,
          "position": 3506
        },
        "endLoc": {
          "line": 324,
          "column": 15,
          "position": 3610
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ", \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                     \"noise_device\": (['gpu', 'cpu'], ),\n                      }\n               }\n    RETURN_TYPES = (\"SAMPLER\",)\n    CATEGORY = \"sampling/custom_sampling/samplers\"\n\n    FUNCTION = \"get_sampler\"\n\n    def get_sampler(self, eta, s_noise, r",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 370,
        "end": 379,
        "startLoc": {
          "line": 370,
          "column": 4,
          "position": 4124
        },
        "endLoc": {
          "line": 379,
          "column": 2,
          "position": 4213
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 323,
        "end": 332,
        "startLoc": {
          "line": 323,
          "column": 4,
          "position": 3582
        },
        "endLoc": {
          "line": 332,
          "column": 13,
          "position": 3671
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"eta\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                     \"s_noise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                      }",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 387,
        "end": 393,
        "startLoc": {
          "line": 387,
          "column": 26,
          "position": 4295
        },
        "endLoc": {
          "line": 393,
          "column": 2,
          "position": 4399
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 318,
        "end": 324,
        "startLoc": {
          "line": 318,
          "column": 20,
          "position": 3506
        },
        "endLoc": {
          "line": 324,
          "column": 15,
          "position": 3610
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\":\n                    {\"eta\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                     \"s_noise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                      }\n               }\n    RETURN_TYPES = (\"SAMPLER\",)\n    CATEGORY = \"sampling/custom_sampling/samplers\"\n\n    FUNCTION = \"get_sampler\"\n\n    def get_sampler(self, eta, s_noise):\n        sampler = comfy.samplers.ksampler(\"euler_ancestral\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 404,
        "end": 418,
        "startLoc": {
          "line": 404,
          "column": 22,
          "position": 4486
        },
        "endLoc": {
          "line": 418,
          "column": 18,
          "position": 4647
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 318,
        "end": 401,
        "startLoc": {
          "line": 318,
          "column": 20,
          "position": 3506
        },
        "endLoc": {
          "line": 401,
          "column": 21,
          "position": 4456
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ", \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                     \"s_noise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 100.0, \"step\":0.01, \"round\": False}),\n                      }\n               }\n    RETURN_TYPES = (\"SAMPLER\",)\n    CATEGORY = \"sampling/custom_sampling/samplers\"\n\n    FUNCTION = \"get_sampler\"\n\n    def get_sampler(self, order",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 468,
        "end": 477,
        "startLoc": {
          "line": 468,
          "column": 4,
          "position": 5348
        },
        "endLoc": {
          "line": 477,
          "column": 6,
          "position": 5455
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 391,
        "end": 400,
        "startLoc": {
          "line": 391,
          "column": 4,
          "position": 4331
        },
        "endLoc": {
          "line": 400,
          "column": 4,
          "position": 4438
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": ", ),\n                    \"sampler\": (\"SAMPLER\", ),\n                    \"sigmas\": (\"SIGMAS\", ),\n                    \"latent_image\": (\"LATENT\", ),\n                     }\n                }\n\n    RETURN_TYPES = (\"LATENT\",\"LATENT\")\n    RETURN_NAMES = (\"output\", \"denoised_output\")\n\n    FUNCTION = \"sample\"\n\n    CATEGORY = \"sampling/custom_sampling\"\n\n    def sample(self, noise",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 678,
        "end": 692,
        "startLoc": {
          "line": 678,
          "column": 9,
          "position": 7459
        },
        "endLoc": {
          "line": 692,
          "column": 6,
          "position": 7552
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 510,
        "end": 524,
        "startLoc": {
          "line": 510,
          "column": 15,
          "position": 5890
        },
        "endLoc": {
          "line": 524,
          "column": 6,
          "position": 5983
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "}),\n                              \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096})}}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"generate\"\n\n    CATEGORY = \"latent/video\"\n\n    def generate(self, width, height, length, batch_size=1):\n        latent = torch.zeros([batch_size, 16, ((length - 1) // 8",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_cosmos.py",
        "start": 12,
        "end": 20,
        "startLoc": {
          "line": 12,
          "column": 2,
          "position": 155
        },
        "endLoc": {
          "line": 20,
          "column": 2,
          "position": 265
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_mochi.py",
        "start": 10,
        "end": 39,
        "startLoc": {
          "line": 10,
          "column": 2,
          "position": 148
        },
        "endLoc": {
          "line": 39,
          "column": 2,
          "position": 441
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "(nodes.ControlNetApplyAdvanced):\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": {\"positive\": (\"CONDITIONING\", ),\n                             \"negative\": (\"CONDITIONING\", ),\n                             \"control_net\": (\"CONTROL_NET\", ),\n                             \"vae\": (\"VAE\", ),\n                             \"image\": (\"IMAGE\", ),\n                             \"mask\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_controlnet.py",
        "start": 27,
        "end": 35,
        "startLoc": {
          "line": 27,
          "column": 33,
          "position": 206
        },
        "endLoc": {
          "line": 35,
          "column": 7,
          "position": 289
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_sd3.py",
        "start": 88,
        "end": 96,
        "startLoc": {
          "line": 88,
          "column": 19,
          "position": 955
        },
        "endLoc": {
          "line": 96,
          "column": 11,
          "position": 1038
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ", ),\n                             \"strength\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                             \"start_percent\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.001}),\n                             \"end_percent\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.001})\n                             }}\n\n    FUNCTION",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_controlnet.py",
        "start": 35,
        "end": 41,
        "startLoc": {
          "line": 35,
          "column": 7,
          "position": 294
        },
        "endLoc": {
          "line": 41,
          "column": 9,
          "position": 409
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_sd3.py",
        "start": 95,
        "end": 100,
        "startLoc": {
          "line": 95,
          "column": 8,
          "position": 1032
        },
        "endLoc": {
          "line": 100,
          "column": 9,
          "position": 1146
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "]\n        if len(tokens[\"l\"]) != len(tokens[\"g\"]):\n            empty = clip.tokenize(\"\")\n            while len(tokens[\"l\"]) < len(tokens[\"g\"]):\n                tokens[\"l\"] += empty[\"l\"]\n            while len(tokens[\"l\"]) > len(tokens[\"g\"]):\n                tokens[\"g\"] += empty[\"g\"]\n        return (clip.encode_from_tokens_scheduled(tokens,",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_clip_sdxl.py",
        "start": 42,
        "end": 49,
        "startLoc": {
          "line": 42,
          "column": 4,
          "position": 617
        },
        "endLoc": {
          "line": 49,
          "column": 2,
          "position": 732
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_sd3.py",
        "start": 78,
        "end": 85,
        "startLoc": {
          "line": 78,
          "column": 8,
          "position": 830
        },
        "endLoc": {
          "line": 85,
          "column": 2,
          "position": 945
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "metadata = {}\n    if not args.disable_metadata:\n        if prompt is not None:\n            metadata[\"prompt\"] = json.dumps(prompt)\n        if extra_pnginfo is not None:\n            for x in extra_pnginfo:\n                metadata[x] = json.dumps(extra_pnginfo[x])\n\n    # Opus supported sample rates",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_audio.py",
        "start": 100,
        "end": 108,
        "startLoc": {
          "line": 100,
          "column": 5,
          "position": 1024
        },
        "endLoc": {
          "line": 108,
          "column": 30,
          "position": 1110
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_hunyuan3d.py",
        "start": 606,
        "end": 614,
        "startLoc": {
          "line": 606,
          "column": 9,
          "position": 6163
        },
        "endLoc": {
          "line": 614,
          "column": 4,
          "position": 6249
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ":\n    def __init__(self):\n        self.output_dir = folder_paths.get_output_directory()\n        self.type = \"output\"\n        self.prefix_append = \"\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"audio\": (\"AUDIO\", ),\n                            \"filename_prefix\": (\"STRING\", {\"default\": \"audio/ComfyUI\"}),\n                            \"quality\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_audio.py",
        "start": 229,
        "end": 239,
        "startLoc": {
          "line": 229,
          "column": 13,
          "position": 2129
        },
        "endLoc": {
          "line": 239,
          "column": 10,
          "position": 2222
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_audio.py",
        "start": 205,
        "end": 215,
        "startLoc": {
          "line": 205,
          "column": 10,
          "position": 1920
        },
        "endLoc": {
          "line": 215,
          "column": 2,
          "position": 2013
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ":\n    def __init__(self):\n        self.output_dir = folder_paths.get_output_directory()\n        self.type = \"output\"\n        self.prefix_append = \"\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"audio\": (\"AUDIO\", ),\n                            \"filename_prefix\": (\"STRING\", {\"default\": \"audio/ComfyUI\"}),\n                            \"quality\": ([\"64k\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_audio.py",
        "start": 254,
        "end": 264,
        "startLoc": {
          "line": 254,
          "column": 14,
          "position": 2371
        },
        "endLoc": {
          "line": 264,
          "column": 6,
          "position": 2469
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_audio.py",
        "start": 205,
        "end": 239,
        "startLoc": {
          "line": 205,
          "column": 10,
          "position": 1920
        },
        "endLoc": {
          "line": 239,
          "column": 5,
          "position": 2227
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": ":\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"model\": (\"MODEL\",),\n                              \"q\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              \"k\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              \"v\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              \"out\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              }}\n    RETURN_TYPES = (\"MODEL\",)\n    FUNCTION = \"patch\"\n\n    CATEGORY = \"_for_testing/attention_experiments\"\n\n    def patch(self, model, q, k, v, out):\n        m = attention_multiply(\"attn2\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_attention_multiply.py",
        "start": 37,
        "end": 52,
        "startLoc": {
          "line": 37,
          "column": 27,
          "position": 541
        },
        "endLoc": {
          "line": 52,
          "column": 8,
          "position": 775
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_attention_multiply.py",
        "start": 19,
        "end": 34,
        "startLoc": {
          "line": 19,
          "column": 26,
          "position": 276
        },
        "endLoc": {
          "line": 34,
          "column": 8,
          "position": 510
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": ",),\n                              \"q\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              \"k\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              \"v\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              \"out\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 10.0, \"step\": 0.01}),\n                              }}\n    RETURN_TYPES = (\"CLIP\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_attention_multiply.py",
        "start": 58,
        "end": 64,
        "startLoc": {
          "line": 58,
          "column": 7,
          "position": 835
        },
        "endLoc": {
          "line": 64,
          "column": 7,
          "position": 989
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_attention_multiply.py",
        "start": 22,
        "end": 28,
        "startLoc": {
          "line": 22,
          "column": 8,
          "position": 305
        },
        "endLoc": {
          "line": 28,
          "column": 8,
          "position": 459
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": "import numpy as np\nimport torch\n\ndef loglinear_interp(t_steps, num_steps):\n    \"\"\"\n    Performs log-linear interpolation of a given array of decreasing numbers.\n    \"\"\"\n    xs = np.linspace(0, 1, len(t_steps))\n    ys = np.log(t_steps[::-1])\n\n    new_xs = np.linspace(0, 1, num_steps)\n    new_ys = np.interp(new_xs, xs, ys)\n\n    interped_ys = np.exp(new_ys)[::-1].copy()\n    return interped_ys\n\nNOISE_LEVELS = {\"SD1\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_align_your_steps.py",
        "start": 2,
        "end": 18,
        "startLoc": {
          "line": 2,
          "column": 1,
          "position": 2
        },
        "endLoc": {
          "line": 18,
          "column": 6,
          "position": 139
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_optimalsteps.py",
        "start": 4,
        "end": 21,
        "startLoc": {
          "line": 4,
          "column": 1,
          "position": 4
        },
        "endLoc": {
          "line": 21,
          "column": 7,
          "position": 142
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ", \"min\": 1, \"max\": 10000}),\n                     \"denoise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                      }\n               }\n    RETURN_TYPES = (\"SIGMAS\",)\n    CATEGORY = \"sampling/custom_sampling/schedulers\"\n\n    FUNCTION = \"get_sigmas\"\n\n    def get_sigmas(self, model_type",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_align_your_steps.py",
        "start": 27,
        "end": 36,
        "startLoc": {
          "line": 27,
          "column": 3,
          "position": 313
        },
        "endLoc": {
          "line": 36,
          "column": 11,
          "position": 404
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_custom_sampler.py",
        "start": 17,
        "end": 26,
        "startLoc": {
          "line": 17,
          "column": 3,
          "position": 114
        },
        "endLoc": {
          "line": 26,
          "column": 6,
          "position": 205
        }
      }
    },
    {
      "format": "python",
      "lines": 26,
      "fragment": "}),\n                     \"denoise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                      }\n               }\n    RETURN_TYPES = (\"SIGMAS\",)\n    CATEGORY = \"sampling/custom_sampling/schedulers\"\n\n    FUNCTION = \"get_sigmas\"\n\n    def get_sigmas(self, model_type, steps, denoise):\n        total_steps = steps\n        if denoise < 1.0:\n            if denoise <= 0.0:\n                return (torch.FloatTensor([]),)\n            total_steps = round(steps * denoise)\n\n        sigmas = NOISE_LEVELS[model_type][:]\n        if (steps + 1) != len(sigmas):\n            sigmas = loglinear_interp(sigmas, steps + 1)\n\n        sigmas = sigmas[-(total_steps + 1):]\n        sigmas[-1] = 0\n        return (torch.FloatTensor(sigmas), )\n\nNODE_CLASS_MAPPINGS = {\n    \"AlignYourStepsScheduler\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_align_your_steps.py",
        "start": 27,
        "end": 52,
        "startLoc": {
          "line": 27,
          "column": 6,
          "position": 325
        },
        "endLoc": {
          "line": 52,
          "column": 26,
          "position": 571
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_optimalsteps.py",
        "start": 31,
        "end": 56,
        "startLoc": {
          "line": 31,
          "column": 5,
          "position": 448
        },
        "endLoc": {
          "line": 56,
          "column": 24,
          "position": 694
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": ", \"min\": 1.0, \"max\": 1000.0, \"step\": 0.1}),\n                             \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096, \"tooltip\": \"The number of latent images in the batch.\"}),\n                             }}\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"generate\"\n\n    CATEGORY = \"latent/audio\"\n\n    def generate(self, seconds, batch_size):\n        length = int",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_ace.py",
        "start": 32,
        "end": 41,
        "startLoc": {
          "line": 32,
          "column": 6,
          "position": 308
        },
        "endLoc": {
          "line": 41,
          "column": 4,
          "position": 415
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_audio.py",
        "start": 23,
        "end": 32,
        "startLoc": {
          "line": 23,
          "column": 5,
          "position": 139
        },
        "endLoc": {
          "line": 32,
          "column": 6,
          "position": 246
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "def add_keys(self, node_ids):\n        for node_id in node_ids:\n            if node_id in self.keys:\n                continue\n            if not self.dynprompt.has_node(node_id):\n                continue\n            node = self.dynprompt.get_node(node_id)\n            self.keys[node_id] = self",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_execution/caching.py",
        "start": 85,
        "end": 92,
        "startLoc": {
          "line": 85,
          "column": 5,
          "position": 779
        },
        "endLoc": {
          "line": 92,
          "column": 5,
          "position": 857
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_execution/caching.py",
        "start": 65,
        "end": 72,
        "startLoc": {
          "line": 65,
          "column": 5,
          "position": 580
        },
        "endLoc": {
          "line": 72,
          "column": 2,
          "position": 658
        }
      }
    },
    {
      "format": "python",
      "lines": 19,
      "fragment": "}),\n                \"face_limit\": (\"INT\", {\"min\": -1, \"max\": 500000, \"default\": -1}),\n                \"quad\": (\"BOOLEAN\", {\"default\": False})\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n                \"unique_id\": \"UNIQUE_ID\",\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\", \"MODEL_TASK_ID\",)\n    RETURN_NAMES = (\"model_file\", \"model task_id\")\n    FUNCTION = \"generate_mesh\"\n    CATEGORY = \"api node/3d/Tripo\"\n    API_NODE = True\n    OUTPUT_NODE = True\n\n    def generate_mesh(self, image",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_tripo.py",
        "start": 180,
        "end": 198,
        "startLoc": {
          "line": 180,
          "column": 17,
          "position": 1569
        },
        "endLoc": {
          "line": 198,
          "column": 6,
          "position": 1721
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_tripo.py",
        "start": 111,
        "end": 129,
        "startLoc": {
          "line": 111,
          "column": 11,
          "position": 906
        },
        "endLoc": {
          "line": 129,
          "column": 7,
          "position": 1058
        }
      }
    },
    {
      "format": "python",
      "lines": 22,
      "fragment": "),\n                \"texture_seed\": (\"INT\", {\"default\": 42}),\n                \"texture_quality\": ([\"standard\", \"detailed\"], {\"default\": \"standard\"}),\n                \"texture_alignment\": ([\"original_image\", \"geometry\"], {\"default\": \"original_image\"}),\n                \"face_limit\": (\"INT\", {\"min\": -1, \"max\": 500000, \"default\": -1}),\n                \"quad\": (\"BOOLEAN\", {\"default\": False})\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n                \"unique_id\": \"UNIQUE_ID\",\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\", \"MODEL_TASK_ID\",)\n    RETURN_NAMES = (\"model_file\", \"model task_id\")\n    FUNCTION = \"generate_mesh\"\n    CATEGORY = \"api node/3d/Tripo\"\n    API_NODE = True\n    OUTPUT_NODE = True\n\n    def generate_mesh(self, image, image_left",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_tripo.py",
        "start": 249,
        "end": 270,
        "startLoc": {
          "line": 249,
          "column": 2,
          "position": 2182
        },
        "endLoc": {
          "line": 270,
          "column": 11,
          "position": 2397
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_tripo.py",
        "start": 177,
        "end": 198,
        "startLoc": {
          "line": 177,
          "column": 17,
          "position": 1509
        },
        "endLoc": {
          "line": 198,
          "column": 14,
          "position": 1724
        }
      }
    },
    {
      "format": "python",
      "lines": 21,
      "fragment": ":\n    \"\"\"\n    Generates images synchronously based on prompt and resolution.\n    \"\"\"\n\n    RETURN_TYPES = (IO.IMAGE,)\n    DESCRIPTION = cleandoc(__doc__ or \"\")  # Handle potential None value\n    FUNCTION = \"api_call\"\n    API_NODE = True\n    CATEGORY = \"api node/image/Stability AI\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"prompt\": (\n                    IO.STRING,\n                    {\n                        \"multiline\": True,\n                        \"default\": \"\",\n                        \"tooltip\": \"What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 177,
        "end": 197,
        "startLoc": {
          "line": 177,
          "column": 31,
          "position": 1084
        },
        "endLoc": {
          "line": 197,
          "column": 154,
          "position": 1197
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 49,
        "end": 69,
        "startLoc": {
          "line": 49,
          "column": 30,
          "position": 274
        },
        "endLoc": {
          "line": 69,
          "column": 94,
          "position": 387
        }
      }
    },
    {
      "format": "python",
      "lines": 22,
      "fragment": ",\n                    },\n                ),\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 4294967294,\n                        \"control_after_generate\": True,\n                        \"tooltip\": \"The random seed used for creating the noise.\",\n                    },\n                ),\n            },\n            \"optional\": {\n                \"image\": (IO.IMAGE,),\n                \"negative_prompt\": (\n                    IO.STRING,\n                    {\n                        \"default\": \"\",\n                        \"forceInput\": True,\n                        \"tooltip\": \"Keywords of what you do not wish to see in the output image. This is an advanced feature.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 219,
        "end": 240,
        "startLoc": {
          "line": 219,
          "column": 118,
          "position": 1352
        },
        "endLoc": {
          "line": 240,
          "column": 92,
          "position": 1475
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 86,
        "end": 107,
        "startLoc": {
          "line": 86,
          "column": 45,
          "position": 492
        },
        "endLoc": {
          "line": 107,
          "column": 107,
          "position": 615
        }
      }
    },
    {
      "format": "python",
      "lines": 20,
      "fragment": "},\n                ),\n                \"image_denoise\": (\n                    IO.FLOAT,\n                    {\n                        \"default\": 0.5,\n                        \"min\": 0.0,\n                        \"max\": 1.0,\n                        \"step\": 0.01,\n                        \"tooltip\": \"Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all.\",\n                    },\n                ),\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n            },\n        }\n\n    def api_call(self, model",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 241,
        "end": 260,
        "startLoc": {
          "line": 241,
          "column": 21,
          "position": 1478
        },
        "endLoc": {
          "line": 260,
          "column": 6,
          "position": 1583
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 108,
        "end": 127,
        "startLoc": {
          "line": 108,
          "column": 21,
          "position": 618
        },
        "endLoc": {
          "line": 127,
          "column": 7,
          "position": 723
        }
      }
    },
    {
      "format": "python",
      "lines": 28,
      "fragment": ":\n    \"\"\"\n    Upscale image with minimal alterations to 4K resolution.\n    \"\"\"\n\n    RETURN_TYPES = (IO.IMAGE,)\n    DESCRIPTION = cleandoc(__doc__ or \"\")  # Handle potential None value\n    FUNCTION = \"api_call\"\n    API_NODE = True\n    CATEGORY = \"api node/image/Stability AI\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"image\": (IO.IMAGE,),\n                \"prompt\": (\n                    IO.STRING,\n                    {\n                        \"multiline\": True,\n                        \"default\": \"\",\n                        \"tooltip\": \"What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.\"\n                    },\n                ),\n                \"creativity\": (\n                    IO.FLOAT,\n                    {\n                        \"default\": 0.3",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 417,
        "end": 444,
        "startLoc": {
          "line": 417,
          "column": 29,
          "position": 2628
        },
        "endLoc": {
          "line": 444,
          "column": 4,
          "position": 2782
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 316,
        "end": 343,
        "startLoc": {
          "line": 316,
          "column": 33,
          "position": 1999
        },
        "endLoc": {
          "line": 343,
          "column": 5,
          "position": 2153
        }
      }
    },
    {
      "format": "python",
      "lines": 21,
      "fragment": ",\n                    },\n                ),\n                \"style_preset\": (get_stability_style_presets(),\n                    {\n                        \"tooltip\": \"Optional desired style of generated image.\",\n                    },\n                ),\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 4294967294,\n                        \"control_after_generate\": True,\n                        \"tooltip\": \"The random seed used for creating the noise.\",\n                    },\n                ),\n            },\n            \"optional\": {\n                \"negative_prompt\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 448,
        "end": 468,
        "startLoc": {
          "line": 448,
          "column": 100,
          "position": 2811
        },
        "endLoc": {
          "line": 468,
          "column": 18,
          "position": 2918
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 81,
        "end": 101,
        "startLoc": {
          "line": 81,
          "column": 35,
          "position": 464
        },
        "endLoc": {
          "line": 101,
          "column": 8,
          "position": 571
        }
      }
    },
    {
      "format": "python",
      "lines": 31,
      "fragment": ",\n                    },\n                ),\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 4294967294,\n                        \"control_after_generate\": True,\n                        \"tooltip\": \"The random seed used for creating the noise.\",\n                    },\n                ),\n            },\n            \"optional\": {\n                \"negative_prompt\": (\n                    IO.STRING,\n                    {\n                        \"default\": \"\",\n                        \"forceInput\": True,\n                        \"tooltip\": \"Keywords of what you do not wish to see in the output image. This is an advanced feature.\"\n                    },\n                ),\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n            },\n        }\n\n    def api_call(self, image: torch.Tensor, prompt: str, creativity: float, style_preset",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 453,
        "end": 483,
        "startLoc": {
          "line": 453,
          "column": 45,
          "position": 2839
        },
        "endLoc": {
          "line": 483,
          "column": 13,
          "position": 3020
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_stability.py",
        "start": 347,
        "end": 377,
        "startLoc": {
          "line": 347,
          "column": 100,
          "position": 2182
        },
        "endLoc": {
          "line": 377,
          "column": 5,
          "position": 2363
        }
      }
    },
    {
      "format": "python",
      "lines": 19,
      "fragment": "@classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"prompt\": model_field_to_node_input(\n                    IO.STRING, RunwayImageToVideoRequest, \"promptText\", multiline=True\n                ),\n                \"start_frame\": (\n                    IO.IMAGE,\n                    {\"tooltip\": \"Start frame to be used for the video\"},\n                ),\n                \"duration\": model_field_to_node_input(\n                    IO.COMBO, RunwayImageToVideoRequest, \"duration\", enum_type=Duration\n                ),\n                \"ratio\": model_field_to_node_input(\n                    IO.COMBO,\n                    RunwayImageToVideoRequest,\n                    \"ratio\",\n                    enum_type=RunwayGen4TurboAspectRatio",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 302,
        "end": 320,
        "startLoc": {
          "line": 302,
          "column": 5,
          "position": 1780
        },
        "endLoc": {
          "line": 320,
          "column": 27,
          "position": 1906
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 219,
        "end": 237,
        "startLoc": {
          "line": 219,
          "column": 5,
          "position": 1283
        },
        "endLoc": {
          "line": 237,
          "column": 23,
          "position": 1409
        }
      }
    },
    {
      "format": "python",
      "lines": 31,
      "fragment": ",\n                ),\n                \"seed\": model_field_to_node_input(\n                    IO.INT,\n                    RunwayImageToVideoRequest,\n                    \"seed\",\n                    control_after_generate=True,\n                ),\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n                \"unique_id\": \"UNIQUE_ID\",\n            },\n        }\n\n    def api_call(\n        self,\n        prompt: str,\n        start_frame: torch.Tensor,\n        duration: str,\n        ratio: str,\n        seed: int,\n        unique_id: Optional[str] = None,\n        **kwargs,\n    ) -> tuple[VideoFromFile]:\n        # Validate inputs\n        validate_string(prompt, min_length=1)\n        validate_input_image(start_frame)\n\n        # Upload image",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 320,
        "end": 350,
        "startLoc": {
          "line": 320,
          "column": 27,
          "position": 1907
        },
        "endLoc": {
          "line": 350,
          "column": 15,
          "position": 2083
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 237,
        "end": 267,
        "startLoc": {
          "line": 237,
          "column": 23,
          "position": 1410
        },
        "endLoc": {
          "line": 267,
          "column": 2,
          "position": 1586
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "download_urls = upload_images_to_comfyapi(\n            start_frame,\n            max_images=1,\n            mime_type=\"image/png\",\n            auth_kwargs=kwargs,\n        )\n        if len(download_urls) != 1:\n            raise RunwayApiError(\"Failed to upload one or more images to comfy api.\")\n\n        return self.generate_video(\n            RunwayImageToVideoRequest(\n                promptText=prompt,\n                seed=seed,\n                model=Model(\"gen4_turbo\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 351,
        "end": 364,
        "startLoc": {
          "line": 351,
          "column": 9,
          "position": 2086
        },
        "endLoc": {
          "line": 364,
          "column": 13,
          "position": 2169
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 268,
        "end": 281,
        "startLoc": {
          "line": 268,
          "column": 9,
          "position": 1593
        },
        "endLoc": {
          "line": 281,
          "column": 14,
          "position": 1676
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": "),\n                duration=Duration(duration),\n                ratio=AspectRatio(ratio),\n                promptImage=RunwayPromptImageObject(\n                    root=[\n                        RunwayPromptImageDetailedObject(\n                            uri=str(download_urls[0]), position=\"first\"\n                        )\n                    ]\n                ),\n            ),\n            auth_kwargs=kwargs,\n            node_id=unique_id,\n        )\n\n\nclass RunwayFirstLastFrameNode",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 364,
        "end": 380,
        "startLoc": {
          "line": 364,
          "column": 13,
          "position": 2170
        },
        "endLoc": {
          "line": 380,
          "column": 25,
          "position": 2255
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 281,
        "end": 297,
        "startLoc": {
          "line": 281,
          "column": 14,
          "position": 1677
        },
        "endLoc": {
          "line": 297,
          "column": 27,
          "position": 1762
        }
      }
    },
    {
      "format": "python",
      "lines": 21,
      "fragment": "},\n                ),\n                \"duration\": model_field_to_node_input(\n                    IO.COMBO, RunwayImageToVideoRequest, \"duration\", enum_type=Duration\n                ),\n                \"ratio\": model_field_to_node_input(\n                    IO.COMBO,\n                    RunwayImageToVideoRequest,\n                    \"ratio\",\n                    enum_type=RunwayGen3aAspectRatio,\n                ),\n                \"seed\": model_field_to_node_input(\n                    IO.INT,\n                    RunwayImageToVideoRequest,\n                    \"seed\",\n                    control_after_generate=True,\n                ),\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"unique_id\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 415,
        "end": 435,
        "startLoc": {
          "line": 415,
          "column": 21,
          "position": 2481
        },
        "endLoc": {
          "line": 435,
          "column": 12,
          "position": 2595
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 228,
        "end": 248,
        "startLoc": {
          "line": 228,
          "column": 39,
          "position": 1351
        },
        "endLoc": {
          "line": 248,
          "column": 16,
          "position": 1465
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": ": torch.Tensor,\n        duration: str,\n        ratio: str,\n        seed: int,\n        unique_id: Optional[str] = None,\n        **kwargs,\n    ) -> tuple[VideoFromFile]:\n        # Validate inputs\n        validate_string(prompt, min_length=1)\n        validate_input_image(start_frame)\n        validate_input_image",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 444,
        "end": 454,
        "startLoc": {
          "line": 444,
          "column": 10,
          "position": 2644
        },
        "endLoc": {
          "line": 454,
          "column": 21,
          "position": 2724
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 256,
        "end": 267,
        "startLoc": {
          "line": 256,
          "column": 12,
          "position": 1505
        },
        "endLoc": {
          "line": 267,
          "column": 2,
          "position": 1586
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": ":\n            raise RunwayApiError(\"Failed to upload one or more images to comfy api.\")\n\n        return self.generate_video(\n            RunwayImageToVideoRequest(\n                promptText=prompt,\n                seed=seed,\n                model=Model(\"gen3a_turbo\"),\n                duration=Duration(duration),\n                ratio=AspectRatio(ratio),\n                promptImage=RunwayPromptImageObject(\n                    root=[\n                        RunwayPromptImageDetailedObject(\n                            uri=str(download_urls[0]), position=\"first\"\n                        ),",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 464,
        "end": 478,
        "startLoc": {
          "line": 464,
          "column": 2,
          "position": 2790
        },
        "endLoc": {
          "line": 478,
          "column": 2,
          "position": 2885
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_runway.py",
        "start": 274,
        "end": 289,
        "startLoc": {
          "line": 274,
          "column": 2,
          "position": 1636
        },
        "endLoc": {
          "line": 289,
          "column": 2,
          "position": 1733
        }
      }
    },
    {
      "format": "python",
      "lines": 31,
      "fragment": "(Rodin3DAPI):\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"Images\":\n                (\n                    IO.IMAGE,\n                    {\n                        \"forceInput\":True,\n                    }\n                )\n            },\n            \"optional\": {\n                **COMMON_PARAMETERS\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n            },\n        }\n\n    def api_call(\n        self,\n        Images,\n        Seed,\n        Material_Type,\n        Polygon_count,\n        **kwargs\n    ):\n        tier = \"Detail\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_rodin.py",
        "start": 309,
        "end": 339,
        "startLoc": {
          "line": 309,
          "column": 15,
          "position": 2149
        },
        "endLoc": {
          "line": 339,
          "column": 9,
          "position": 2291
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_rodin.py",
        "start": 266,
        "end": 296,
        "startLoc": {
          "line": 266,
          "column": 16,
          "position": 1847
        },
        "endLoc": {
          "line": 296,
          "column": 10,
          "position": 1989
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "num_images = Images.shape[0]\n        m_images = []\n        for i in range(num_images):\n            m_images.append(Images[i])\n        mesh_mode, quality = self.GetQualityAndMode(Polygon_count)\n        task_uuid, subscription_key = self.CreateGenerateTask(images=m_images, seed=Seed, material=Material_Type, quality=quality, tier=tier, mesh_mode=mesh_mode, **kwargs)\n        self.poll_for_task_status(subscription_key, **kwargs)\n        Download_List = self.GetRodinDownloadList(task_uuid, **kwargs)\n        model = self.DownLoadFiles(Download_List)\n\n        return (model,)\n\nclass Rodin3D_Smooth",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_rodin.py",
        "start": 340,
        "end": 352,
        "startLoc": {
          "line": 340,
          "column": 9,
          "position": 2294
        },
        "endLoc": {
          "line": 352,
          "column": 15,
          "position": 2450
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_rodin.py",
        "start": 297,
        "end": 309,
        "startLoc": {
          "line": 297,
          "column": 9,
          "position": 1992
        },
        "endLoc": {
          "line": 309,
          "column": 15,
          "position": 2148
        }
      }
    },
    {
      "format": "python",
      "lines": 31,
      "fragment": "(Rodin3DAPI):\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"Images\":\n                (\n                    IO.IMAGE,\n                    {\n                        \"forceInput\":True,\n                    }\n                )\n            },\n            \"optional\": {\n                **COMMON_PARAMETERS\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n            },\n        }\n\n    def api_call(\n        self,\n        Images,\n        Seed,\n        Material_Type,\n        Polygon_count,\n        **kwargs\n    ):\n        tier = \"Smooth\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_rodin.py",
        "start": 352,
        "end": 382,
        "startLoc": {
          "line": 352,
          "column": 15,
          "position": 2451
        },
        "endLoc": {
          "line": 382,
          "column": 9,
          "position": 2593
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_rodin.py",
        "start": 266,
        "end": 296,
        "startLoc": {
          "line": 266,
          "column": 16,
          "position": 1847
        },
        "endLoc": {
          "line": 296,
          "column": 10,
          "position": 1989
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "num_images = Images.shape[0]\n        m_images = []\n        for i in range(num_images):\n            m_images.append(Images[i])\n        mesh_mode, quality = self.GetQualityAndMode(Polygon_count)\n        task_uuid, subscription_key = self.CreateGenerateTask(images=m_images, seed=Seed, material=Material_Type, quality=quality, tier=tier, mesh_mode=mesh_mode, **kwargs)\n        self.poll_for_task_status(subscription_key, **kwargs)\n        Download_List = self.GetRodinDownloadList(task_uuid, **kwargs)\n        model = self.DownLoadFiles(Download_List)\n\n        return (model,)\n\nclass Rodin3D_Sketch",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_rodin.py",
        "start": 383,
        "end": 395,
        "startLoc": {
          "line": 383,
          "column": 9,
          "position": 2596
        },
        "endLoc": {
          "line": 395,
          "column": 15,
          "position": 2752
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_rodin.py",
        "start": 297,
        "end": 309,
        "startLoc": {
          "line": 297,
          "column": 9,
          "position": 1992
        },
        "endLoc": {
          "line": 309,
          "column": 15,
          "position": 2148
        }
      }
    },
    {
      "format": "python",
      "lines": 47,
      "fragment": ",\n                ),\n                \"quality\": (\n                    [resolution.value for resolution in PixverseQuality],\n                    {\n                        \"default\": PixverseQuality.res_540p,\n                    },\n                ),\n                \"duration_seconds\": ([dur.value for dur in PixverseDuration],),\n                \"motion_mode\": ([mode.value for mode in PixverseMotionMode],),\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 2147483647,\n                        \"control_after_generate\": True,\n                        \"tooltip\": \"Seed for video generation.\",\n                    },\n                ),\n            },\n            \"optional\": {\n                \"negative_prompt\": (\n                    IO.STRING,\n                    {\n                        \"default\": \"\",\n                        \"forceInput\": True,\n                        \"tooltip\": \"An optional text description of undesired elements on an image.\",\n                    },\n                ),\n                \"pixverse_template\": (\n                    PixverseIO.TEMPLATE,\n                    {\n                        \"tooltip\": \"An optional template to influence style of generation, created by the PixVerse Template node.\"\n                    },\n                ),\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n                \"unique_id\": \"UNIQUE_ID\",\n            },\n        }\n\n    def api_call(\n        self,\n        image",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 261,
        "end": 307,
        "startLoc": {
          "line": 261,
          "column": 2,
          "position": 1624
        },
        "endLoc": {
          "line": 307,
          "column": 6,
          "position": 1907
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 124,
        "end": 169,
        "startLoc": {
          "line": 124,
          "column": 2,
          "position": 731
        },
        "endLoc": {
          "line": 169,
          "column": 7,
          "position": 1012
        }
      }
    },
    {
      "format": "python",
      "lines": 12,
      "fragment": ": str,\n        quality: str,\n        duration_seconds: int,\n        motion_mode: str,\n        seed,\n        negative_prompt: str = None,\n        pixverse_template: int = None,\n        unique_id: Optional[str] = None,\n        **kwargs,\n    ):\n        validate_string(prompt, strip_whitespace=False)\n        img_id",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 308,
        "end": 319,
        "startLoc": {
          "line": 308,
          "column": 7,
          "position": 1917
        },
        "endLoc": {
          "line": 319,
          "column": 7,
          "position": 2004
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 170,
        "end": 181,
        "startLoc": {
          "line": 170,
          "column": 13,
          "position": 1020
        },
        "endLoc": {
          "line": 181,
          "column": 41,
          "position": 1107
        }
      }
    },
    {
      "format": "python",
      "lines": 33,
      "fragment": ",\n                quality=quality,\n                duration=duration_seconds,\n                motion_mode=motion_mode,\n                negative_prompt=negative_prompt if negative_prompt else None,\n                template_id=pixverse_template,\n                seed=seed,\n            ),\n            auth_kwargs=kwargs,\n        )\n        response_api = operation.execute()\n\n        if response_api.Resp is None:\n            raise Exception(f\"PixVerse request failed: '{response_api.ErrMsg}'\")\n\n        operation = PollingOperation(\n            poll_endpoint=ApiEndpoint(\n                path=f\"/proxy/pixverse/video/result/{response_api.Resp.video_id}\",\n                method=HttpMethod.GET,\n                request_model=EmptyRequest,\n                response_model=PixverseGenerationStatusResponse,\n            ),\n            completed_statuses=[PixverseStatus.successful],\n            failed_statuses=[\n                PixverseStatus.contents_moderation,\n                PixverseStatus.failed,\n                PixverseStatus.deleted,\n            ],\n            status_extractor=lambda x: x.Resp.status,\n            auth_kwargs=kwargs,\n            node_id=unique_id,\n            result_url_extractor=get_video_url_from_response,\n            estimated_duration=AVERAGE_DURATION_I2V",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 338,
        "end": 370,
        "startLoc": {
          "line": 338,
          "column": 7,
          "position": 2137
        },
        "endLoc": {
          "line": 370,
          "column": 21,
          "position": 2348
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 198,
        "end": 230,
        "startLoc": {
          "line": 198,
          "column": 13,
          "position": 1224
        },
        "endLoc": {
          "line": 230,
          "column": 21,
          "position": 1435
        }
      }
    },
    {
      "format": "python",
      "lines": 38,
      "fragment": ": (IO.IMAGE,),\n                \"prompt\": (\n                    IO.STRING,\n                    {\n                        \"multiline\": True,\n                        \"default\": \"\",\n                        \"tooltip\": \"Prompt for the video generation\",\n                    },\n                ),\n                \"quality\": (\n                    [resolution.value for resolution in PixverseQuality],\n                    {\n                        \"default\": PixverseQuality.res_540p,\n                    },\n                ),\n                \"duration_seconds\": ([dur.value for dur in PixverseDuration],),\n                \"motion_mode\": ([mode.value for mode in PixverseMotionMode],),\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 2147483647,\n                        \"control_after_generate\": True,\n                        \"tooltip\": \"Seed for video generation.\",\n                    },\n                ),\n            },\n            \"optional\": {\n                \"negative_prompt\": (\n                    IO.STRING,\n                    {\n                        \"default\": \"\",\n                        \"forceInput\": True,\n                        \"tooltip\": \"An optional text description of undesired elements on an image.\",\n                    },\n                ),\n            }",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 394,
        "end": 431,
        "startLoc": {
          "line": 394,
          "column": 13,
          "position": 2500
        },
        "endLoc": {
          "line": 431,
          "column": 2,
          "position": 2753
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 254,
        "end": 153,
        "startLoc": {
          "line": 254,
          "column": 8,
          "position": 1576
        },
        "endLoc": {
          "line": 153,
          "column": 20,
          "position": 934
        }
      }
    },
    {
      "format": "python",
      "lines": 36,
      "fragment": ",\n                seed=seed,\n            ),\n            auth_kwargs=kwargs,\n        )\n        response_api = operation.execute()\n\n        if response_api.Resp is None:\n            raise Exception(f\"PixVerse request failed: '{response_api.ErrMsg}'\")\n\n        operation = PollingOperation(\n            poll_endpoint=ApiEndpoint(\n                path=f\"/proxy/pixverse/video/result/{response_api.Resp.video_id}\",\n                method=HttpMethod.GET,\n                request_model=EmptyRequest,\n                response_model=PixverseGenerationStatusResponse,\n            ),\n            completed_statuses=[PixverseStatus.successful],\n            failed_statuses=[\n                PixverseStatus.contents_moderation,\n                PixverseStatus.failed,\n                PixverseStatus.deleted,\n            ],\n            status_extractor=lambda x: x.Resp.status,\n            auth_kwargs=kwargs,\n            node_id=unique_id,\n            result_url_extractor=get_video_url_from_response,\n            estimated_duration=AVERAGE_DURATION_T2V,\n        )\n        response_poll = operation.execute()\n\n        vid_response = requests.get(response_poll.Resp.url)\n        return (VideoFromFile(BytesIO(vid_response.content)),)\n\n\nNODE_CLASS_MAPPINGS",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 478,
        "end": 513,
        "startLoc": {
          "line": 478,
          "column": 5,
          "position": 3083
        },
        "endLoc": {
          "line": 513,
          "column": 20,
          "position": 3308
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pixverse.py",
        "start": 203,
        "end": 239,
        "startLoc": {
          "line": 203,
          "column": 18,
          "position": 1262
        },
        "endLoc": {
          "line": 239,
          "column": 6,
          "position": 1488
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": ": torch.Tensor,\n        prompt_text: str,\n        negative_prompt: str,\n        seed: int,\n        unique_id: str,\n        **kwargs,\n    ) -> tuple[VideoFromFile]:\n        # Convert video to BytesIO\n        video_bytes_io = io.BytesIO()\n        video.save_to(video_bytes_io, format=VideoContainer.MP4, codec=VideoCodec.H264)\n        video_bytes_io.seek(0)\n\n        # Convert mask to binary mask with three channels",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pika.py",
        "start": 565,
        "end": 577,
        "startLoc": {
          "line": 565,
          "column": 5,
          "position": 3387
        },
        "endLoc": {
          "line": 577,
          "column": 50,
          "position": 3485
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pika.py",
        "start": 468,
        "end": 480,
        "startLoc": {
          "line": 468,
          "column": 6,
          "position": 2797
        },
        "endLoc": {
          "line": 480,
          "column": 27,
          "position": 2895
        }
      }
    },
    {
      "format": "python",
      "lines": 23,
      "fragment": "(\n            promptText=prompt_text,\n            negativePrompt=negative_prompt,\n            seed=seed,\n        )\n\n        initial_operation = SynchronousOperation(\n            endpoint=ApiEndpoint(\n                path=PATH_PIKADDITIONS,\n                method=HttpMethod.POST,\n                request_model=PikaBodyGeneratePikadditionsGeneratePikadditionsPost,\n                response_model=PikaGenerateResponse,\n            ),\n            request=pika_request_data,\n            files=pika_files,\n            content_type=\"multipart/form-data\",\n            auth_kwargs=kwargs,\n        )\n\n        return self.execute_task(initial_operation, auth_kwargs=kwargs, node_id=unique_id)\n\n\nclass PikaffectsNode",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pika.py",
        "start": 597,
        "end": 619,
        "startLoc": {
          "line": 597,
          "column": 47,
          "position": 3656
        },
        "endLoc": {
          "line": 619,
          "column": 15,
          "position": 3776
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_pika.py",
        "start": 490,
        "end": 512,
        "startLoc": {
          "line": 490,
          "column": 53,
          "position": 2970
        },
        "endLoc": {
          "line": 512,
          "column": 14,
          "position": 3090
        }
      }
    },
    {
      "format": "python",
      "lines": 26,
      "fragment": ",\n                        \"tooltip\": \"Model to use for video generation\",\n                    },\n                ),\n            },\n            \"optional\": {\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 0xFFFFFFFFFFFFFFFF,\n                        \"control_after_generate\": True,\n                        \"tooltip\": \"The random seed used for creating the noise.\",\n                    },\n                ),\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n                \"unique_id\": \"UNIQUE_ID\",\n            },\n        }\n\n    RETURN_TYPES = (\"VIDEO\",)\n    DESCRIPTION = \"Generates videos from an image and prompts using MiniMax's API\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_minimax.py",
        "start": 225,
        "end": 250,
        "startLoc": {
          "line": 225,
          "column": 9,
          "position": 1324
        },
        "endLoc": {
          "line": 250,
          "column": 65,
          "position": 1463
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_minimax.py",
        "start": 58,
        "end": 83,
        "startLoc": {
          "line": 58,
          "column": 9,
          "position": 269
        },
        "endLoc": {
          "line": 83,
          "column": 52,
          "position": 408
        }
      }
    },
    {
      "format": "python",
      "lines": 33,
      "fragment": ",\n                        \"tooltip\": \"Model to use for video generation\",\n                    },\n                ),\n            },\n            \"optional\": {\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 0xFFFFFFFFFFFFFFFF,\n                        \"control_after_generate\": True,\n                        \"tooltip\": \"The random seed used for creating the noise.\",\n                    },\n                ),\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n                \"unique_id\": \"UNIQUE_ID\",\n            },\n        }\n\n    RETURN_TYPES = (\"VIDEO\",)\n    DESCRIPTION = \"Generates videos from an image and prompts using MiniMax's API\"\n    FUNCTION = \"generate_video\"\n    CATEGORY = \"api node/video/MiniMax\"\n    API_NODE = True\n    OUTPUT_NODE = True\n\n\n# A dictionary that contains all nodes you want to export with their names",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_minimax.py",
        "start": 287,
        "end": 319,
        "startLoc": {
          "line": 287,
          "column": 9,
          "position": 1635
        },
        "endLoc": {
          "line": 319,
          "column": 75,
          "position": 1806
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_minimax.py",
        "start": 58,
        "end": 257,
        "startLoc": {
          "line": 58,
          "column": 9,
          "position": 269
        },
        "endLoc": {
          "line": 257,
          "column": 6,
          "position": 1495
        }
      }
    },
    {
      "format": "python",
      "lines": 28,
      "fragment": ",\n            ),\n            auth_kwargs=kwargs,\n        )\n        response_api: LumaGeneration = operation.execute()\n\n        operation = PollingOperation(\n            poll_endpoint=ApiEndpoint(\n                path=f\"/proxy/luma/generations/{response_api.id}\",\n                method=HttpMethod.GET,\n                request_model=EmptyRequest,\n                response_model=LumaGeneration,\n            ),\n            completed_statuses=[LumaState.completed],\n            failed_statuses=[LumaState.failed],\n            status_extractor=lambda x: x.state,\n            result_url_extractor=image_result_url_extractor,\n            node_id=unique_id,\n            auth_kwargs=kwargs,\n        )\n        response_poll = operation.execute()\n\n        img_response = requests.get(response_poll.assets.image)\n        img = process_image_response(img_response)\n        return (img,)\n\n\nclass",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 401,
        "end": 428,
        "startLoc": {
          "line": 401,
          "column": 2,
          "position": 2701
        },
        "endLoc": {
          "line": 428,
          "column": 6,
          "position": 2878
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 269,
        "end": 295,
        "startLoc": {
          "line": 269,
          "column": 14,
          "position": 1755
        },
        "endLoc": {
          "line": 295,
          "column": 4,
          "position": 1932
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": ")\n\n        operation = PollingOperation(\n            poll_endpoint=ApiEndpoint(\n                path=f\"/proxy/luma/generations/{response_api.id}\",\n                method=HttpMethod.GET,\n                request_model=EmptyRequest,\n                response_model=LumaGeneration,\n            ),\n            completed_statuses=[LumaState.completed],\n            failed_statuses=[LumaState.failed],\n            status_extractor=lambda x: x.state,\n            result_url_extractor=video_result_url_extractor",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 535,
        "end": 547,
        "startLoc": {
          "line": 535,
          "column": 10,
          "position": 3598
        },
        "endLoc": {
          "line": 547,
          "column": 27,
          "position": 3682
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 273,
        "end": 285,
        "startLoc": {
          "line": 273,
          "column": 2,
          "position": 1782
        },
        "endLoc": {
          "line": 285,
          "column": 27,
          "position": 1866
        }
      }
    },
    {
      "format": "python",
      "lines": 20,
      "fragment": "RETURN_TYPES = (IO.VIDEO,)\n    DESCRIPTION = cleandoc(__doc__ or \"\")  # Handle potential None value\n    FUNCTION = \"api_call\"\n    API_NODE = True\n    CATEGORY = \"api node/video/Luma\"\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"prompt\": (\n                    IO.STRING,\n                    {\n                        \"multiline\": True,\n                        \"default\": \"\",\n                        \"tooltip\": \"Prompt for the video generation\",\n                    },\n                ),\n                \"model\": ([model.value for model in LumaVideoModel],),\n                # \"aspect_ratio\": ([ratio.value for ratio in LumaAspectRatio], {",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 563,
        "end": 582,
        "startLoc": {
          "line": 563,
          "column": 5,
          "position": 3765
        },
        "endLoc": {
          "line": 582,
          "column": 65,
          "position": 3905
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 433,
        "end": 452,
        "startLoc": {
          "line": 433,
          "column": 5,
          "position": 2891
        },
        "endLoc": {
          "line": 452,
          "column": 15,
          "position": 3031
        }
      }
    },
    {
      "format": "python",
      "lines": 26,
      "fragment": "\"resolution\": (\n                    [resolution.value for resolution in LumaVideoOutputResolution],\n                    {\n                        \"default\": LumaVideoOutputResolution.res_540p,\n                    },\n                ),\n                \"duration\": ([dur.value for dur in LumaVideoModelOutputDuration],),\n                \"loop\": (\n                    IO.BOOLEAN,\n                    {\n                        \"default\": False,\n                    },\n                ),\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 0xFFFFFFFFFFFFFFFF,\n                        \"control_after_generate\": True,\n                        \"tooltip\": \"Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.\",\n                    },\n                ),\n            },\n            \"optional\": {\n                \"first_image\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 585,
        "end": 610,
        "startLoc": {
          "line": 585,
          "column": 17,
          "position": 3914
        },
        "endLoc": {
          "line": 610,
          "column": 14,
          "position": 4076
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 458,
        "end": 483,
        "startLoc": {
          "line": 458,
          "column": 17,
          "position": 3073
        },
        "endLoc": {
          "line": 483,
          "column": 16,
          "position": 3235
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": ")\n        duration = duration if model != LumaVideoModel.ray_1_6 else None\n        resolution = resolution if model != LumaVideoModel.ray_1_6 else None\n\n        operation = SynchronousOperation(\n            endpoint=ApiEndpoint(\n                path=\"/proxy/luma/generations\",\n                method=HttpMethod.POST,\n                request_model=LumaGenerationRequest,\n                response_model=LumaGeneration,\n            ),\n            request=LumaGenerationRequest(\n                prompt=prompt,\n                model=model,\n                aspect_ratio",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 647,
        "end": 661,
        "startLoc": {
          "line": 647,
          "column": 7,
          "position": 4341
        },
        "endLoc": {
          "line": 661,
          "column": 13,
          "position": 4449
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 510,
        "end": 524,
        "startLoc": {
          "line": 510,
          "column": 2,
          "position": 3403
        },
        "endLoc": {
          "line": 524,
          "column": 11,
          "position": 3511
        }
      }
    },
    {
      "format": "python",
      "lines": 23,
      "fragment": ",\n                concepts=luma_concepts.create_api_model() if luma_concepts else None,\n            ),\n            auth_kwargs=kwargs,\n        )\n        response_api: LumaGeneration = operation.execute()\n\n        if unique_id:\n            PromptServer.instance.send_progress_text(f\"Luma video generation started: {response_api.id}\", unique_id)\n\n        operation = PollingOperation(\n            poll_endpoint=ApiEndpoint(\n                path=f\"/proxy/luma/generations/{response_api.id}\",\n                method=HttpMethod.GET,\n                request_model=EmptyRequest,\n                response_model=LumaGeneration,\n            ),\n            completed_statuses=[LumaState.completed],\n            failed_statuses=[LumaState.failed],\n            status_extractor=lambda x: x.state,\n            result_url_extractor=video_result_url_extractor,\n            node_id=unique_id,\n            estimated_duration=LUMA_I2V_AVERAGE_DURATION",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 665,
        "end": 687,
        "startLoc": {
          "line": 665,
          "column": 10,
          "position": 4480
        },
        "endLoc": {
          "line": 687,
          "column": 26,
          "position": 4642
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_luma.py",
        "start": 527,
        "end": 549,
        "startLoc": {
          "line": 527,
          "column": 5,
          "position": 3532
        },
        "endLoc": {
          "line": 549,
          "column": 26,
          "position": 3694
        }
      }
    },
    {
      "format": "python",
      "lines": 30,
      "fragment": "def __init__(self):\n        pass\n\n    @classmethod\n    def INPUT_TYPES(cls) -> InputTypeDict:\n        return {\n            \"required\": {\n                \"prompt\": (\n                    IO.STRING,\n                    {\n                        \"multiline\": True,\n                        \"default\": \"\",\n                        \"tooltip\": \"Prompt for the image generation\",\n                    },\n                ),\n                \"turbo\": (\n                    IO.BOOLEAN,\n                    {\n                        \"default\": False,\n                        \"tooltip\": \"Whether to use turbo mode (faster generation, potentially lower quality)\",\n                    }\n                ),\n            },\n            \"optional\": {\n                \"aspect_ratio\": (\n                    IO.COMBO,\n                    {\n                        \"options\": list(V1_V2_RATIO_MAP.keys()),\n                        \"default\": \"1:1\",\n                        \"tooltip\": \"The aspect ratio for image generation. Ignored if resolution is not set to AUTO.\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 389,
        "end": 418,
        "startLoc": {
          "line": 389,
          "column": 5,
          "position": 2182
        },
        "endLoc": {
          "line": 418,
          "column": 83,
          "position": 2353
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 254,
        "end": 283,
        "startLoc": {
          "line": 254,
          "column": 5,
          "position": 1327
        },
        "endLoc": {
          "line": 283,
          "column": 41,
          "position": 1498
        }
      }
    },
    {
      "format": "python",
      "lines": 23,
      "fragment": ",\n                    },\n                ),\n                \"magic_prompt_option\": (\n                    IO.COMBO,\n                    {\n                        \"options\": [\"AUTO\", \"ON\", \"OFF\"],\n                        \"default\": \"AUTO\",\n                        \"tooltip\": \"Determine if MagicPrompt should be used in generation\",\n                    },\n                ),\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 2147483647,\n                        \"step\": 1,\n                        \"control_after_generate\": True,\n                        \"display\": \"number\",\n                    },\n                ),\n                \"style_type\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 426,
        "end": 448,
        "startLoc": {
          "line": 426,
          "column": 100,
          "position": 2405
        },
        "endLoc": {
          "line": 448,
          "column": 13,
          "position": 2533
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 283,
        "end": 305,
        "startLoc": {
          "line": 283,
          "column": 41,
          "position": 1499
        },
        "endLoc": {
          "line": 305,
          "column": 18,
          "position": 1627
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": ",\n                    },\n                ),\n                \"negative_prompt\": (\n                    IO.STRING,\n                    {\n                        \"multiline\": True,\n                        \"default\": \"\",\n                        \"tooltip\": \"Description of what to exclude from the image\",\n                    },\n                ),\n                \"num_images\": (\n                    IO.INT,\n                    {\"default\": 1, \"min\": 1, \"max\": 8, \"step\": 1, \"display\": \"number\"},\n                ),\n                #\"color_palette\": (",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 453,
        "end": 468,
        "startLoc": {
          "line": 453,
          "column": 38,
          "position": 2583
        },
        "endLoc": {
          "line": 468,
          "column": 20,
          "position": 2687
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 302,
        "end": 317,
        "startLoc": {
          "line": 302,
          "column": 9,
          "position": 1616
        },
        "endLoc": {
          "line": 317,
          "column": 2,
          "position": 1720
        }
      }
    },
    {
      "format": "python",
      "lines": 20,
      "fragment": "},\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n                \"unique_id\": \"UNIQUE_ID\",\n            },\n        }\n\n    RETURN_TYPES = (IO.IMAGE,)\n    FUNCTION = \"api_call\"\n    CATEGORY = \"api node/image/Ideogram\"\n    DESCRIPTION = cleandoc(__doc__ or \"\")\n    API_NODE = True\n\n    def api_call(\n        self,\n        prompt,\n        turbo=False,\n        aspect_ratio=\"1:1\",\n        resolution",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 476,
        "end": 495,
        "startLoc": {
          "line": 476,
          "column": 13,
          "position": 2711
        },
        "endLoc": {
          "line": 495,
          "column": 11,
          "position": 2824
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 317,
        "end": 336,
        "startLoc": {
          "line": 317,
          "column": 13,
          "position": 1720
        },
        "endLoc": {
          "line": 336,
          "column": 20,
          "position": 1833
        }
      }
    },
    {
      "format": "python",
      "lines": 14,
      "fragment": "operation = SynchronousOperation(\n            endpoint=ApiEndpoint(\n                path=\"/proxy/ideogram/generate\",\n                method=HttpMethod.POST,\n                request_model=IdeogramGenerateRequest,\n                response_model=IdeogramGenerateResponse,\n            ),\n            request=IdeogramGenerateRequest(\n                image_request=ImageRequest(\n                    prompt=prompt,\n                    model=model,\n                    num_images=num_images,\n                    seed=seed,\n                    aspect_ratio=final_aspect_ratio",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 520,
        "end": 533,
        "startLoc": {
          "line": 520,
          "column": 9,
          "position": 2992
        },
        "endLoc": {
          "line": 533,
          "column": 19,
          "position": 3074
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 347,
        "end": 360,
        "startLoc": {
          "line": 347,
          "column": 9,
          "position": 1906
        },
        "endLoc": {
          "line": 360,
          "column": 13,
          "position": 1988
        }
      }
    },
    {
      "format": "python",
      "lines": 20,
      "fragment": "else None,\n                )\n            ),\n            auth_kwargs=kwargs,\n        )\n\n        response = operation.execute()\n\n        if not response.data or len(response.data) == 0:\n            raise Exception(\"No images were generated in the response\")\n\n        image_urls = [image_data.url for image_data in response.data if image_data.url]\n\n        if not image_urls:\n            raise Exception(\"No image URLs were generated in the response\")\n\n        display_image_urls_on_node(image_urls, unique_id)\n        return (download_and_process_images(image_urls),)\n\nclass IdeogramV3",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 540,
        "end": 559,
        "startLoc": {
          "line": 540,
          "column": 2,
          "position": 3148
        },
        "endLoc": {
          "line": 559,
          "column": 11,
          "position": 3282
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 364,
        "end": 384,
        "startLoc": {
          "line": 364,
          "column": 2,
          "position": 2036
        },
        "endLoc": {
          "line": 384,
          "column": 11,
          "position": 2171
        }
      }
    },
    {
      "format": "python",
      "lines": 23,
      "fragment": ",\n                    },\n                ),\n                \"magic_prompt_option\": (\n                    IO.COMBO,\n                    {\n                        \"options\": [\"AUTO\", \"ON\", \"OFF\"],\n                        \"default\": \"AUTO\",\n                        \"tooltip\": \"Determine if MagicPrompt should be used in generation\",\n                    },\n                ),\n                \"seed\": (\n                    IO.INT,\n                    {\n                        \"default\": 0,\n                        \"min\": 0,\n                        \"max\": 2147483647,\n                        \"step\": 1,\n                        \"control_after_generate\": True,\n                        \"display\": \"number\",\n                    },\n                ),\n                \"num_images\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 608,
        "end": 630,
        "startLoc": {
          "line": 608,
          "column": 100,
          "position": 3547
        },
        "endLoc": {
          "line": 630,
          "column": 13,
          "position": 3675
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 283,
        "end": 305,
        "startLoc": {
          "line": 283,
          "column": 41,
          "position": 1499
        },
        "endLoc": {
          "line": 305,
          "column": 18,
          "position": 1627
        }
      }
    },
    {
      "format": "python",
      "lines": 20,
      "fragment": "},\n                ),\n            },\n            \"hidden\": {\n                \"auth_token\": \"AUTH_TOKEN_COMFY_ORG\",\n                \"comfy_api_key\": \"API_KEY_COMFY_ORG\",\n                \"unique_id\": \"UNIQUE_ID\",\n            },\n        }\n\n    RETURN_TYPES = (IO.IMAGE,)\n    FUNCTION = \"api_call\"\n    CATEGORY = \"api node/image/Ideogram\"\n    DESCRIPTION = cleandoc(__doc__ or \"\")\n    API_NODE = True\n\n    def api_call(\n        self,\n        prompt,\n        image",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 640,
        "end": 659,
        "startLoc": {
          "line": 640,
          "column": 21,
          "position": 3768
        },
        "endLoc": {
          "line": 659,
          "column": 6,
          "position": 3877
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 315,
        "end": 334,
        "startLoc": {
          "line": 315,
          "column": 9,
          "position": 1712
        },
        "endLoc": {
          "line": 334,
          "column": 6,
          "position": 1821
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": "response = operation.execute()\n\n        if not response.data or len(response.data) == 0:\n            raise Exception(\"No images were generated in the response\")\n\n        image_urls = [image_data.url for image_data in response.data if image_data.url]\n\n        if not image_urls:\n            raise Exception(\"No image URLs were generated in the response\")\n\n        display_image_urls_on_node(image_urls, unique_id)\n        return (download_and_process_images(image_urls),)\n\n\nNODE_CLASS_MAPPINGS",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 777,
        "end": 791,
        "startLoc": {
          "line": 777,
          "column": 9,
          "position": 4692
        },
        "endLoc": {
          "line": 791,
          "column": 20,
          "position": 4802
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_api_nodes/nodes_ideogram.py",
        "start": 370,
        "end": 384,
        "startLoc": {
          "line": 370,
          "column": 9,
          "position": 2059
        },
        "endLoc": {
          "line": 384,
          "column": 6,
          "position": 2169
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", device=\"cpu\", max_length=77, freeze=True, layer=\"penultimate\", layer_idx=None, dtype=None, model_options={}):\n        if layer == \"penultimate\":\n            layer=\"hidden\"\n            layer_idx=-2\n\n        textmodel_json_config = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"clip_config_bigg.json\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/sdxl_clip.py",
        "start": 6,
        "end": 11,
        "startLoc": {
          "line": 6,
          "column": 5,
          "position": 33
        },
        "endLoc": {
          "line": 11,
          "column": 24,
          "position": 122
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd2_clip.py",
        "start": 5,
        "end": 10,
        "startLoc": {
          "line": 5,
          "column": 11,
          "position": 34
        },
        "endLoc": {
          "line": 10,
          "column": 23,
          "position": 123
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "(embedding_directory=embedding_directory, tokenizer_data=tokenizer_data)\n\n    def tokenize_with_weights(self, text:str, return_word_ids=False, **kwargs):\n        out = {}\n        out[\"g\"] = self.clip_g.tokenize_with_weights(text, return_word_ids, **kwargs)\n        out[\"l\"] = self.clip_l.tokenize_with_weights(text, return_word_ids, **kwargs)\n        return",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/sdxl_clip.py",
        "start": 27,
        "end": 33,
        "startLoc": {
          "line": 27,
          "column": 19,
          "position": 368
        },
        "endLoc": {
          "line": 33,
          "column": 7,
          "position": 460
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/sd3_clip.py",
        "start": 44,
        "end": 50,
        "startLoc": {
          "line": 44,
          "column": 15,
          "position": 584
        },
        "endLoc": {
          "line": 50,
          "column": 4,
          "position": 676
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "(input, weight, bias)\n\n        def forward(self, *args, **kwargs):\n            if self.comfy_cast_weights or len(self.weight_function) > 0 or len(self.bias_function) > 0:\n                return self.forward_comfy_cast_weights(*args, **kwargs)\n            else:\n                return super().forward(*args, **kwargs)\n\n    class Conv2d",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 94,
        "end": 102,
        "startLoc": {
          "line": 94,
          "column": 14,
          "position": 760
        },
        "endLoc": {
          "line": 102,
          "column": 7,
          "position": 862
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 80,
        "end": 88,
        "startLoc": {
          "line": 80,
          "column": 7,
          "position": 596
        },
        "endLoc": {
          "line": 88,
          "column": 7,
          "position": 698
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": ", CastWeightBiasOp):\n        def reset_parameters(self):\n            return None\n\n        def forward_comfy_cast_weights(self, input):\n            weight, bias = cast_bias_weight(self, input)\n            return self._conv_forward(input, weight, bias)\n\n        def forward(self, *args, **kwargs):\n            if self.comfy_cast_weights or len(self.weight_function) > 0 or len(self.bias_function) > 0:\n                return self.forward_comfy_cast_weights(*args, **kwargs)\n            else:\n                return super().forward(*args, **kwargs)\n\n    class Conv3d",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 102,
        "end": 116,
        "startLoc": {
          "line": 102,
          "column": 7,
          "position": 869
        },
        "endLoc": {
          "line": 116,
          "column": 7,
          "position": 1026
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 88,
        "end": 88,
        "startLoc": {
          "line": 88,
          "column": 7,
          "position": 705
        },
        "endLoc": {
          "line": 88,
          "column": 7,
          "position": 698
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": ", CastWeightBiasOp):\n        def reset_parameters(self):\n            return None\n\n        def forward_comfy_cast_weights(self, input):\n            weight, bias = cast_bias_weight(self, input)\n            return self._conv_forward(input, weight, bias)\n\n        def forward(self, *args, **kwargs):\n            if self.comfy_cast_weights or len(self.weight_function) > 0 or len(self.bias_function) > 0:\n                return self.forward_comfy_cast_weights(*args, **kwargs)\n            else:\n                return super().forward(*args, **kwargs)\n\n    class GroupNorm",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 116,
        "end": 130,
        "startLoc": {
          "line": 116,
          "column": 7,
          "position": 1033
        },
        "endLoc": {
          "line": 130,
          "column": 10,
          "position": 1190
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 88,
        "end": 88,
        "startLoc": {
          "line": 88,
          "column": 7,
          "position": 705
        },
        "endLoc": {
          "line": 88,
          "column": 7,
          "position": 698
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": ")\n\n        def forward(self, *args, **kwargs):\n            if self.comfy_cast_weights or len(self.weight_function) > 0 or len(self.bias_function) > 0:\n                return self.forward_comfy_cast_weights(*args, **kwargs)\n            else:\n                return super().forward(*args, **kwargs)\n\n    class LayerNorm",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 136,
        "end": 144,
        "startLoc": {
          "line": 136,
          "column": 4,
          "position": 1274
        },
        "endLoc": {
          "line": 144,
          "column": 10,
          "position": 1368
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 80,
        "end": 88,
        "startLoc": {
          "line": 80,
          "column": 5,
          "position": 604
        },
        "endLoc": {
          "line": 88,
          "column": 7,
          "position": 698
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": ", weight, bias, self.eps)\n\n        def forward(self, *args, **kwargs):\n            if self.comfy_cast_weights or len(self.weight_function) > 0 or len(self.bias_function) > 0:\n                return self.forward_comfy_cast_weights(*args, **kwargs)\n            else:\n                return super().forward(*args, **kwargs)\n\n    class RMSNorm",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 154,
        "end": 162,
        "startLoc": {
          "line": 154,
          "column": 17,
          "position": 1473
        },
        "endLoc": {
          "line": 162,
          "column": 8,
          "position": 1578
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 136,
        "end": 88,
        "startLoc": {
          "line": 136,
          "column": 11,
          "position": 1263
        },
        "endLoc": {
          "line": 88,
          "column": 7,
          "position": 698
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "def forward(self, *args, **kwargs):\n            if self.comfy_cast_weights or len(self.weight_function) > 0 or len(self.bias_function) > 0:\n                return self.forward_comfy_cast_weights(*args, **kwargs)\n            else:\n                return super().forward(*args, **kwargs)\n\n    class ConvTranspose2d",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 175,
        "end": 181,
        "startLoc": {
          "line": 175,
          "column": 9,
          "position": 1695
        },
        "endLoc": {
          "line": 181,
          "column": 16,
          "position": 1785
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 82,
        "end": 88,
        "startLoc": {
          "line": 82,
          "column": 9,
          "position": 608
        },
        "endLoc": {
          "line": 88,
          "column": 7,
          "position": 698
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": ")\n\n        def forward(self, *args, **kwargs):\n            if self.comfy_cast_weights or len(self.weight_function) > 0 or len(self.bias_function) > 0:\n                return self.forward_comfy_cast_weights(*args, **kwargs)\n            else:\n                return super().forward(*args, **kwargs)\n\n    class ConvTranspose1d",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 194,
        "end": 202,
        "startLoc": {
          "line": 194,
          "column": 9,
          "position": 1939
        },
        "endLoc": {
          "line": 202,
          "column": 16,
          "position": 2033
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 80,
        "end": 88,
        "startLoc": {
          "line": 80,
          "column": 5,
          "position": 604
        },
        "endLoc": {
          "line": 88,
          "column": 7,
          "position": 698
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "(\n                input, weight, bias, self.stride, self.padding,\n                output_padding, self.groups, self.dilation)\n\n        def forward(self, *args, **kwargs):\n            if self.comfy_cast_weights or len(self.weight_function) > 0 or len(self.bias_function) > 0:\n                return self.forward_comfy_cast_weights(*args, **kwargs)\n            else:\n                return super().forward(*args, **kwargs)\n\n    class Embedding",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 213,
        "end": 223,
        "startLoc": {
          "line": 213,
          "column": 17,
          "position": 2153
        },
        "endLoc": {
          "line": 223,
          "column": 10,
          "position": 2281
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/ops.py",
        "start": 192,
        "end": 88,
        "startLoc": {
          "line": 192,
          "column": 17,
          "position": 1905
        },
        "endLoc": {
          "line": 88,
          "column": 7,
          "position": 698
        }
      }
    },
    {
      "format": "python",
      "lines": 7,
      "fragment": "def calculate_denoised(self, sigma, model_output, model_input):\n        sigma = sigma.view(sigma.shape[:1] + (1,) * (model_output.ndim - 1))\n        return model_input - model_output * sigma\n\n    def noise_scaling(self, sigma, noise, latent_image, max_denoise=False):\n        sigma = sigma.view(sigma.shape[:1] + (1,) * (noise.ndim - 1))\n        return",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_sampling.py",
        "start": 60,
        "end": 66,
        "startLoc": {
          "line": 60,
          "column": 5,
          "position": 779
        },
        "endLoc": {
          "line": 66,
          "column": 7,
          "position": 908
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_sampling.py",
        "start": 29,
        "end": 35,
        "startLoc": {
          "line": 29,
          "column": 5,
          "position": 270
        },
        "endLoc": {
          "line": 35,
          "column": 3,
          "position": 399
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "), min=0, max=(len(self.sigmas) - 1))\n        low_idx = t.floor().long()\n        high_idx = t.ceil().long()\n        w = t.frac()\n        log_sigma = (1 - w) * self.log_sigmas[low_idx] + w * self.log_sigmas[high_idx]\n        return log_sigma.exp().to(timestep.device)\n\n    def",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_sampling.py",
        "start": 144,
        "end": 151,
        "startLoc": {
          "line": 144,
          "column": 7,
          "position": 1730
        },
        "endLoc": {
          "line": 151,
          "column": 4,
          "position": 1848
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy_extras/nodes_model_advanced.py",
        "start": 43,
        "end": 51,
        "startLoc": {
          "line": 43,
          "column": 2,
          "position": 569
        },
        "endLoc": {
          "line": 51,
          "column": 6,
          "position": 687
        }
      }
    },
    {
      "format": "python",
      "lines": 9,
      "fragment": "(torch.nn.Module):\n    def __init__(self, model_config=None):\n        super().__init__()\n        if model_config is not None:\n            sampling_settings = model_config.sampling_settings\n        else:\n            sampling_settings = {}\n\n        self.set_parameters(shift=sampling_settings.get(\"shift\", 1.15",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_sampling.py",
        "start": 318,
        "end": 326,
        "startLoc": {
          "line": 318,
          "column": 18,
          "position": 3613
        },
        "endLoc": {
          "line": 326,
          "column": 5,
          "position": 3693
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_sampling.py",
        "start": 224,
        "end": 232,
        "startLoc": {
          "line": 224,
          "column": 26,
          "position": 2542
        },
        "endLoc": {
          "line": 232,
          "column": 4,
          "position": 2622
        }
      }
    },
    {
      "format": "python",
      "lines": 15,
      "fragment": ")\n        self.register_buffer('sigmas', ts)\n\n    @property\n    def sigma_min(self):\n        return self.sigmas[0]\n\n    @property\n    def sigma_max(self):\n        return self.sigmas[-1]\n\n    def timestep(self, sigma):\n        return sigma\n\n    def",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_sampling.py",
        "start": 330,
        "end": 344,
        "startLoc": {
          "line": 330,
          "column": 2,
          "position": 3757
        },
        "endLoc": {
          "line": 344,
          "column": 4,
          "position": 3839
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_sampling.py",
        "start": 237,
        "end": 249,
        "startLoc": {
          "line": 237,
          "column": 11,
          "position": 2717
        },
        "endLoc": {
          "line": 249,
          "column": 2,
          "position": 2797
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "dit_config[\"context_in_dim\"] = 4096\n        dit_config[\"hidden_size\"] = 3072\n        dit_config[\"mlp_ratio\"] = 4.0\n        dit_config[\"num_heads\"] = 24\n        dit_config[\"depth\"] = count_blocks(state_dict_keys, '{}double_blocks.'.format(key_prefix) + '{}.')\n        dit_config[\"depth_single_blocks\"] = count_blocks(state_dict_keys, '{}single_blocks.'.format(key_prefix) + '{}.')\n        dit_config[\"axes_dim\"] = [16, 56, 56]\n        dit_config[\"theta\"] = 10000",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 170,
        "end": 177,
        "startLoc": {
          "line": 170,
          "column": 9,
          "position": 2233
        },
        "endLoc": {
          "line": 177,
          "column": 6,
          "position": 2348
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 144,
        "end": 151,
        "startLoc": {
          "line": 144,
          "column": 9,
          "position": 1876
        },
        "endLoc": {
          "line": 151,
          "column": 4,
          "position": 1991
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", 'dtype': dtype, 'in_channels': 4, 'model_channels': 320,\n                    'num_res_blocks': [2, 2, 2, 2], 'transformer_depth': [1, 1, 1, 1, 1, 1, 0, 0], 'channel_mult': [1, 2, 4, 4], 'transformer_depth_middle': 1,\n                    'use_linear_in_transformer': True, 'context_dim': 1024, 'num_head_channels': 64, 'transformer_depth_output': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n                    'use_temporal_attention': False, 'use_temporal_resblock': False}\n\n    SD21_unclipl",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 674,
        "end": 679,
        "startLoc": {
          "line": 674,
          "column": 5,
          "position": 7974
        },
        "endLoc": {
          "line": 679,
          "column": 13,
          "position": 8139
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 668,
        "end": 673,
        "startLoc": {
          "line": 668,
          "column": 5,
          "position": 7763
        },
        "endLoc": {
          "line": 673,
          "column": 13,
          "position": 7928
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", 'dtype': dtype, 'in_channels': 4, 'model_channels': 320,\n                    'num_res_blocks': [2, 2, 2, 2], 'transformer_depth': [1, 1, 1, 1, 1, 1, 0, 0], 'channel_mult': [1, 2, 4, 4], 'transformer_depth_middle': 1,\n                    'use_linear_in_transformer': True, 'context_dim': 1024, 'num_head_channels': 64, 'transformer_depth_output': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n                    'use_temporal_attention': False, 'use_temporal_resblock': False}\n\n    SD15",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 680,
        "end": 685,
        "startLoc": {
          "line": 680,
          "column": 5,
          "position": 8185
        },
        "endLoc": {
          "line": 685,
          "column": 5,
          "position": 8350
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 668,
        "end": 673,
        "startLoc": {
          "line": 668,
          "column": 5,
          "position": 7763
        },
        "endLoc": {
          "line": 673,
          "column": 13,
          "position": 7928
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", 'model_channels': 320,\n                              'num_res_blocks': [2, 2, 2], 'transformer_depth': [0, 0, 2, 2, 10, 10], 'channel_mult': [1, 2, 4], 'transformer_depth_middle': 10,\n                              'use_linear_in_transformer': True, 'context_dim': 2048, 'num_head_channels': 64, 'transformer_depth_output': [0, 0, 0, 2, 2, 2, 10, 10, 10],\n                              'use_temporal_attention': False, 'use_temporal_resblock': False}\n\n    SDXL_diffusers_ip2p",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 704,
        "end": 709,
        "startLoc": {
          "line": 704,
          "column": 2,
          "position": 8993
        },
        "endLoc": {
          "line": 709,
          "column": 20,
          "position": 9125
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 656,
        "end": 661,
        "startLoc": {
          "line": 656,
          "column": 2,
          "position": 7380
        },
        "endLoc": {
          "line": 661,
          "column": 13,
          "position": 7512
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", 'model_channels': 320,\n                              'num_res_blocks': [2, 2, 2], 'transformer_depth': [0, 0, 2, 2, 10, 10], 'channel_mult': [1, 2, 4], 'transformer_depth_middle': 10,\n                              'use_linear_in_transformer': True, 'context_dim': 2048, 'num_head_channels': 64, 'transformer_depth_output': [0, 0, 0, 2, 2, 2, 10, 10, 10],\n                              'use_temporal_attention': False, 'use_temporal_resblock': False}\n\n    SSD_1B",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 710,
        "end": 715,
        "startLoc": {
          "line": 710,
          "column": 2,
          "position": 9183
        },
        "endLoc": {
          "line": 715,
          "column": 7,
          "position": 9315
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 656,
        "end": 661,
        "startLoc": {
          "line": 656,
          "column": 2,
          "position": 7380
        },
        "endLoc": {
          "line": 661,
          "column": 13,
          "position": 7512
        }
      }
    },
    {
      "format": "python",
      "lines": 6,
      "fragment": ", 'model_channels': 320, 'num_res_blocks': [2, 2, 2, 2], 'transformer_depth': [1, 1, 1, 1, 1, 1, 0, 0],\n            'channel_mult': [1, 2, 4, 4], 'transformer_depth_middle': 1, 'use_linear_in_transformer': False, 'context_dim': 768, 'num_heads': 8,\n            'transformer_depth_output': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n            'use_temporal_attention': False, 'use_temporal_resblock': False}\n\n    LotusD",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 752,
        "end": 757,
        "startLoc": {
          "line": 752,
          "column": 2,
          "position": 10442
        },
        "endLoc": {
          "line": 757,
          "column": 7,
          "position": 10595
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/model_detection.py",
        "start": 668,
        "end": 691,
        "startLoc": {
          "line": 668,
          "column": 2,
          "position": 7775
        },
        "endLoc": {
          "line": 691,
          "column": 14,
          "position": 8555
        }
      }
    },
    {
      "format": "python",
      "lines": 32,
      "fragment": "def pad_tensor_to_shape(tensor: torch.Tensor, new_shape: list[int]) -> torch.Tensor:\n    \"\"\"\n    Pad a tensor to a new shape with zeros.\n\n    Args:\n        tensor (torch.Tensor): The original tensor to be padded.\n        new_shape (List[int]): The desired shape of the padded tensor.\n\n    Returns:\n        torch.Tensor: A new tensor padded with zeros to the specified shape.\n\n    Note:\n        If the new shape is smaller than the original tensor in any dimension,\n        the original tensor will be truncated in that dimension.\n    \"\"\"\n    if any([new_shape[i] < tensor.shape[i] for i in range(len(new_shape))]):\n        raise ValueError(\"The new shape must be larger than the original tensor in all dimensions\")\n\n    if len(new_shape) != len(tensor.shape):\n        raise ValueError(\"The new shape must have the same number of dimensions as the original tensor\")\n\n    # Create a new tensor filled with zeros\n    padded_tensor = torch.zeros(new_shape, dtype=tensor.dtype, device=tensor.device)\n\n    # Create slicing tuples for both tensors\n    orig_slices = tuple(slice(0, dim) for dim in tensor.shape)\n    new_slices = tuple(slice(0, dim) for dim in tensor.shape)\n\n    # Copy the original tensor into the new tensor\n    padded_tensor[new_slices] = tensor[orig_slices]\n\n    return padded_tensor",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/lora.py",
        "start": 299,
        "end": 330,
        "startLoc": {
          "line": 299,
          "column": 1,
          "position": 3234
        },
        "endLoc": {
          "line": 330,
          "column": 14,
          "position": 3445
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/weight_adapter/base.py",
        "start": 73,
        "end": 104,
        "startLoc": {
          "line": 73,
          "column": 1,
          "position": 590
        },
        "endLoc": {
          "line": 104,
          "column": 14,
          "position": 801
        }
      }
    },
    {
      "format": "python",
      "lines": 11,
      "fragment": "def process_in(self, latent):\n        latents_mean = self.latents_mean.to(latent.device, latent.dtype)\n        latents_std = self.latents_std.to(latent.device, latent.dtype)\n        return (latent - latents_mean) * self.scale_factor / latents_std\n\n    def process_out(self, latent):\n        latents_mean = self.latents_mean.to(latent.device, latent.dtype)\n        latents_std = self.latents_std.to(latent.device, latent.dtype)\n        return latent * latents_std / self.scale_factor + latents_mean\n\nclass LTXV",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/latent_formats.py",
        "start": 213,
        "end": 223,
        "startLoc": {
          "line": 213,
          "column": 5,
          "position": 2299
        },
        "endLoc": {
          "line": 223,
          "column": 5,
          "position": 2450
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/latent_formats.py",
        "start": 59,
        "end": 70,
        "startLoc": {
          "line": 59,
          "column": 5,
          "position": 524
        },
        "endLoc": {
          "line": 70,
          "column": 6,
          "position": 676
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "self.taesd_decoder_name = None #TODO\n\n    def process_in(self, latent):\n        latents_mean = self.latents_mean.to(latent.device, latent.dtype)\n        latents_std = self.latents_std.to(latent.device, latent.dtype)\n        return (latent - latents_mean) * self.scale_factor / latents_std\n\n    def process_out(self, latent):\n        latents_mean = self.latents_mean.to(latent.device, latent.dtype)\n        latents_std = self.latents_std.to(latent.device, latent.dtype)\n        return latent * latents_std / self.scale_factor + latents_mean\n\nclass Hunyuan3Dv2",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/latent_formats.py",
        "start": 448,
        "end": 460,
        "startLoc": {
          "line": 448,
          "column": 9,
          "position": 5339
        },
        "endLoc": {
          "line": 460,
          "column": 12,
          "position": 5502
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/latent_formats.py",
        "start": 211,
        "end": 70,
        "startLoc": {
          "line": 211,
          "column": 9,
          "position": 2287
        },
        "endLoc": {
          "line": 70,
          "column": 6,
          "position": 676
        }
      }
    },
    {
      "format": "python",
      "lines": 20,
      "fragment": ",\n            heads=n_heads,\n            dim_head=d_head,\n            operations=ops)\n        self.ff = FeedForward(query_dim, glu=True)\n\n        self.norm1 = ops.LayerNorm(query_dim)\n        self.norm2 = ops.LayerNorm(query_dim)\n\n        self.register_parameter('alpha_attn', nn.Parameter(torch.tensor(0.)))\n        self.register_parameter('alpha_dense', nn.Parameter(torch.tensor(0.)))\n\n        # this can be useful: we can externally change magnitude of tanh(alpha)\n        # for example, when it is set to 0, then the entire model is same as\n        # original one\n        self.scale = 1\n\n    def forward(self, x, objs):\n\n        N_visual",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/gligen.py",
        "start": 97,
        "end": 116,
        "startLoc": {
          "line": 97,
          "column": 10,
          "position": 848
        },
        "endLoc": {
          "line": 116,
          "column": 9,
          "position": 996
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/gligen.py",
        "start": 60,
        "end": 79,
        "startLoc": {
          "line": 60,
          "column": 12,
          "position": 520
        },
        "endLoc": {
          "line": 79,
          "column": 2,
          "position": 668
        }
      }
    },
    {
      "format": "python",
      "lines": 10,
      "fragment": "(nn.Module):\n    def __init__(self, query_dim, context_dim, n_heads, d_head):\n        super().__init__()\n\n        # we need a linear projection since we need cat visual feature and obj\n        # feature\n        self.linear = ops.Linear(context_dim, query_dim)\n\n        self.attn = CrossAttention(\n            query_dim=query_dim, context_dim=query_dim, dim_head",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/gligen.py",
        "start": 127,
        "end": 136,
        "startLoc": {
          "line": 127,
          "column": 25,
          "position": 1138
        },
        "endLoc": {
          "line": 136,
          "column": 9,
          "position": 1221
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/gligen.py",
        "start": 87,
        "end": 98,
        "startLoc": {
          "line": 87,
          "column": 24,
          "position": 766
        },
        "endLoc": {
          "line": 98,
          "column": 6,
          "position": 851
        }
      }
    },
    {
      "format": "python",
      "lines": 17,
      "fragment": ", dim_head=d_head, operations=ops)\n        self.ff = FeedForward(query_dim, glu=True)\n\n        self.norm1 = ops.LayerNorm(query_dim)\n        self.norm2 = ops.LayerNorm(query_dim)\n\n        self.register_parameter('alpha_attn', nn.Parameter(torch.tensor(0.)))\n        self.register_parameter('alpha_dense', nn.Parameter(torch.tensor(0.)))\n\n        # this can be useful: we can externally change magnitude of tanh(alpha)\n        # for example, when it is set to 0, then the entire model is same as\n        # original one\n        self.scale = 1\n\n    def forward(self, x, objs):\n\n        B",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/gligen.py",
        "start": 136,
        "end": 152,
        "startLoc": {
          "line": 136,
          "column": 10,
          "position": 1219
        },
        "endLoc": {
          "line": 152,
          "column": 2,
          "position": 1359
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/gligen.py",
        "start": 61,
        "end": 79,
        "startLoc": {
          "line": 61,
          "column": 8,
          "position": 526
        },
        "endLoc": {
          "line": 79,
          "column": 2,
          "position": 668
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": "unet_dtype = comfy.model_management.unet_dtype(model_params=-1, supported_dtypes=supported_inference_dtypes, weight_dtype=weight_dtype)\n\n    load_device = comfy.model_management.get_torch_device()\n\n    manual_cast_dtype = comfy.model_management.unet_manual_cast(unet_dtype, load_device)\n    operations = model_options.get(\"custom_operations\", None)\n    if operations is None:\n        operations = comfy.ops.pick_operations(unet_dtype, manual_cast_dtype)",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/controlnet.py",
        "start": 690,
        "end": 697,
        "startLoc": {
          "line": 690,
          "column": 9,
          "position": 7432
        },
        "endLoc": {
          "line": 697,
          "column": 2,
          "position": 7530
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/controlnet.py",
        "start": 422,
        "end": 429,
        "startLoc": {
          "line": 422,
          "column": 9,
          "position": 4532
        },
        "endLoc": {
          "line": 429,
          "column": 2,
          "position": 4630
        }
      }
    },
    {
      "format": "python",
      "lines": 13,
      "fragment": "def get_control(self, x_noisy, t, cond, batched_number, transformer_options):\n        control_prev = None\n        if self.previous_controlnet is not None:\n            control_prev = self.previous_controlnet.get_control(x_noisy, t, cond, batched_number, transformer_options)\n\n        if self.timestep_range is not None:\n            if t[0] > self.timestep_range[0] or t[0] < self.timestep_range[1]:\n                if control_prev is not None:\n                    return control_prev\n                else:\n                    return None\n\n        if",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/controlnet.py",
        "start": 769,
        "end": 781,
        "startLoc": {
          "line": 769,
          "column": 5,
          "position": 8302
        },
        "endLoc": {
          "line": 781,
          "column": 3,
          "position": 8449
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/controlnet.py",
        "start": 217,
        "end": 229,
        "startLoc": {
          "line": 217,
          "column": 5,
          "position": 2042
        },
        "endLoc": {
          "line": 229,
          "column": 6,
          "position": 2189
        }
      }
    },
    {
      "format": "json",
      "lines": 17,
      "fragment": "{\n  \"attention_dropout\": 0.0,\n  \"dropout\": 0.0,\n  \"hidden_act\": \"quick_gelu\",\n  \"hidden_size\": 1024,\n  \"image_size\": 336,\n  \"initializer_factor\": 1.0,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-5,\n  \"model_type\": \"clip_vision_model\",\n  \"num_attention_heads\": 16,\n  \"num_channels\": 3,\n  \"num_hidden_layers\": 24,\n  \"patch_size\": 14,\n  \"projection_dim\": 768,\n  \"torch_dtype\"",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision_config_vitl_336.json",
        "start": 1,
        "end": 17,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 17,
          "column": 14,
          "position": 108
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_vision_config_vitl_336_llava.json",
        "start": 1,
        "end": 17,
        "startLoc": {
          "line": 1,
          "column": 1,
          "position": 0
        },
        "endLoc": {
          "line": 17,
          "column": 17,
          "position": 108
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ", dtype, device, operations) for i in range(num_layers)])\n\n    def forward(self, x, mask=None, intermediate_output=None):\n        optimized_attention = optimized_attention_for_device(x.device, mask=mask is not None, small_input=True)\n\n        if intermediate_output is not None:\n            if intermediate_output < 0:\n                intermediate_output = len(self.layers",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_model.py",
        "start": 59,
        "end": 66,
        "startLoc": {
          "line": 59,
          "column": 24,
          "position": 854
        },
        "endLoc": {
          "line": 66,
          "column": 7,
          "position": 961
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/bert.py",
        "start": 71,
        "end": 78,
        "startLoc": {
          "line": 71,
          "column": 15,
          "position": 962
        },
        "endLoc": {
          "line": 78,
          "column": 6,
          "position": 1069
        }
      }
    },
    {
      "format": "python",
      "lines": 8,
      "fragment": ", dtype=dtype)\n\n        mask = None\n        if attention_mask is not None:\n            mask = 1.0 - attention_mask.to(x.dtype).reshape((attention_mask.shape[0], 1, -1, attention_mask.shape[-1])).expand(attention_mask.shape[0], 1, attention_mask.shape[-1], attention_mask.shape[-1])\n            mask = mask.masked_fill(mask.to(torch.bool), -torch.finfo(x.dtype).max)\n\n        causal_mask",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/clip_model.py",
        "start": 104,
        "end": 111,
        "startLoc": {
          "line": 104,
          "column": 13,
          "position": 1529
        },
        "endLoc": {
          "line": 111,
          "column": 12,
          "position": 1667
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/comfy/text_encoders/bert.py",
        "start": 120,
        "end": 208,
        "startLoc": {
          "line": 120,
          "column": 7,
          "position": 1708
        },
        "endLoc": {
          "line": 208,
          "column": 13,
          "position": 2557
        }
      }
    },
    {
      "format": "python",
      "lines": 16,
      "fragment": "for file_name in filenames:\n            try:\n                relative_path = os.path.relpath(os.path.join(dirpath, file_name), directory)\n                result.append(relative_path)\n            except:\n                logging.warning(f\"Warning: Unable to access {file_name}. Skipping this file.\")\n                continue\n\n        for d in subdirs:\n            path: str = os.path.join(dirpath, d)\n            try:\n                dirs[path] = os.path.getmtime(path)\n            except FileNotFoundError:\n                logging.warning(f\"Warning: Unable to access {path}. Skipping this path.\")\n                continue\n    logging",
      "tokens": 0,
      "firstFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/folder_paths.py",
        "start": 255,
        "end": 270,
        "startLoc": {
          "line": 255,
          "column": 9,
          "position": 2491
        },
        "endLoc": {
          "line": 270,
          "column": 8,
          "position": 2626
        }
      },
      "secondFile": {
        "name": "../../../var/folders/j4/jhlngj2j76j0xgrdp8rnl6s80000gn/T/bridge-cli-2frwe_ba/app/model_manager.py",
        "start": 131,
        "end": 147,
        "startLoc": {
          "line": 131,
          "column": 13,
          "position": 1392
        },
        "endLoc": {
          "line": 147,
          "column": 7,
          "position": 1528
        }
      }
    }
  ]
}